{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44775e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54483e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2c94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(test_set_labeled):\n",
    "    test_set_labeled=test_set_labeled.loc[~test_set_labeled[\"task_annotation\"].isna()]\n",
    "    test_set_labeled=test_set_labeled.loc[~test_set_labeled[\"method_annotation\"].isna()]\n",
    "    \n",
    "    test_set_labeled=test_set_labeled.assign(task_annotation=test_set_labeled.task_annotation.str.lower().str.replace(\" ,\",\",\").str.replace(\", \",\",\").str.split(\",\"))\n",
    "\n",
    "    test_set_labeled=test_set_labeled.assign(method_annotation=test_set_labeled.method_annotation.str.lower().str.replace(\" ,\",\",\").str.replace(\", \",\",\").str.split(\",\"))\n",
    "\n",
    "    test_set_labeled=test_set_labeled.assign(org_annotation=test_set_labeled.org_annotation.str.lower().str.replace(\" ,\",\",\").str.replace(\", \",\",\").str.split(\",\"))\n",
    "\n",
    "    test_set_labeled=test_set_labeled.loc[:,['ID','text','task_annotation', 'method_annotation', 'org_annotation']]\n",
    "\n",
    "    return test_set_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abc0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../data/\"\n",
    "output_path=\"../outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ba79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_labeled=pd.read_csv(output_path+\"general/test_set_final.csv\")\n",
    "\n",
    "methods_gpt3=pd.read_csv(output_path+\"sg_ie/gpt3/GPT3_responses_method2_cleaned_f.csv\")\n",
    "tasks_gpt3=pd.read_csv(output_path+\"sg_ie/gpt3/GPT3_responses_task_cleaned_f2.csv\")\n",
    "\n",
    "orgs=pd.read_csv(output_path+\"sg_ie/organizations_test_stanza_ontonotes_final.csv\")\n",
    "df_lan=pd.read_csv(output_path+\"general/test_set_language.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a8e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_scirex=pd.read_json(output_path+\"sg_ie/test_scirex_tasks_methods_clusters_salient_final_f.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd885ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_labeled=test_set_labeled.loc[test_set_labeled.label==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad09899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a7cecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miller-etal-2012-using</td>\n",
       "      <td>[{'words': ['disambiguation', 'disambiguation'...</td>\n",
       "      <td>[{'words': ['distributional similarity'], 'val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kim-etal-2019-unsupervised</td>\n",
       "      <td>[{'words': ['parsing', 'constituency grammar i...</td>\n",
       "      <td>[{'words': ['unsupervised recurrent neural net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iyer-etal-2021-veealign</td>\n",
       "      <td>[{'words': ['ontology alignment', 'ontology al...</td>\n",
       "      <td>[{'words': ['dual attention', 'dual attention ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patra-etal-2013-automatic</td>\n",
       "      <td>[{'words': ['automatic music mood classificati...</td>\n",
       "      <td>[{'words': ['automatic methods'], 'value': 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kazi-etal-2014-mitll</td>\n",
       "      <td>[{'words': ['mt', 'mt', 'translating'], 'value...</td>\n",
       "      <td>[{'words': ['pro and drem optimization'], 'val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5083</th>\n",
       "      <td>owoputi-etal-2013-improved</td>\n",
       "      <td>[{'words': ['part of speech tagging', 'part of...</td>\n",
       "      <td>[{'words': ['large - scale unsupervised word c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>kang-etal-2020-neural</td>\n",
       "      <td>[{'words': ['question answering', 'question an...</td>\n",
       "      <td>[{'words': ['transformer based policy network'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>ligozat-2013-question</td>\n",
       "      <td>[{'words': ['question classification', 'questi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>hozumi-etal-1993-integration</td>\n",
       "      <td>[{'words': ['segmentation'], 'value': 0.398467...</td>\n",
       "      <td>[{'words': ['integration of morphological and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>maruf-etal-2021-explaining</td>\n",
       "      <td>[{'words': ['explaining decision tree predicti...</td>\n",
       "      <td>[{'words': ['dts', 'dts'], 'value': 0.34952490...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5088 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ID  \\\n",
       "0           miller-etal-2012-using   \n",
       "1       kim-etal-2019-unsupervised   \n",
       "2          iyer-etal-2021-veealign   \n",
       "3        patra-etal-2013-automatic   \n",
       "4             kazi-etal-2014-mitll   \n",
       "...                            ...   \n",
       "5083    owoputi-etal-2013-improved   \n",
       "5084         kang-etal-2020-neural   \n",
       "5085         ligozat-2013-question   \n",
       "5086  hozumi-etal-1993-integration   \n",
       "5087    maruf-etal-2021-explaining   \n",
       "\n",
       "                                            task_scirex  \\\n",
       "0     [{'words': ['disambiguation', 'disambiguation'...   \n",
       "1     [{'words': ['parsing', 'constituency grammar i...   \n",
       "2     [{'words': ['ontology alignment', 'ontology al...   \n",
       "3     [{'words': ['automatic music mood classificati...   \n",
       "4     [{'words': ['mt', 'mt', 'translating'], 'value...   \n",
       "...                                                 ...   \n",
       "5083  [{'words': ['part of speech tagging', 'part of...   \n",
       "5084  [{'words': ['question answering', 'question an...   \n",
       "5085  [{'words': ['question classification', 'questi...   \n",
       "5086  [{'words': ['segmentation'], 'value': 0.398467...   \n",
       "5087  [{'words': ['explaining decision tree predicti...   \n",
       "\n",
       "                                          method_scirex  \n",
       "0     [{'words': ['distributional similarity'], 'val...  \n",
       "1     [{'words': ['unsupervised recurrent neural net...  \n",
       "2     [{'words': ['dual attention', 'dual attention ...  \n",
       "3     [{'words': ['automatic methods'], 'value': 0, ...  \n",
       "4     [{'words': ['pro and drem optimization'], 'val...  \n",
       "...                                                 ...  \n",
       "5083  [{'words': ['large - scale unsupervised word c...  \n",
       "5084  [{'words': ['transformer based policy network'...  \n",
       "5085                                                 []  \n",
       "5086  [{'words': ['integration of morphological and ...  \n",
       "5087  [{'words': ['dts', 'dts'], 'value': 0.34952490...  \n",
       "\n",
       "[5088 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_scirex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff56052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_set_labeled=process_test_data(test_set_labeled)\n",
    "df_labels_scirex=df_labels_scirex.loc[:,['ID','task_scirex','method_scirex']]\n",
    "## organizations\n",
    "orgs=orgs.assign(organization=orgs.organization.str.lower())\n",
    "orgs=orgs.groupby(['ID'])['organization'].apply(list).reset_index()\n",
    "## gpt 3\n",
    "tasks_gpt3=tasks_gpt3.assign(tasks=tasks_gpt3.tasks.str.lower())\n",
    "methods_gpt3=methods_gpt3.assign(methods=methods_gpt3.methods.str.lower())\n",
    "tasks_gpt3=tasks_gpt3.groupby(['ID'])['tasks'].apply(list).reset_index()\n",
    "methods_gpt3=methods_gpt3.groupby(['ID'])['methods'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34053823",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set_labeled.merge(tasks_gpt3,on=['ID'],how='left').merge(methods_gpt3,on=['ID'],how='left').merge(df_labels_scirex,on=['ID'],how='left').merge(orgs,on=['ID'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08eb27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set.loc[~test_set.task_scirex.isna(),:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616c9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set.loc[~test_set.method_scirex.isna(),:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84112683",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in test_set.iterrows():\n",
    "    tasks=[]\n",
    "    methods=[]\n",
    "    if len(d['task_scirex'])==0:\n",
    "        for word in d['tasks']:\n",
    "            tasks.append({'words':[word],'value':0,'top_word':word})\n",
    "        test_set.at[i,'task_scirex']=tasks\n",
    "    if len(d['method_scirex'])==0:\n",
    "        for word in d['methods']:\n",
    "            methods.append({'words':[word],'value':0,'top_word':word})\n",
    "        test_set.at[i,'method_scirex']=methods\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21761c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>task_annotation</th>\n",
       "      <th>method_annotation</th>\n",
       "      <th>org_annotation</th>\n",
       "      <th>tasks</th>\n",
       "      <th>methods</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "      <th>organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, text, task_annotation, method_annotation, org_annotation, tasks, methods, task_scirex, method_scirex, organization]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.loc[test_set.method_scirex.apply(lambda x:len(x))==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da6c5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dccb8ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>task_annotation</th>\n",
       "      <th>method_annotation</th>\n",
       "      <th>org_annotation</th>\n",
       "      <th>tasks</th>\n",
       "      <th>methods</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "      <th>organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, text, task_annotation, method_annotation, org_annotation, tasks, methods, task_scirex, method_scirex, organization]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.loc[test_set.method_scirex.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bed7afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "872836a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lev_sim(actual, predicted):\n",
    "    if predicted == []:\n",
    "        return 0\n",
    "    print(\"aa::::\",actual)\n",
    "    print(predicted)\n",
    "    \n",
    "    predicted_max=[]\n",
    "    for p in predicted:\n",
    "        max_ratio=0\n",
    "        for pp in p['words']:\n",
    "            for a in actual:\n",
    "                ratio = fuzz.partial_ratio(a.lower(), pp.lower())\n",
    "                if ratio>max_ratio:\n",
    "                    max_ratio=ratio\n",
    "        predicted_max.append(max_ratio)\n",
    "    return max(predicted_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f9626f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>task_annotation</th>\n",
       "      <th>method_annotation</th>\n",
       "      <th>org_annotation</th>\n",
       "      <th>tasks</th>\n",
       "      <th>methods</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "      <th>organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, text, task_annotation, method_annotation, org_annotation, tasks, methods, task_scirex, method_scirex, organization]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.loc[test_set.method_scirex.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10ddcf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set.loc[~test_set.task_scirex.isna(),:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62ccc07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa:::: ['contrastive automatic analysis of verbs']\n",
      "[{'words': ['automatic distinction'], 'value': 0, 'top_word': 'automatic distinction'}, {'words': ['contrastive automatic analysis of verbs'], 'value': 0, 'top_word': 'contrastive automatic analysis of verbs'}, {'words': ['semantic annotation'], 'value': 0, 'top_word': 'semantic annotation'}, {'words': ['semantic annotation'], 'value': 0, 'top_word': 'semantic annotation'}]\n",
      "aa:::: ['semantic annotation']\n",
      "[{'words': ['semantic annotation'], 'value': 0, 'top_word': 'semantic annotation'}, {'words': ['contrastive analysis'], 'value': 0, 'top_word': 'contrastive analysis'}, {'words': ['medical terminology'], 'value': 0, 'top_word': 'medical terminology'}]\n",
      "Towards Automatic Distinction between Specialized and Non-Specialized Occurrences of Verbs in Medical Corpora. The medical field gathers people of different social statuses, such as students, pharmacists, managers, biologists, nurses and mainly medical doctors and patients, who represent the main actors. Despite their different levels of expertise, these actors need to interact and understand each other but the communication is not always easy and effective. This paper describes a method for a contrastive automatic analysis of verbs in medical corpora, based on the semantic annotation of the verbs nominal co-occurents. The corpora used are specialized in cardiology and distinguished according to their levels of expertise (high and low). The semantic annotation of these corpora is performed by using an existing medical terminology. The results indicate that the same verbs occurring in the two corpora show different specialization levels, which are indicated by the words (nouns and adjectives derived from medical terms) they occur with.\n",
      "['semantic annotation']\n",
      "[{'words': ['semantic annotation'], 'value': 0, 'top_word': 'semantic annotation'}, {'words': ['contrastive analysis'], 'value': 0, 'top_word': 'contrastive analysis'}, {'words': ['medical terminology'], 'value': 0, 'top_word': 'medical terminology'}]\n",
      "100\n",
      "aa:::: ['legal area classification']\n",
      "[{'words': ['legal area classification', 'classifying judgments into legal areas'], 'value': 0.31437352300000004, 'top_word': 'legal area classification'}]\n",
      "aa:::: ['topic model', 'word embedding', 'language model']\n",
      "[{'words': ['text classifiers'], 'value': 0, 'top_word': 'text classifiers'}, {'words': ['machine learning (\"ml\") approaches'], 'value': 0, 'top_word': 'machine learning (\"ml\") approaches'}, {'words': ['nlp methods'], 'value': 0, 'top_word': 'nlp methods'}, {'words': ['statistical models'], 'value': 0, 'top_word': 'statistical models'}, {'words': ['topic model'], 'value': 0, 'top_word': 'topic model'}, {'words': ['word embedding'], 'value': 0, 'top_word': 'word embedding'}, {'words': ['language model - based classifiers'], 'value': 0, 'top_word': 'language model - based classifiers'}]\n",
      "Legal Area Classification: A Comparative Study of Text Classifiers on Singapore Supreme Court Judgments. This paper conducts a comparative study on the performance of various machine learning (\"ML\") approaches for classifying judgments into legal areas. Using a novel dataset of 6,227 Singapore Supreme Court judgments, we investigate how state-of-the-art NLP methods compare against traditional statistical models when applied to a legal corpus that comprised few but lengthy documents. All approaches tested, including topic model, word embedding, and language model-based classifiers, performed well with as little as a few hundred judgments. However, more work needs to be done to optimize state-of-the-art methods for the legal domain.\n",
      "['topic model', 'word embedding', 'language model']\n",
      "[{'words': ['text classifiers'], 'value': 0, 'top_word': 'text classifiers'}, {'words': ['machine learning (\"ml\") approaches'], 'value': 0, 'top_word': 'machine learning (\"ml\") approaches'}, {'words': ['nlp methods'], 'value': 0, 'top_word': 'nlp methods'}, {'words': ['statistical models'], 'value': 0, 'top_word': 'statistical models'}, {'words': ['topic model'], 'value': 0, 'top_word': 'topic model'}, {'words': ['word embedding'], 'value': 0, 'top_word': 'word embedding'}, {'words': ['language model - based classifiers'], 'value': 0, 'top_word': 'language model - based classifiers'}]\n",
      "100\n",
      "aa:::: ['hope speech detection', 'text classification']\n",
      "[{'words': ['hope speech detection', 'hope speech detection', 'voice detection'], 'value': 0.5902768075, 'top_word': 'hope speech detection'}, {'words': ['lt edi 2021'], 'value': 0.2862163186, 'top_word': 'lt edi 2021'}]\n",
      "aa:::: ['language model', 'xlm-roberta', 'tf-idf']\n",
      "[{'words': ['pre - trained language model'], 'value': 0, 'top_word': 'pre - trained language model'}, {'words': ['language model'], 'value': 0, 'top_word': 'language model'}, {'words': ['xlm - roberta pre - trained language model'], 'value': 0, 'top_word': 'xlm - roberta pre - trained language model'}, {'words': ['tf - idf algorithm'], 'value': 0, 'top_word': 'tf - idf algorithm'}]\n",
      "TEAM HUB@LT-EDI-EACL2021: Hope Speech Detection Based On Pre-trained Language Model. This article introduces the system description of TEAM HUB team participating in LT-EDI 2021: Hope Speech Detection. This shared task is the first task related to the desired voice detection. The data set in the shared task consists of three different languages (English, Tamil, and Malayalam). The task type is text classification. Based on the analysis and understanding of the task description and data set, we designed a system based on a pre-trained language model to complete this shared task. In this system, we use methods and models that combine the XLM-RoBERTa pre-trained language model and the Tf-Idf algorithm. In the final result ranking announced by the task organizer, our system obtained F1 scores of 0.93, 0.84, 0.59 on the English dataset, Malayalam dataset, and Tamil dataset. Our submission results are ranked 1, 2, and 3 respectively.\n",
      "['language model', 'xlm-roberta', 'tf-idf']\n",
      "[{'words': ['pre - trained language model'], 'value': 0, 'top_word': 'pre - trained language model'}, {'words': ['language model'], 'value': 0, 'top_word': 'language model'}, {'words': ['xlm - roberta pre - trained language model'], 'value': 0, 'top_word': 'xlm - roberta pre - trained language model'}, {'words': ['tf - idf algorithm'], 'value': 0, 'top_word': 'tf - idf algorithm'}]\n",
      "100\n",
      "aa:::: ['identifying and classifying malware text']\n",
      "[{'words': ['identifying and classifying malware text'], 'value': 0, 'top_word': 'identifying and classifying malware text'}, {'words': ['semeval 2018'], 'value': 0, 'top_word': 'semeval 2018'}]\n",
      "aa:::: ['supervised learning', 'conditional random fields']\n",
      "[{'words': ['conditional random fields'], 'value': 0, 'top_word': 'conditional random fields'}, {'words': ['na\\\\\"\\\\ive bayes classifiers'], 'value': 0, 'top_word': 'na\\\\\"\\\\ive bayes classifiers'}, {'words': ['supervised learning approach'], 'value': 0, 'top_word': 'supervised learning approach'}]\n",
      "Flytxt\\_NTNU at SemEval-2018 Task 8: Identifying and Classifying Malware Text Using Conditional Random Fields and Na\\\"\\ive Bayes Classifiers. Cybersecurity risks such as malware threaten the personal safety of users, but to identify malware text is a major challenge. The paper proposes a supervised learning approach to identifying malware sentences given a document (subTask1 of SemEval 2018, Task 8), as well as to classifying malware tokens in the sentences (subTask2). The approach achieved good results, ranking second of twelve participants for both subtasks, with F-scores of 57% for subTask1 and 28% for subTask2.\n",
      "['supervised learning', 'conditional random fields']\n",
      "[{'words': ['conditional random fields'], 'value': 0, 'top_word': 'conditional random fields'}, {'words': ['na\\\\\"\\\\ive bayes classifiers'], 'value': 0, 'top_word': 'na\\\\\"\\\\ive bayes classifiers'}, {'words': ['supervised learning approach'], 'value': 0, 'top_word': 'supervised learning approach'}]\n",
      "100\n",
      "aa:::: ['compiling an interactive literary translation site']\n",
      "[{'words': ['interactive literary translation', 'literary translation', 'literary translation', 'literary translation'], 'value': 0.4173472673, 'top_word': 'literary translation'}]\n",
      "aa:::: ['web site']\n",
      "[{'words': ['web resources'], 'value': 0, 'top_word': 'web resources'}, {'words': ['course methodology'], 'value': 0, 'top_word': 'course methodology'}]\n",
      "Compiling an Interactive Literary Translation Web Site for Education Purposes. The project under discussion represents an attempt to exploit the potential of web resources for higher education and, more particularly, on a domain (that of literary translation) which is traditionally considered not very much in relation to technology and computer science. Translation and Interpreting students at the Universidad de Málaga are offered the possibility to take an English-Spanish Literary Translation module, which epitomises the need for debate in the field of Humanities. Sadly enough, implementation of course methodology is rendered very difficult or impossible owing to time restrictions and overcrowded classrooms. It is our contention that the setting up of a web site may solve some of these issues. We intend to provide both students and the literary translation-aware Internet audience with an integrated, scalable, multifunctional debate forum. Project contents will include a detailed course description, relevant reference materials and interaction services (mailing list, debate forum and chat rooms). This is obviously without limitation, as the Forum is open to any other contents that users may consider necessary or convenient, with a view to a more interdisciplinary approach, further research on the field of Literary Translation and future developments within the project framework.\n",
      "['web site']\n",
      "[{'words': ['web resources'], 'value': 0, 'top_word': 'web resources'}, {'words': ['course methodology'], 'value': 0, 'top_word': 'course methodology'}]\n",
      "62\n",
      "aa:::: ['avoiding and resolving initiative conflicts']\n",
      "[{'words': ['avoiding and resolving initiative conflicts'], 'value': 0, 'top_word': 'avoiding and resolving initiative conflicts'}, {'words': ['dialogue'], 'value': 0, 'top_word': 'dialogue'}, {'words': ['initiative conflicts'], 'value': 0, 'top_word': 'initiative conflicts'}, {'words': ['human - human conversation'], 'value': 0, 'top_word': 'human - human conversation'}]\n",
      "aa:::: ['empirical study']\n",
      "[{'words': ['empirical study'], 'value': 0, 'top_word': 'empirical study'}, {'words': ['corpus analysis'], 'value': 0, 'top_word': 'corpus analysis'}, {'words': ['linguistic analysis'], 'value': 0, 'top_word': 'linguistic analysis'}]\n",
      "Avoiding and Resolving Initiative Conflicts in Dialogue. In this paper, we report on an empirical study on initiative conflicts in human-human conversation. We examined these conflicts in two corpora of task-oriented dialogues. The results show that conversants try to avoid initiative conflicts, but when these conflicts occur, they are efficiently resolved by linguistic devices, such as volume.\n",
      "['empirical study']\n",
      "[{'words': ['empirical study'], 'value': 0, 'top_word': 'empirical study'}, {'words': ['corpus analysis'], 'value': 0, 'top_word': 'corpus analysis'}, {'words': ['linguistic analysis'], 'value': 0, 'top_word': 'linguistic analysis'}]\n",
      "100\n",
      "aa:::: ['fake news detection']\n",
      "[{'words': ['fake news detection', 'language of fake news spreaders'], 'value': 0.2366785277, 'top_word': 'fake news detection'}]\n",
      "aa:::: ['language-based user representations']\n",
      "[{'words': ['language - based user representations'], 'value': 0, 'top_word': 'language - based user representations'}, {'words': ['language - based user representations'], 'value': 0, 'top_word': 'language - based user representations'}]\n",
      "Words are the Window to the Soul: Language-based User Representations for Fake News Detection. Cognitive and social traits of individuals are reflected in language use. Moreover, individuals who are prone to spread fake news online often share common traits. Building on these ideas, we introduce a model that creates representations of individuals on social media based only on the language they produce, and use them to detect fake news. We show that language-based user representations are beneficial for this task. We also present an extended analysis of the language of fake news spreaders, showing that its main features are mostly domain independent and consistent across two English datasets. Finally, we exploit the relation between language use and connections in the social graph to assess the presence of the Echo Chamber effect in our data.\n",
      "['language-based user representations']\n",
      "[{'words': ['language - based user representations'], 'value': 0, 'top_word': 'language - based user representations'}, {'words': ['language - based user representations'], 'value': 0, 'top_word': 'language - based user representations'}]\n",
      "94\n",
      "aa:::: ['conversion of plain texts']\n",
      "[{'words': ['multimodal language learner texts'], 'value': 0, 'top_word': 'multimodal language learner texts'}, {'words': ['conversion of plain texts'], 'value': 0, 'top_word': 'conversion of plain texts'}, {'words': ['multimodal online versions'], 'value': 0, 'top_word': 'multimodal online versions'}, {'words': ['language learners'], 'value': 0, 'top_word': 'language learners'}, {'words': ['reading and listening'], 'value': 0, 'top_word': 'reading and listening'}, {'words': ['conversion task'], 'value': 0, 'top_word': 'conversion task'}]\n",
      "aa:::: ['learning and reading assistant']\n",
      "[{'words': ['lara'], 'value': 0, 'top_word': 'lara'}, {'words': ['lara (learning and reading assistant)'], 'value': 0, 'top_word': 'lara (learning and reading assistant)'}, {'words': ['crowdsourcing techniques'], 'value': 0, 'top_word': 'crowdsourcing techniques'}, {'words': ['lara'], 'value': 0, 'top_word': 'lara'}]\n",
      "Constructing Multimodal Language Learner Texts Using LARA: Experiences with Nine Languages. LARA (Learning and Reading Assistant) is an open source platform whose purpose is to support easy conversion of plain texts into multimodal online versions suitable for use by language learners. This involves semi-automatically tagging the text, adding other annotations and recording audio. The platform is suitable for creating texts in multiple languages via crowdsourcing techniques that can be used for teaching a language via reading and listening. We present results of initial experiments by various collaborators where we measure the time required to produce substantial LARA resources, up to the length of short novels, in Dutch, English, Farsi, French, German, Icelandic, Irish, Swedish and Turkish. The first results are encouraging. Although there are some startup problems, the conversion task seems manageable for the languages tested so far. The resulting enriched texts are posted online and are freely available in both source and compiled form.\n",
      "['learning and reading assistant']\n",
      "[{'words': ['lara'], 'value': 0, 'top_word': 'lara'}, {'words': ['lara (learning and reading assistant)'], 'value': 0, 'top_word': 'lara (learning and reading assistant)'}, {'words': ['crowdsourcing techniques'], 'value': 0, 'top_word': 'crowdsourcing techniques'}, {'words': ['lara'], 'value': 0, 'top_word': 'lara'}]\n",
      "100\n",
      "aa:::: ['eye-tracking']\n",
      "[{'words': ['eye tracking studies'], 'value': 0, 'top_word': 'eye tracking studies'}, {'words': ['reading difficulties'], 'value': 0, 'top_word': 'reading difficulties'}]\n",
      "aa:::: ['lexical properties', ' parallel gaze data']\n",
      "[{'words': ['online processing techniques'], 'value': 0, 'top_word': 'online processing techniques'}]\n",
      "Effects of Lexical Properties on Viewing Time per Word in Autistic and Neurotypical Readers. Eye tracking studies from the past few decades have shaped the way we think of word complexity and cognitive load: words that are long, rare and ambiguous are more difficult to read. However, online processing techniques have been scarcely applied to investigating the reading difficulties of people with autism and what vocabulary is challenging for them. We present parallel gaze data obtained from adult readers with autism and a control group of neurotypical readers and show that the former required higher cognitive effort to comprehend the texts as evidenced by three gaze-based measures. We divide all words into four classes based on their viewing times for both groups and investigate the relationship between longer viewing times and word length, word frequency, and four cognitively-based measures (word concreteness, familiarity, age of acquisition and imagability).\n",
      "['lexical properties', ' parallel gaze data']\n",
      "[{'words': ['online processing techniques'], 'value': 0, 'top_word': 'online processing techniques'}]\n",
      "44\n",
      "aa:::: ['extracting symptoms']\n",
      "[{'words': ['extracting symptoms'], 'value': 0, 'top_word': 'extracting symptoms'}, {'words': ['medical providers'], 'value': 0, 'top_word': 'medical providers'}]\n",
      "aa:::: ['curriculum learning', 'sequence-to-sequence', 'hierarchical span-attribute tagging (sa-t) model']\n",
      "[{'words': ['deep learning approaches'], 'value': 0, 'top_word': 'deep learning approaches'}, {'words': ['hierarchical span - attribute tagging (sa - t) model'], 'value': 0, 'top_word': 'hierarchical span - attribute tagging (sa - t) model'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}, {'words': ['sequence - to - sequence model'], 'value': 0, 'top_word': 'sequence - to - sequence model'}]\n",
      "Extracting Symptoms and their Status from Clinical Conversations. This paper describes novel models tailored for a new application, that of extracting the symptoms mentioned in clinical conversations along with their status. Lack of any publicly available corpus in this privacy-sensitive domain led us to develop our own corpus, consisting of about 3K conversations annotated by professional medical scribes. We propose two novel deep learning approaches to infer the symptom names and their status: (1) a new hierarchical span-attribute tagging (SA-T) model, trained using curriculum learning, and (2) a variant of sequence-to-sequence model which decodes the symptoms and their status from a few speaker turns within a sliding window over the conversation. This task stems from a realistic application of assisting medical providers in capturing symptoms mentioned by patients from their clinical conversations. To reflect this application, we define multiple metrics. From inter-rater agreement, we find that the task is inherently difficult. We conduct comprehensive evaluations on several contrasting conditions and observe that the performance of the models range from an F-score of 0.5 to 0.8 depending on the condition. Our analysis not only reveals the inherent challenges of the task, but also provides useful directions to improve the models.\n",
      "['curriculum learning', 'sequence-to-sequence', 'hierarchical span-attribute tagging (sa-t) model']\n",
      "[{'words': ['deep learning approaches'], 'value': 0, 'top_word': 'deep learning approaches'}, {'words': ['hierarchical span - attribute tagging (sa - t) model'], 'value': 0, 'top_word': 'hierarchical span - attribute tagging (sa - t) model'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}, {'words': ['sequence - to - sequence model'], 'value': 0, 'top_word': 'sequence - to - sequence model'}]\n",
      "100\n",
      "aa:::: ['span detection', 'classification']\n",
      "[{'words': ['classification tasks', 'classification tasks'], 'value': 0.2862141579, 'top_word': 'classification tasks'}, {'words': ['span detection task', 'classification and span detection'], 'value': 0.3522171974, 'top_word': 'span detection task'}]\n",
      "aa:::: ['pre-trained transformer', 'classifier ensembling']\n",
      "[{'words': ['transformer based models'], 'value': 0.2669769824, 'top_word': 'transformer based models'}]\n",
      "Pre-trained Transformer-based Classification and Span Detection Models for Social Media Health Applications. This paper describes our approach for six classification tasks (Tasks 1a, 3a, 3b, 4 and 5) and one span detection task (Task 1b) from the Social Media Mining for Health (SMM4H) 2021 shared tasks. We developed two separate systems for classification and span detection, both based on pre-trained Transformer-based models. In addition, we applied oversampling and classifier ensembling in the classification tasks. The results of our submissions are over the median scores in all tasks except for Task 1a. Furthermore, our model achieved first place in Task 4 and obtained a 7% higher F 1-score than the median in Task 1b.\n",
      "['pre-trained transformer', 'classifier ensembling']\n",
      "[{'words': ['transformer based models'], 'value': 0.2669769824, 'top_word': 'transformer based models'}]\n",
      "48\n",
      "aa:::: ['question answering']\n",
      "[{'words': ['question answering', 'answering', 'question answering', 'question answering'], 'value': 0.7436277717, 'top_word': 'question answering'}]\n",
      "aa:::: ['question answering system']\n",
      "[{'words': ['open - domain techniques'], 'value': 0, 'top_word': 'open - domain techniques'}, {'words': ['question answering system'], 'value': 0, 'top_word': 'question answering system'}]\n",
      "Question Answering in the Biomedical Domain. Question answering techniques have mainly been investigated in open domains. However, there are particular challenges in extending these open-domain techniques to extend into the biomedical domain. Question answering focusing on patients is less studied. We find that there are some challenges in patient question answering such as limited annotated data, lexical gap and quality of answer spans. We aim to address some of these gaps by extending and developing upon the literature to design a question answering system that can decide on the most appropriate answers for patients attempting to self-diagnose while including the ability to abstain from answering when confidence is low.\n",
      "['question answering system']\n",
      "[{'words': ['open - domain techniques'], 'value': 0, 'top_word': 'open - domain techniques'}, {'words': ['question answering system'], 'value': 0, 'top_word': 'question answering system'}]\n",
      "100\n",
      "aa:::: ['sign language recognition']\n",
      "[{'words': ['unsupervised term discovery', 'unsupervised spoken term discovery', 'spoken term discovery'], 'value': 0.25085994100000003, 'top_word': 'unsupervised spoken term discovery'}, {'words': ['continuous sign language', 'sign language recognition', 'slr'], 'value': 0.425698638, 'top_word': 'slr'}]\n",
      "aa:::: ['unsupervised term discovery']\n",
      "[{'words': ['unsupervised learning'], 'value': 0, 'top_word': 'unsupervised learning'}, {'words': ['spoken term discovery'], 'value': 0, 'top_word': 'spoken term discovery'}, {'words': ['hand shape and pose features'], 'value': 0, 'top_word': 'hand shape and pose features'}]\n",
      "Unsupervised Term Discovery for Continuous Sign Language. Most of the sign language recognition (SLR) systems rely on supervision for training and available annotated sign language resources are scarce due to the difficulties of manual labeling. Unsupervised discovery of lexical units would facilitate the annotation process and thus lead to better SLR systems. Inspired by the unsupervised spoken term discovery in speech processing field, we investigate whether a similar approach can be applied in sign language to discover repeating lexical units. We adapt an algorithm that is designed for spoken term discovery by using hand shape and pose features instead of speech features. The experiments are run on a large scale continuous sign corpus and the performance is evaluated using gloss level annotations. This work introduces a new task for sign language processing that has not been addressed before.\n",
      "['unsupervised term discovery']\n",
      "[{'words': ['unsupervised learning'], 'value': 0, 'top_word': 'unsupervised learning'}, {'words': ['spoken term discovery'], 'value': 0, 'top_word': 'spoken term discovery'}, {'words': ['hand shape and pose features'], 'value': 0, 'top_word': 'hand shape and pose features'}]\n",
      "81\n",
      "aa:::: ['relevance quality in product search']\n",
      "[{'words': ['product search'], 'value': 0, 'top_word': 'product search'}, {'words': ['high - precision query - product semantic similarity'], 'value': 0, 'top_word': 'high - precision query - product semantic similarity'}, {'words': ['product search'], 'value': 0, 'top_word': 'product search'}, {'words': ['e - commerce system'], 'value': 0, 'top_word': 'e - commerce system'}, {'words': ['semantic similarity'], 'value': 0, 'top_word': 'semantic similarity'}, {'words': ['ranking applications'], 'value': 0, 'top_word': 'ranking applications'}, {'words': ['re - ranking feature'], 'value': 0, 'top_word': 're - ranking feature'}, {'words': ['optimization'], 'value': 0, 'top_word': 'optimization'}, {'words': ['e - commerce setting'], 'value': 0, 'top_word': 'e - commerce setting'}, {'words': ['ranking'], 'value': 0, 'top_word': 'ranking'}]\n",
      "aa:::: ['bert']\n",
      "[{'words': ['high - precision crossencoder bert model'], 'value': 0, 'top_word': 'high - precision crossencoder bert model'}, {'words': ['high - precision models'], 'value': 0, 'top_word': 'high - precision models'}]\n",
      "Improving Relevance Quality in Product Search using High-Precision Query-Product Semantic Similarity. Ensuring relevance quality in product search is a critical task as it impacts the customer's ability to find intended products in the short-term as well as the general perception and trust of the e-commerce system in the long term. In this work we leverage a high-precision crossencoder BERT model for semantic similarity between customer query and products and survey its effectiveness for three ranking applications where offline-generated scores could be used: (1) as an offline metric for estimating relevance quality impact, (2) as a re-ranking feature covering head/torso queries, and (3) as a training objective for optimization. We present results on effectiveness of this strategy for the large e-commerce setting, which has general applicability for choice of other high-precision models and tasks in ranking.\n",
      "['bert']\n",
      "[{'words': ['high - precision crossencoder bert model'], 'value': 0, 'top_word': 'high - precision crossencoder bert model'}, {'words': ['high - precision models'], 'value': 0, 'top_word': 'high - precision models'}]\n",
      "100\n",
      "aa:::: ['spoken language systems']\n",
      "[{'words': ['next - generation spoken language systems'], 'value': 0, 'top_word': 'next - generation spoken language systems'}]\n",
      "aa:::: ['guidelines']\n",
      "[{'words': ['tokenization'], 'value': 0, 'top_word': 'tokenization'}, {'words': ['part-of-speech tagging'], 'value': 0, 'top_word': 'part-of-speech tagging'}, {'words': ['parsing'], 'value': 0, 'top_word': 'parsing'}]\n",
      "Initial Draft Guidelines for the Development of the Next-Generation Spoken Language Systems Speech Research Database. To best serve the strategic needs of the DARPA SLS research program by creating the next-generation speech database(s).\n",
      "['guidelines']\n",
      "[{'words': ['tokenization'], 'value': 0, 'top_word': 'tokenization'}, {'words': ['part-of-speech tagging'], 'value': 0, 'top_word': 'part-of-speech tagging'}, {'words': ['parsing'], 'value': 0, 'top_word': 'parsing'}]\n",
      "32\n",
      "aa:::: ['machine translation', 'information retrieval']\n",
      "[{'words': ['machine translation', 'translation'], 'value': 0.3741724193, 'top_word': 'translation'}]\n",
      "aa:::: ['surveys', 'questionnaires']\n",
      "[{'words': ['medar'], 'value': 0, 'top_word': 'medar'}, {'words': ['medar'], 'value': 0, 'top_word': 'medar'}, {'words': ['nemlar network'], 'value': 0, 'top_word': 'nemlar network'}]\n",
      "MEDAR: Collaboration between European and Mediterranean Arabic Partners to Support the Development of Language Technology for Arabic. After the successful completion of the NEMLAR project 2003-2005, a new opportunity for a project was opened by the European Commission, and a group of largely the same partners is now executing the MEDAR project. MEDAR will be updating the surveys and BLARK for Arabic already made, and will then focus on machine translation (and other tools for translation) and information retrieval with a focus on language resources, tools and evaluation for these applications. A very important part of the MEDAR project is to reinforce and extend the NEMLAR network and to create a cooperation roadmap for Human Language Technologies for Arabic. It is expected that the cooperation roadmap will attract wide attention from other parties and that it can help create a larger platform for collaborative projects. Finally, the project will focus on dissemination of knowledge about existing resources and tools, as well as actors and activities; this will happen through newsletter, website and an international conference which will follow up on the Cairo conference of 2004. Dissemination to user communities will also be important, e.g. through participation in translators' conferences. The goal of these activities is to create a stronger and lasting collaboration between EU countries and Arabic speaking countries.\n",
      "['surveys', 'questionnaires']\n",
      "[{'words': ['medar'], 'value': 0, 'top_word': 'medar'}, {'words': ['medar'], 'value': 0, 'top_word': 'medar'}, {'words': ['nemlar network'], 'value': 0, 'top_word': 'nemlar network'}]\n",
      "40\n",
      "aa:::: ['exploring stylistic variation']\n",
      "[{'words': ['regression task'], 'value': 0, 'top_word': 'regression task'}, {'words': ['social media'], 'value': 0, 'top_word': 'social media'}]\n",
      "aa:::: ['regression', 'stylistic features']\n",
      "[{'words': ['nlp tools'], 'value': 0, 'top_word': 'nlp tools'}]\n",
      "Exploring Stylistic Variation with Age and Income on Twitter. Writing style allows NLP tools to adjust to the traits of an author. In this paper, we explore the relation between stylistic and syntactic features and authors' age and income. We confirm our hypothesis that for numerous feature types writing style is predictive of income even beyond age. We analyze the predictive power of writing style features in a regression task on two data sets of around 5,000 Twitter users each. Additionally, we use our validated features to study daily variations in writing style of users from distinct income groups. Temporal stylistic patterns not only provide novel psychological insight into user behavior, but are useful for future research and applications in social media.\n",
      "['regression', 'stylistic features']\n",
      "[{'words': ['nlp tools'], 'value': 0, 'top_word': 'nlp tools'}]\n",
      "33\n",
      "aa:::: ['fake news detection']\n",
      "[{'words': ['vietnamese fake news detection', 'fake news detection on social network sites'], 'value': 0.5039985180000001, 'top_word': 'vietnamese fake news detection'}]\n",
      "aa:::: ['phobert embeddings', 'ensemble method']\n",
      "[{'words': ['phobert embeddings'], 'value': 0, 'top_word': 'phobert embeddings'}, {'words': ['ensemble method'], 'value': 0, 'top_word': 'ensemble method'}, {'words': ['phobert'], 'value': 0, 'top_word': 'phobert'}]\n",
      "ReINTEL Challenge 2020: Vietnamese Fake News Detection usingEnsemble Model with PhoBERT embeddings. Along with the increasing traffic of social networks in Vietnam in recent years, the number of unreliable news has also grown rapidly. As we make decisions based on the information we come across daily, fake news, depending on the severity of the matter, can lead to disastrous consequences. This paper presents our approach for the Fake News Detection on Social Network Sites (SNSs), using an ensemble method with linguistic features extracted using PhoBERT (Nguyen and Nguyen, 2020). Our method achieves AUC score of 0.9521 and got 1 st place on the private test at the 7 th International Workshop on Vietnamese Language and Speech Processing (VLSP). For reproducing the result, the code can be found at https://gitlab.com/thuan.\n",
      "['phobert embeddings', 'ensemble method']\n",
      "[{'words': ['phobert embeddings'], 'value': 0, 'top_word': 'phobert embeddings'}, {'words': ['ensemble method'], 'value': 0, 'top_word': 'ensemble method'}, {'words': ['phobert'], 'value': 0, 'top_word': 'phobert'}]\n",
      "100\n",
      "aa:::: ['analysis of propaganda techniques']\n",
      "[{'words': ['analysis of propaganda techniques'], 'value': 0, 'top_word': 'analysis of propaganda techniques'}, {'words': ['factchecking and disinformation detection'], 'value': 0, 'top_word': 'factchecking and disinformation detection'}, {'words': ['media literacy'], 'value': 0, 'top_word': 'media literacy'}, {'words': ['critical thinking'], 'value': 0, 'top_word': 'critical thinking'}, {'words': ['disinformation campaigns'], 'value': 0, 'top_word': 'disinformation campaigns'}]\n",
      "aa:::: ['propaganda persuasion techniques analyzer']\n",
      "[{'words': ['prta', 'prta propaganda persuasion techniques analyzer'], 'value': 0.2848195657, 'top_word': 'prta'}]\n",
      "Prta: A System to Support the Analysis of Propaganda Techniques in the News. Recent events, such as the 2016 US Presidential Campaign, Brexit and the COVID-19 \"infodemic\", have brought into the spotlight the dangers of online disinformation. There has been a lot of research focusing on factchecking and disinformation detection. However, little attention has been paid to the specific rhetorical and psychological techniques used to convey propaganda messages. Revealing the use of such techniques can help promote media literacy and critical thinking, and eventually contribute to limiting the impact of \"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion Techniques Analyzer) allows users to explore the articles crawled on a regular basis by highlighting the spans in which propaganda techniques occur and to compare them on the basis of their use of propaganda techniques. The system further reports statistics about the use of such techniques, overall and over time, or according to filtering criteria specified by the user based on time interval, keywords, and/or political orientation of the media. Moreover, it allows users to analyze any text or URL through a dedicated interface or via an API. The system is available online: https://www.tanbih.org/prta.\n",
      "['propaganda persuasion techniques analyzer']\n",
      "[{'words': ['prta', 'prta propaganda persuasion techniques analyzer'], 'value': 0.2848195657, 'top_word': 'prta'}]\n",
      "100\n",
      "aa:::: ['conversation systems']\n",
      "[{'words': ['conversation initiation', 'conversation initiator', 'conversation initiation'], 'value': 0.17704412220000001, 'top_word': 'conversation initiation'}]\n",
      "aa:::: ['information retrieval', 'generation models']\n",
      "[{'words': ['conversation initiator'], 'value': 0, 'top_word': 'conversation initiator'}, {'words': ['conversation systems'], 'value': 0, 'top_word': 'conversation systems'}, {'words': ['conversation systems'], 'value': 0, 'top_word': 'conversation systems'}, {'words': ['information retrieval'], 'value': 0, 'top_word': 'information retrieval'}, {'words': ['generation based models'], 'value': 0, 'top_word': 'generation based models'}]\n",
      "Conversation Initiation by Diverse News Contents Introduction. In our everyday chitchat , there is a conversation initiator, who proactively casts an initial utterance to start chatting. However, most existing conversation systems cannot play this role. Previous studies on conversation systems assume that the user always initiates conversation, and have placed emphasis on how to respond to the given user's utterance. As a result, existing conversation systems become passive. Namely they continue waiting until being spoken to by the users. In this paper, we consider the system as a conversation initiator and propose a novel task of generating the initial utterance in open-domain non-task-oriented conversation. Here, in order not to make users bored, it is necessary to generate diverse utterances to initiate conversation without relying on boilerplate utterances like greetings. To this end, we propose to generate initial utterance by summarizing and chatting about news articles, which provide fresh and various contents everyday. To address the lack of the training data for this task, we constructed a novel largescale dataset through crowd-sourcing. We also analyzed the dataset in detail to examine how humans initiate conversations (the dataset will be released to facilitate future research activities). We present several approaches to conversation initiation including information retrieval based and generation based models. Experimental results showed that the proposed models trained on our dataset performed reasonably well and outperformed baselines that utilize automatically collected training data in both automatic and manual evaluation. * This work was done during research internship at Yahoo Japan Corporation. 1 \"Conversation\" in this paper refers to open-domain nontask-oriented conversations and chitchat .\n",
      "['information retrieval', 'generation models']\n",
      "[{'words': ['conversation initiator'], 'value': 0, 'top_word': 'conversation initiator'}, {'words': ['conversation systems'], 'value': 0, 'top_word': 'conversation systems'}, {'words': ['conversation systems'], 'value': 0, 'top_word': 'conversation systems'}, {'words': ['information retrieval'], 'value': 0, 'top_word': 'information retrieval'}, {'words': ['generation based models'], 'value': 0, 'top_word': 'generation based models'}]\n",
      "100\n",
      "aa:::: ['categorizing offensive language']\n",
      "[{'words': ['automatically identifying offensive language', 'offensive classification'], 'value': 0.4135538936, 'top_word': 'offensive classification'}, {'words': ['categorizing offensive language in social networks'], 'value': 0.4670377672, 'top_word': 'categorizing offensive language in social networks'}]\n",
      "aa:::: ['hierarchical attention capsule network', 'integrated gradients']\n",
      "[{'words': ['hierarchical attention', 'hierarchical attention capsule network'], 'value': 0.4923342392, 'top_word': 'hierarchical attention capsule network'}, {'words': ['capsule system'], 'value': 0.2974184453, 'top_word': 'capsule system'}]\n",
      "Categorizing Offensive Language in Social Networks: A Chinese Corpus, Systems and an Explainable Tool. Recently, more and more data have been generated in the online world, filled with offensive language such as threats, swear words or straightforward insults. It is disgraceful for a progressive society, and then the question arises on how language resources and technologies can cope with this challenge. However, previous work only analyzes the problem as a whole but fails to detect particular types of offensive content in a more fine-grained way, mainly because of the lack of annotated data. In this work, we present a densely annotated data-set COLA (Categorizing Offensive LAnguage), consists of fine-grained insulting language, antisocial language and illegal language. We study different strategies for automatically identifying offensive language on COLA data. Further, we design a capsule system with hierarchical attention to aggregate and fully utilize information, which obtains a state-of-the-art result. Results from experiments prove that our hierarchical attention capsule network (HACN) performs significantly better than existing methods in offensive classification with the precision of 94.37% and recall of 95.28%. We also explain what our model has learned with an explanation tool called Integrated Gradients. Meanwhile, our system's processing speed can handle each sentence in 10msec, suggesting the potential for efficient deployment in real situations.\n",
      "['hierarchical attention capsule network', 'integrated gradients']\n",
      "[{'words': ['hierarchical attention', 'hierarchical attention capsule network'], 'value': 0.4923342392, 'top_word': 'hierarchical attention capsule network'}, {'words': ['capsule system'], 'value': 0.2974184453, 'top_word': 'capsule system'}]\n",
      "100\n",
      "aa:::: ['question answering', 'domain adaptaion', 'transfer learning']\n",
      "[{'words': ['boosting low resource biomedical qa', 'biomedical question answering'], 'value': 0.5877873451, 'top_word': 'biomedical question answering'}]\n",
      "aa:::: ['masked language models', 'language models', 'entity-aware masking']\n",
      "[{'words': ['entity aware masking strategies', 'biomedical entity aware masking'], 'value': 0.5193934441, 'top_word': 'biomedical entity aware masking'}]\n",
      "Boosting Low-Resource Biomedical QA via Entity-Aware Masking Strategies. Biomedical question-answering (QA) has gained increased attention for its capability to provide users with high-quality information from a vast scientific literature. Although an increasing number of biomedical QA datasets has been recently made available, those resources are still rather limited and expensive to produce. Transfer learning via pre-trained language models (LMs) has been shown as a promising approach to leverage existing general-purpose knowledge. However, finetuning these large models can be costly and time consuming, often yielding limited benefits when adapting to specific themes of specialised domains, such as the COVID-19 literature. To bootstrap further their domain adaptation, we propose a simple yet unexplored approach, which we call biomedical entity-aware masking (BEM). We encourage masked language models to learn entity-centric knowledge based on the pivotal entities characterizing the domain at hand, and employ those entities to drive the LM fine-tuning. The resulting strategy is a downstream process applicable to a wide variety of masked LMs, not requiring additional memory or components in the neural architectures. Experimental results show performance on par with state-of-the-art models on several biomedical QA datasets.\n",
      "['masked language models', 'language models', 'entity-aware masking']\n",
      "[{'words': ['entity aware masking strategies', 'biomedical entity aware masking'], 'value': 0.5193934441, 'top_word': 'biomedical entity aware masking'}]\n",
      "95\n",
      "aa:::: ['statistical modeling']\n",
      "[{'words': ['linguistics'], 'value': 0, 'top_word': 'linguistics'}]\n",
      "aa:::: ['grammatical analysis', 'working-memory-based processing']\n",
      "[{'words': ['statistical modeling'], 'value': 0, 'top_word': 'statistical modeling'}, {'words': ['working - memory capacity'], 'value': 0, 'top_word': 'working - memory capacity'}, {'words': ['grammatical analysis;'], 'value': 0, 'top_word': 'grammatical analysis;'}, {'words': ['working - memory (wm) - based processing analysis'], 'value': 0, 'top_word': 'working - memory (wm) - based processing analysis'}, {'words': ['wm - based processing analysis'], 'value': 0, 'top_word': 'wm - based processing analysis'}, {'words': ['wm'], 'value': 0, 'top_word': 'wm'}, {'words': ['l2 learners'], 'value': 0, 'top_word': 'l2 learners'}]\n",
      "A Statistical Modeling of the Correlation between Island Effects and Working-memory Capacity for L2 Learners. The cause of island effects has evoked considerable debate within syntax and other fields of linguistics. The two competing approaches stand out: the grammatical analysis; and the working-memory (WM)-based processing analysis. In this paper we report three experiments designed to test one of the premises of the WM-based processing analysis: that the strength of island effects should vary as a function of individual differences in WM capacity. The results show that island effects present even for L2 learners are more likely attributed to grammatical constraints than to limited processing resources.\n",
      "['grammatical analysis', 'working-memory-based processing']\n",
      "[{'words': ['statistical modeling'], 'value': 0, 'top_word': 'statistical modeling'}, {'words': ['working - memory capacity'], 'value': 0, 'top_word': 'working - memory capacity'}, {'words': ['grammatical analysis;'], 'value': 0, 'top_word': 'grammatical analysis;'}, {'words': ['working - memory (wm) - based processing analysis'], 'value': 0, 'top_word': 'working - memory (wm) - based processing analysis'}, {'words': ['wm - based processing analysis'], 'value': 0, 'top_word': 'wm - based processing analysis'}, {'words': ['wm'], 'value': 0, 'top_word': 'wm'}, {'words': ['l2 learners'], 'value': 0, 'top_word': 'l2 learners'}]\n",
      "100\n",
      "aa:::: ['online abuse detection']\n",
      "[{'words': ['online abuse and cyberbullying detection'], 'value': 0.5617464185000001, 'top_word': 'online abuse and cyberbullying detection'}]\n",
      "aa:::: ['transformers', 'dataset']\n",
      "[{'words': ['transformer - based deep learning models'], 'value': 0, 'top_word': 'transformer - based deep learning models'}]\n",
      "A Large-Scale English Multi-Label Twitter Dataset for Cyberbullying and Online Abuse Detection. In this paper, we introduce a new English Twitter-based dataset for online abuse and cyberbullying detection. Comprising 62,587 tweets, this dataset was sourced from Twitter using specific query terms designed to retrieve tweets with high probabilities of various forms of bullying and offensive content, including insult, profanity, sarcasm, threat, porn and exclusion. Analysis performed on the dataset confirmed common cyberbullying themes reported by other studies and revealed interesting relationships between the classes. The dataset was used to train a number of transformer-based deep learning models returning impressive results.\n",
      "['transformers', 'dataset']\n",
      "[{'words': ['transformer - based deep learning models'], 'value': 0, 'top_word': 'transformer - based deep learning models'}]\n",
      "92\n",
      "aa:::: ['corpus']\n",
      "[{'words': ['annotation procedure'], 'value': 0, 'top_word': 'annotation procedure'}]\n",
      "aa:::: ['multi-layed annotation', 'annotation procedure']\n",
      "[{'words': ['syntax'], 'value': 0, 'top_word': 'syntax'}, {'words': ['semantics'], 'value': 0, 'top_word': 'semantics'}, {'words': ['co-reference'], 'value': 0, 'top_word': 'co-reference'}, {'words': ['events'], 'value': 0, 'top_word': 'events'}, {'words': ['time expressions'], 'value': 0, 'top_word': 'time expressions'}, {'words': ['temporal relationships'], 'value': 0, 'top_word': 'temporal relationships'}, {'words': ['semantic roles'], 'value': 0, 'top_word': 'semantic roles'}, {'words': ['word senses'], 'value': 0, 'top_word': 'word senses'}]\n",
      "The N2 corpus: A semantically annotated collection of Islamist extremist stories. We describe the N2 (Narrative Networks) Corpus, a new language resource. The corpus is unique in three important ways. First, every text in the corpus is a story, which is in contrast to other language resources that may contain stories or story-like texts, but are not specifically curated to contain only stories. Second, the unifying theme of the corpus is material relevant to Islamist Extremists, having been produced by or often referenced by them. Third, every text in the corpus has been annotated for 14 layers of syntax and semantics, including: referring expressions and co-reference; events, time expressions, and temporal relationships; semantic roles; and word senses. In cases where analyzers were not available to do high-quality automatic annotations, layers were manually doubleannotated and adjudicated by trained annotators. The corpus comprises 100 texts and 42,480 words. Most of the texts were originally in Arabic but all are provided in English translation. We explain the motivation for constructing the corpus, the process for selecting the texts, the detailed contents of the corpus itself, the rationale behind the choice of annotation layers, and the annotation procedure.\n",
      "['multi-layed annotation', 'annotation procedure']\n",
      "[{'words': ['syntax'], 'value': 0, 'top_word': 'syntax'}, {'words': ['semantics'], 'value': 0, 'top_word': 'semantics'}, {'words': ['co-reference'], 'value': 0, 'top_word': 'co-reference'}, {'words': ['events'], 'value': 0, 'top_word': 'events'}, {'words': ['time expressions'], 'value': 0, 'top_word': 'time expressions'}, {'words': ['temporal relationships'], 'value': 0, 'top_word': 'temporal relationships'}, {'words': ['semantic roles'], 'value': 0, 'top_word': 'semantic roles'}, {'words': ['word senses'], 'value': 0, 'top_word': 'word senses'}]\n",
      "50\n",
      "aa:::: ['cognitive distortion detection']\n",
      "[{'words': ['detecting cognitive distortions'], 'value': 0, 'top_word': 'detecting cognitive distortions'}, {'words': ['cognitive behavioral therapy'], 'value': 0, 'top_word': 'cognitive behavioral therapy'}]\n",
      "aa:::: ['pretrained sentence-bert embeddings', 'svm classifier']\n",
      "[{'words': ['natural language processing'], 'value': 0, 'top_word': 'natural language processing'}, {'words': ['classification algorithms'], 'value': 0, 'top_word': 'classification algorithms'}, {'words': ['svm classifier'], 'value': 0, 'top_word': 'svm classifier'}]\n",
      "Detecting Cognitive Distortions from Patient-Therapist Interactions. An important part of Cognitive Behavioral Therapy (CBT) is to recognize and restructure certain negative thinking patterns that are also known as cognitive distortions. This project aims to detect these distortions using natural language processing. We compare and contrast different types of linguistic features as well as different classification algorithms and explore the limitations of applying these techniques on a small dataset. We find that pretrained Sentence-BERT embeddings to train an SVM classifier yields the best results with an F1-score of 0.79. Lastly, we discuss how this work provides insights into the types of linguistic features that are inherent in cognitive distortions.\n",
      "['pretrained sentence-bert embeddings', 'svm classifier']\n",
      "[{'words': ['natural language processing'], 'value': 0, 'top_word': 'natural language processing'}, {'words': ['classification algorithms'], 'value': 0, 'top_word': 'classification algorithms'}, {'words': ['svm classifier'], 'value': 0, 'top_word': 'svm classifier'}]\n",
      "100\n",
      "aa:::: ['assessing dataset generalizability', 'hateful memes challenge', 'hateful meme detection']\n",
      "[{'words': ['hateful meme detection', 'detecting real world hate'], 'value': 0.39759027960000004, 'top_word': 'detecting real world hate'}]\n",
      "aa:::: ['ocr', 'multimodal models']\n",
      "[{'words': ['machine learning systems'], 'value': 0, 'top_word': 'machine learning systems'}, {'words': ['ocr'], 'value': 0, 'top_word': 'ocr'}, {'words': ['multimodal models'], 'value': 0, 'top_word': 'multimodal models'}]\n",
      "Memes in the Wild: Assessing the Generalizability of the Hateful Memes Challenge Dataset. Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text-and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to 'memes in the wild'. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that memes in the wild differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than 'traditional memes', including screenshots of conversations or text on a plain background. This paper thus serves as a reality check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\n",
      "['ocr', 'multimodal models']\n",
      "[{'words': ['machine learning systems'], 'value': 0, 'top_word': 'machine learning systems'}, {'words': ['ocr'], 'value': 0, 'top_word': 'ocr'}, {'words': ['multimodal models'], 'value': 0, 'top_word': 'multimodal models'}]\n",
      "100\n",
      "aa:::: ['terminological database']\n",
      "[{'words': ['encoding terms'], 'value': 0, 'top_word': 'encoding terms'}, {'words': ['maritime terminological database'], 'value': 0, 'top_word': 'maritime terminological database'}, {'words': ['term selection and extraction'], 'value': 0, 'top_word': 'term selection and extraction'}, {'words': ['evaluating synsets;'], 'value': 0, 'top_word': 'evaluating synsets;'}, {'words': ['exporting synsets'], 'value': 0, 'top_word': 'exporting synsets'}, {'words': ['meteorology'], 'value': 0, 'top_word': 'meteorology'}]\n",
      "aa:::: ['encoding terms']\n",
      "[{'words': ['eurowordnet/italwordnet model'], 'value': 0, 'top_word': 'eurowordnet/italwordnet model'}, {'words': ['iwn model'], 'value': 0, 'top_word': 'iwn model'}, {'words': ['hyperonymy/hyponymy relation'], 'value': 0, 'top_word': 'hyperonymy/hyponymy relation'}]\n",
      "Encoding Terms from a Scientific Domain in a Terminological Database: Methodology and Criteria. This paper reports on the main phases of a research which aims at enhancing a maritime terminological database by means of a set of terms belonging to meteorology. The structure of the terminological database, according to EuroWordNet/ItalWordNet model is described; the criteria used to build corpora of specialized texts are explained as well as the use of the corpora as source for term selection and extraction. The contribution of the semantic databases is taken into account: on the one hand, the most recent version of the Princeton WordNet has been exploited as reference for comparing and evaluating synsets; on the other hand, the Italian WordNet has been employed as source for exporting synsets to be coded in the terminological resource. The set of semantic relations useful to codify new terms belonging to the discipline of meteorology is examined, revising the semantic relations provided by the IWN model, introducing new relations which are more suitably tailored to specific requirements either scientific or pragmatic. The need for a particular relation is highlighted to represent the mental association which is made when a term intuitively recalls another term, but they are neither synonyms nor connected by means of a hyperonymy/hyponymy relation.\n",
      "['encoding terms']\n",
      "[{'words': ['eurowordnet/italwordnet model'], 'value': 0, 'top_word': 'eurowordnet/italwordnet model'}, {'words': ['iwn model'], 'value': 0, 'top_word': 'iwn model'}, {'words': ['hyperonymy/hyponymy relation'], 'value': 0, 'top_word': 'hyperonymy/hyponymy relation'}]\n",
      "44\n",
      "aa:::: ['intellectual access to large oral history collections', 'topic classification', 'boundary detection']\n",
      "[{'words': ['malach project'], 'value': 0, 'top_word': 'malach project'}, {'words': ['interactive search'], 'value': 0, 'top_word': 'interactive search'}, {'words': ['automated clustering'], 'value': 0, 'top_word': 'automated clustering'}, {'words': ['boundary detection'], 'value': 0, 'top_word': 'boundary detection'}, {'words': ['topic classification tasks'], 'value': 0, 'top_word': 'topic classification tasks'}]\n",
      "aa:::: ['automated clustering', 'automatic speech recognition techniques']\n",
      "[{'words': ['malach project'], 'value': 0, 'top_word': 'malach project'}, {'words': ['machine learning techniques'], 'value': 0, 'top_word': 'machine learning techniques'}, {'words': ['automatic speech recognition techniques'], 'value': 0, 'top_word': 'automatic speech recognition techniques'}]\n",
      "Invited Talk: Lessons from the MALACH Project: Applying New Technologies to Improve Intellectual Access to Large Oral History Collections. In this talk I will describe the goals of the MALACH project (Multilingual Access to Large Spoken Archives) and our research results. I'll begin by describing the unique characteristics of the oral history collection that we used, in which Holocaust survivors, witnesses and rescuers were interviewed in several languages. Each interview has been digitized and extensively catalogued by subject matter experts, thus producing a remarkably rich collection for the application of machine learning techniques. Automatic speech recognition techniques originally developed for the domain of conversational telephone speech were adapted to process these materials with word error rates that are adequate to provide useful features to support interactive search and automated clustering, boundary detection, and topic classification tasks. As I describe our results, I will focus particularly on the evaluation methods that that we have used to assess the potential utility of this technology. I'll conclude with some remarks about possible future directions for research on applying new technologies to improve intellectual access to oral history and other spoken word collections.\n",
      "['automated clustering', 'automatic speech recognition techniques']\n",
      "[{'words': ['malach project'], 'value': 0, 'top_word': 'malach project'}, {'words': ['machine learning techniques'], 'value': 0, 'top_word': 'machine learning techniques'}, {'words': ['automatic speech recognition techniques'], 'value': 0, 'top_word': 'automatic speech recognition techniques'}]\n",
      "100\n",
      "aa:::: ['contrastive analysis', 'typology driven estimation']\n",
      "[{'words': ['esl', 'esl', 'esl'], 'value': 0.6191312571, 'top_word': 'esl'}]\n",
      "aa:::: ['bootstrapping']\n",
      "[{'words': ['contrastive analysis', 'theory of contrastive analysis'], 'value': 0.1391729303, 'top_word': 'contrastive analysis'}]\n",
      "Contrastive Analysis with Predictive Power: Typology Driven Estimation of Grammatical Error Distributions in ESL. This work examines the impact of crosslinguistic transfer on grammatical errors in English as Second Language (ESL) texts. Using a computational framework that formalizes the theory of Contrastive Analysis (CA), we demonstrate that language specific error distributions in ESL writing can be predicted from the typological properties of the native language and their relation to the typology of English. Our typology driven model enables to obtain accurate estimates of such distributions without access to any ESL data for the target languages. Furthermore, we present a strategy for adjusting our method to low-resource languages that lack typological documentation using a bootstrapping approach which approximates native language typology from ESL texts. Finally, we show that our framework is instrumental for linguistic inquiry seeking to identify first language factors that contribute to a wide range of difficulties in second language acquisition.\n",
      "['bootstrapping']\n",
      "[{'words': ['contrastive analysis', 'theory of contrastive analysis'], 'value': 0.1391729303, 'top_word': 'contrastive analysis'}]\n",
      "38\n",
      "aa:::: ['offensive language identification']\n",
      "[{'words': ['detection of offensive content in social media', 'offensive speech detection'], 'value': 0.2880212888, 'top_word': 'offensive speech detection'}, {'words': ['classify offensive text', 'commentpost level classification tasks', 'five category classification task', 'six category classification tasks'], 'value': 0.2782902457, 'top_word': 'five category classification task'}, {'words': ['offensive language identification'], 'value': 0.5059614778, 'top_word': 'offensive language identification'}]\n",
      "aa:::: ['multilingual bert']\n",
      "[{'words': ['hub@dravidianlangtech - eacl2021'], 'value': 0, 'top_word': 'hub@dravidianlangtech - eacl2021'}, {'words': ['multilingual bert model'], 'value': 0, 'top_word': 'multilingual bert model'}, {'words': ['fine - tuning methods'], 'value': 0, 'top_word': 'fine - tuning methods'}]\n",
      "HUB@DravidianLangTech-EACL2021: Identify and Classify Offensive Text in Multilingual Code Mixing in Social Media. This paper introduces the system description of the HUB team participating in Dravidian-LangTech-EACL2021: Offensive Language Identification in Dravidian Languages. The theme of this shared task is the detection of offensive content in social media. Among the known tasks related to offensive speech detection, this is the first task to detect offensive comments posted in social media comments in the Dravidian language. The task organizer team provided us with the code-mixing task data set mainly composed of three different languages: Malayalam, Kannada, and Tamil. The tasks on the code mixed data in these three different languages can be seen as three different comment/post-level classification tasks. The task on the Malayalam data set is a five-category classification task, and the Kannada and Tamil language data sets are two six-category classification tasks. Based on our analysis of the task description and task data set, we chose to use the multilingual BERT model to complete this task. In this paper, we will discuss our fine-tuning methods, models, experiments, and results.\n",
      "['multilingual bert']\n",
      "[{'words': ['hub@dravidianlangtech - eacl2021'], 'value': 0, 'top_word': 'hub@dravidianlangtech - eacl2021'}, {'words': ['multilingual bert model'], 'value': 0, 'top_word': 'multilingual bert model'}, {'words': ['fine - tuning methods'], 'value': 0, 'top_word': 'fine - tuning methods'}]\n",
      "100\n",
      "aa:::: ['biomedical information extraction']\n",
      "[{'words': ['biomedical information extraction', 'information extraction'], 'value': 0.1767408028, 'top_word': 'biomedical information extraction'}]\n",
      "aa:::: ['dependency schemes', 'bioinfer', 'genia treebank']\n",
      "[{'words': ['stanford dependency scheme'], 'value': 0, 'top_word': 'stanford dependency scheme'}, {'words': ['syntactic annotation schemes'], 'value': 0, 'top_word': 'syntactic annotation schemes'}, {'words': ['parsers'], 'value': 0, 'top_word': 'parsers'}, {'words': ['corpora'], 'value': 0, 'top_word': 'corpora'}, {'words': ['stanford dependency scheme'], 'value': 0, 'top_word': 'stanford dependency scheme'}, {'words': ['unifying syntax formalism'], 'value': 0, 'top_word': 'unifying syntax formalism'}, {'words': ['link grammar'], 'value': 0, 'top_word': 'link grammar'}, {'words': ['stanford scheme'], 'value': 0, 'top_word': 'stanford scheme'}, {'words': ['bioinfer'], 'value': 0, 'top_word': 'bioinfer'}, {'words': ['parser'], 'value': 0, 'top_word': 'parser'}]\n",
      "On the unification of syntactic annotations under the Stanford dependency scheme: A case study on BioInfer and GENIA. Several incompatible syntactic annotation schemes are currently used by parsers and corpora in biomedical information extraction. The recently introduced Stanford dependency scheme has been suggested to be a suitable unifying syntax formalism. In this paper, we present a step towards such unification by creating a conversion from the Link Grammar to the Stanford scheme. Further, we create a version of the BioInfer corpus with syntactic annotation in this scheme. We present an application-oriented evaluation of the transformation and assess the suitability of the scheme and our conversion to the unification of the syntactic annotations of BioInfer and the GENIA Treebank. We find that a highly reliable conversion is both feasible to create and practical, increasing the applicability of both the parser and the corpus to information extraction.\n",
      "['dependency schemes', 'bioinfer', 'genia treebank']\n",
      "[{'words': ['stanford dependency scheme'], 'value': 0, 'top_word': 'stanford dependency scheme'}, {'words': ['syntactic annotation schemes'], 'value': 0, 'top_word': 'syntactic annotation schemes'}, {'words': ['parsers'], 'value': 0, 'top_word': 'parsers'}, {'words': ['corpora'], 'value': 0, 'top_word': 'corpora'}, {'words': ['stanford dependency scheme'], 'value': 0, 'top_word': 'stanford dependency scheme'}, {'words': ['unifying syntax formalism'], 'value': 0, 'top_word': 'unifying syntax formalism'}, {'words': ['link grammar'], 'value': 0, 'top_word': 'link grammar'}, {'words': ['stanford scheme'], 'value': 0, 'top_word': 'stanford scheme'}, {'words': ['bioinfer'], 'value': 0, 'top_word': 'bioinfer'}, {'words': ['parser'], 'value': 0, 'top_word': 'parser'}]\n",
      "100\n",
      "aa:::: ['event summarization']\n",
      "[{'words': ['event summarization', 'summarization'], 'value': 0.5334043801, 'top_word': 'summarization'}]\n",
      "aa:::: ['participant-based approach']\n",
      "[{'words': ['participant - based approach'], 'value': 0, 'top_word': 'participant - based approach'}, {'words': ['mixture model'], 'value': 0, 'top_word': 'mixture model'}, {'words': ['participantbased approach'], 'value': 0, 'top_word': 'participantbased approach'}]\n",
      "A Participant-based Approach for Event Summarization Using Twitter Streams. Twitter offers an unprecedented advantage on live reporting of the events happening around the world. However, summarizing the Twitter event has been a challenging task that was not fully explored in the past. In this paper, we propose a participant-based event summarization approach that \"zooms-in\" the Twitter event streams to the participant level, detects the important sub-events associated with each participant using a novel mixture model that combines the \"burstiness\" and \"cohesiveness\" properties of the event tweets, and generates the event summaries progressively. We evaluate the proposed approach on different event types. Results show that the participantbased approach can effectively capture the sub-events that have otherwise been shadowed by the long-tail of other dominant sub-events, yielding summaries with considerably better coverage than the state-of-the-art.\n",
      "['participant-based approach']\n",
      "[{'words': ['participant - based approach'], 'value': 0, 'top_word': 'participant - based approach'}, {'words': ['mixture model'], 'value': 0, 'top_word': 'mixture model'}, {'words': ['participantbased approach'], 'value': 0, 'top_word': 'participantbased approach'}]\n",
      "96\n",
      "aa:::: ['multi-domain dialog system']\n",
      "[{'words': ['multi - modal , multi - domain and socially - engaged conversational agents'], 'value': 0, 'top_word': 'multi - modal , multi - domain and socially - engaged conversational agents'}, {'words': ['multi - modal (incorporating speech'], 'value': 0, 'top_word': 'multi - modal (incorporating speech'}, {'words': ['vision)'], 'value': 0, 'top_word': 'vision)'}, {'words': ['emotion recognition'], 'value': 0, 'top_word': 'emotion recognition'}, {'words': ['engagement level prediction'], 'value': 0, 'top_word': 'engagement level prediction'}, {'words': ['backchanneling) conversational agents'], 'value': 0, 'top_word': 'backchanneling) conversational agents'}, {'words': ['machine learning researchers'], 'value': 0, 'top_word': 'machine learning researchers'}, {'words': ['linguists'], 'value': 0, 'top_word': 'linguists'}, {'words': ['collaborative research'], 'value': 0, 'top_word': 'collaborative research'}]\n",
      "aa:::: ['python']\n",
      "[{'words': ['adviser', 'adviser'], 'value': 0.7977035344000001, 'top_word': 'adviser'}]\n",
      "ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents. We present ADVISER 1-an open-source, multi-domain dialog system toolkit that enables the development of multi-modal (incorporating speech, text and vision), sociallyengaged (e.g. emotion recognition, engagement level prediction and backchanneling) conversational agents. The final Python-based implementation of our toolkit is flexible, easy to use, and easy to extend not only for technically experienced users, such as machine learning researchers, but also for less technically experienced users, such as linguists or cognitive scientists, thereby providing a flexible platform for collaborative research.\n",
      "['python']\n",
      "[{'words': ['adviser', 'adviser'], 'value': 0.7977035344000001, 'top_word': 'adviser'}]\n",
      "0\n",
      "aa:::: ['legal domain ontology']\n",
      "[{'words': ['legal nerc', 'wikipediabased approach'], 'value': 0.3475280972, 'top_word': 'legal nerc'}]\n",
      "aa:::: ['named entity recognizer', 'classifier']\n",
      "[{'words': ['wikipedia'], 'value': 0, 'top_word': 'wikipedia'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}, {'words': ['wikipediabased approach'], 'value': 0, 'top_word': 'wikipediabased approach'}, {'words': ['lkif'], 'value': 0, 'top_word': 'lkif'}, {'words': ['lkif'], 'value': 0, 'top_word': 'lkif'}, {'words': ['named entity recognizer and classifier'], 'value': 0, 'top_word': 'named entity recognizer and classifier'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}]\n",
      "Legal NERC with ontologies, Wikipedia and curriculum learning. In this paper, we present a Wikipediabased approach to develop resources for the legal domain. We establish a mapping between a legal domain ontology, LKIF (Hoekstra et al., 2007), and a Wikipediabased ontology, YAGO (Suchanek et al., 2007), and through that we populate LKIF. Moreover, we use the mentions of those entities in Wikipedia text to train a specific Named Entity Recognizer and Classifier. We find that this classifier works well in the Wikipedia, but, as could be expected, performance decreases in a corpus of judgments of the European Court of Human Rights. However, this tool will be used as a preprocess for human annotation. We resort to a technique called curriculum learning aimed to overcome problems of overfitting by learning increasingly more complex concepts. However, we find that in this particular setting, the method works best by learning from most specific to most general concepts, not the other way round.\n",
      "['named entity recognizer', 'classifier']\n",
      "[{'words': ['wikipedia'], 'value': 0, 'top_word': 'wikipedia'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}, {'words': ['wikipediabased approach'], 'value': 0, 'top_word': 'wikipediabased approach'}, {'words': ['lkif'], 'value': 0, 'top_word': 'lkif'}, {'words': ['lkif'], 'value': 0, 'top_word': 'lkif'}, {'words': ['named entity recognizer and classifier'], 'value': 0, 'top_word': 'named entity recognizer and classifier'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}]\n",
      "100\n",
      "aa:::: ['information mining']\n",
      "[{'words': ['safety information mining'], 'value': 0, 'top_word': 'safety information mining'}, {'words': ['nlp researchers'], 'value': 0, 'top_word': 'nlp researchers'}, {'words': ['relief efforts'], 'value': 0, 'top_word': 'relief efforts'}, {'words': ['word segmentation'], 'value': 0, 'top_word': 'word segmentation'}, {'words': ['named entity recognition'], 'value': 0, 'top_word': 'named entity recognition'}, {'words': ['tweet classification'], 'value': 0, 'top_word': 'tweet classification'}, {'words': ['safety information'], 'value': 0, 'top_word': 'safety information'}]\n",
      "aa:::: ['robust and effective systems']\n",
      "[{'words': ['nlp'], 'value': 0, 'top_word': 'nlp'}]\n",
      "Safety Information Mining --- What can NLP do in a disaster---. This paper describes efforts of NLP researchers to create a system to aid the relief efforts during the 2011 East Japan Earthquake. Specifically, we created a system to mine information regarding the safety of people in the disaster-stricken area from Twitter, a massive yet highly unorganized information source. We describe the large scale collaborative effort to rapidly create robust and effective systems for word segmentation, named entity recognition, and tweet classification. As a result of our efforts, we were able to effectively deliver new information about the safety of over 100 people in the disasterstricken area to a central repository for safety information.\n",
      "['robust and effective systems']\n",
      "[{'words': ['nlp'], 'value': 0, 'top_word': 'nlp'}]\n",
      "33\n",
      "aa:::: ['text prediction']\n",
      "[{'words': ['text prediction', 'contextual text prediction'], 'value': 0.7365233898, 'top_word': 'contextual text prediction'}]\n",
      "aa:::: ['large language models']\n",
      "[{'words': ['text prediction algorithms'], 'value': 0, 'top_word': 'text prediction algorithms'}, {'words': ['large language models'], 'value': 0, 'top_word': 'large language models'}, {'words': ['text prediction model'], 'value': 0, 'top_word': 'text prediction model'}]\n",
      "When does text prediction benefit from additional context? An exploration of contextual signals for chat and email messages. Email and chat communication tools are increasingly important for completing daily tasks. Accurate real-time phrase completion can save time and bolster productivity. Modern text prediction algorithms are based on large language models which typically rely on the prior words in a message to predict a completion. We examine how additional contextual signals (from previous messages, time, and subject) affect the performance of a commercial text prediction model. We compare contextual text prediction in chat and email messages from two of the largest commercial platforms Microsoft Teams and Outlook, finding that contextual signals contribute to performance differently between these scenarios. On emails, time context is most beneficial with small relative gains of 2% over baseline. Whereas, in chat scenarios, using a tailored set of previous messages as context yields relative improvements over the baseline between 9.3% and 18.6% across various critical serviceoriented text prediction metrics.\n",
      "['large language models']\n",
      "[{'words': ['text prediction algorithms'], 'value': 0, 'top_word': 'text prediction algorithms'}, {'words': ['large language models'], 'value': 0, 'top_word': 'large language models'}, {'words': ['text prediction model'], 'value': 0, 'top_word': 'text prediction model'}]\n",
      "100\n",
      "aa:::: ['conversion of protocols into a machine-readable format']\n",
      "[{'words': ['machine reading of instructions'], 'value': 0, 'top_word': 'machine reading of instructions'}, {'words': ['wet lab protocols'], 'value': 0, 'top_word': 'wet lab protocols'}, {'words': ['automatic or semi - automatic conversion of protocols'], 'value': 0, 'top_word': 'automatic or semi - automatic conversion of protocols'}, {'words': ['machine - readable format'], 'value': 0, 'top_word': 'machine - readable format'}, {'words': ['biological research'], 'value': 0, 'top_word': 'biological research'}, {'words': ['shallow semantic parsing of instructional texts'], 'value': 0, 'top_word': 'shallow semantic parsing of instructional texts'}]\n",
      "aa:::: ['annotated corpus']\n",
      "[{'words': ['machine learning approaches'], 'value': 0, 'top_word': 'machine learning approaches'}]\n",
      "An Annotated Corpus for Machine Reading of Instructions in Wet Lab Protocols. We describe an effort to annotate a corpus of natural language instructions consisting of 622 wet lab protocols to facilitate automatic or semi-automatic conversion of protocols into a machine-readable format and benefit biological research. Experimental results demonstrate the utility of our corpus for developing machine learning approaches to shallow semantic parsing of instructional texts. We make our annotated Wet Lab Protocol Corpus available to the research community. 1 1 The dataset is available on the authors' websites.\n",
      "['annotated corpus']\n",
      "[{'words': ['machine learning approaches'], 'value': 0, 'top_word': 'machine learning approaches'}]\n",
      "38\n",
      "aa:::: ['stance classification', 'outcome prediction', 'and impact assessment']\n",
      "[{'words': ['stance classification'], 'value': 0, 'top_word': 'stance classification'}, {'words': ['outcome prediction'], 'value': 0, 'top_word': 'outcome prediction'}, {'words': ['impact assessment'], 'value': 0, 'top_word': 'impact assessment'}, {'words': ['nlp tasks'], 'value': 0, 'top_word': 'nlp tasks'}, {'words': ['group decision - making'], 'value': 0, 'top_word': 'group decision - making'}, {'words': ['group decision - making'], 'value': 0, 'top_word': 'group decision - making'}, {'words': ['nuanced process of conflict and resolution'], 'value': 0, 'top_word': 'nuanced process of conflict and resolution'}, {'words': ['consensus formation'], 'value': 0, 'top_word': 'consensus formation'}, {'words': ['behavioral scientists'], 'value': 0, 'top_word': 'behavioral scientists'}, {'words': ['nlp researchers'], 'value': 0, 'top_word': 'nlp researchers'}]\n",
      "aa:::: ['corpus', 'bert']\n",
      "[{'words': ['bert contextualized word embeddings'], 'value': 0, 'top_word': 'bert contextualized word embeddings'}, {'words': ['language representations'], 'value': 0, 'top_word': 'language representations'}]\n",
      "Stance Classification, Outcome Prediction, and Impact Assessment: NLP Tasks for Studying Group Decision-Making. In group decision-making, the nuanced process of conflict and resolution that leads to consensus formation is closely tied to the quality of decisions made. Behavioral scientists rarely have rich access to process variables, though, as unstructured discussion transcripts are difficult to analyze. Here, we define ways for NLP researchers to contribute to the study of groups and teams. We introduce three tasks alongside a large new corpus of over 400,000 group debates on Wikipedia. We describe the tasks and their importance, then provide baselines showing that BERT contextualized word embeddings consistently outperform other language representations.\n",
      "['corpus', 'bert']\n",
      "[{'words': ['bert contextualized word embeddings'], 'value': 0, 'top_word': 'bert contextualized word embeddings'}, {'words': ['language representations'], 'value': 0, 'top_word': 'language representations'}]\n",
      "100\n",
      "aa:::: ['identifying rumors']\n",
      "[{'words': ['detect rumors', 'identifying rumors'], 'value': 0.29276865350000003, 'top_word': 'detect rumors'}]\n",
      "aa:::: ['propogation trees', 'kernel-based method']\n",
      "[{'words': ['kernel learning'], 'value': 0, 'top_word': 'kernel learning'}, {'words': ['kernel - based method'], 'value': 0, 'top_word': 'kernel - based method'}, {'words': ['propagation tree kernel'], 'value': 0, 'top_word': 'propagation tree kernel'}, {'words': ['kernel - based approach'], 'value': 0, 'top_word': 'kernel - based approach'}, {'words': ['rumor detection models'], 'value': 0, 'top_word': 'rumor detection models'}]\n",
      "Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning. How fake news goes viral via social media? How does its propagation pattern differ from real stories? In this paper, we attempt to address the problem of identifying rumors, i.e., fake information, out of microblog posts based on their propagation structure. We firstly model microblog posts diffusion with propagation trees, which provide valuable clues on how an original message is transmitted and developed over time. We then propose a kernel-based method called Propagation Tree Kernel, which captures high-order patterns differentiating different types of rumors by evaluating the similarities between their propagation tree structures. Experimental results on two real-world datasets demonstrate that the proposed kernel-based approach can detect rumors more quickly and accurately than state-ofthe-art rumor detection models.\n",
      "['propogation trees', 'kernel-based method']\n",
      "[{'words': ['kernel learning'], 'value': 0, 'top_word': 'kernel learning'}, {'words': ['kernel - based method'], 'value': 0, 'top_word': 'kernel - based method'}, {'words': ['propagation tree kernel'], 'value': 0, 'top_word': 'propagation tree kernel'}, {'words': ['kernel - based approach'], 'value': 0, 'top_word': 'kernel - based approach'}, {'words': ['rumor detection models'], 'value': 0, 'top_word': 'rumor detection models'}]\n",
      "89\n",
      "aa:::: ['semantic parsing']\n",
      "[{'words': ['math sat'], 'value': 0.5857397318, 'top_word': 'math sat'}]\n",
      "aa:::: ['tree transducer cascade']\n",
      "[{'words': ['sentential semantic parsing'], 'value': 0, 'top_word': 'sentential semantic parsing'}, {'words': ['cascade of tree transducers'], 'value': 0, 'top_word': 'cascade of tree transducers'}, {'words': ['tree transducer cascade'], 'value': 0, 'top_word': 'tree transducer cascade'}, {'words': ['eu - clid)'], 'value': 0, 'top_word': 'eu - clid)'}, {'words': ['euclid'], 'value': 0, 'top_word': 'euclid'}]\n",
      "Beyond Sentential Semantic Parsing: Tackling the Math SAT with a Cascade of Tree Transducers. We present an approach for answering questions that span multiple sentences and exhibit sophisticated cross-sentence anaphoric phenomena, evaluating on a rich source of such questions-the math portion of the Scholastic Aptitude Test (SAT). By using a tree transducer cascade as its basic architecture, our system (called EU-CLID) propagates uncertainty from multiple sources (e.g. coreference resolution or verb interpretation) until it can be confidently resolved. Experiments show the first-ever results (43% recall and 91% precision) on SAT algebra word problems. We also apply EUCLID to the public Dolphin algebra question set, and improve the state-of-the-art F 1-score from 73.9% to 77.0%.\n",
      "['tree transducer cascade']\n",
      "[{'words': ['sentential semantic parsing'], 'value': 0, 'top_word': 'sentential semantic parsing'}, {'words': ['cascade of tree transducers'], 'value': 0, 'top_word': 'cascade of tree transducers'}, {'words': ['tree transducer cascade'], 'value': 0, 'top_word': 'tree transducer cascade'}, {'words': ['eu - clid)'], 'value': 0, 'top_word': 'eu - clid)'}, {'words': ['euclid'], 'value': 0, 'top_word': 'euclid'}]\n",
      "100\n",
      "aa:::: ['detecting mild cognitiveimpairment']\n",
      "[{'words': ['topic - based measures of conversation'], 'value': 0, 'top_word': 'topic - based measures of conversation'}, {'words': ['detecting mild cognitiveimpairment conversation'], 'value': 0, 'top_word': 'detecting mild cognitiveimpairment conversation'}, {'words': ['cognitive task'], 'value': 0, 'top_word': 'cognitive task'}, {'words': ['mci'], 'value': 0, 'top_word': 'mci'}]\n",
      "aa:::: ['lexical coherence of consecutive utterances']\n",
      "[{'words': ['computational method'], 'value': 0, 'top_word': 'computational method'}, {'words': ['conversation - based measures'], 'value': 0, 'top_word': 'conversation - based measures'}]\n",
      "Topic-Based Measures of Conversation for Detecting Mild CognitiveImpairment. Conversation is a complex cognitive task that engages multiple aspects of cognitive functions to remember the discussed topics, monitor the semantic and linguistic elements, and recognize others' emotions. In this paper, we propose a computational method based on the lexical coherence of consecutive utterances to quantify topical variations in semistructured conversations of older adults with cognitive impairments. Extracting the lexical knowledge of conversational utterances, our method generates a set of novel conversational measures that indicate underlying cognitive deficits among subjects with mild cognitive impairment (MCI). Our preliminary results verify the utility of the proposed conversation-based measures in distinguishing MCI from healthy controls.\n",
      "['lexical coherence of consecutive utterances']\n",
      "[{'words': ['computational method'], 'value': 0, 'top_word': 'computational method'}, {'words': ['conversation - based measures'], 'value': 0, 'top_word': 'conversation - based measures'}]\n",
      "41\n",
      "aa:::: ['machine reading']\n",
      "[{'words': ['linking formula identifiers'], 'value': 0, 'top_word': 'linking formula identifiers'}, {'words': ['mathematical information retrieval'], 'value': 0, 'top_word': 'mathematical information retrieval'}, {'words': ['accessibility of scientific documents'], 'value': 0, 'top_word': 'accessibility of scientific documents'}]\n",
      "aa:::: ['rule-based approach']\n",
      "[{'words': ['mathalign'], 'value': 0, 'top_word': 'mathalign'}, {'words': ['machine reading approaches'], 'value': 0, 'top_word': 'machine reading approaches'}, {'words': ['rule - based approach'], 'value': 0, 'top_word': 'rule - based approach'}]\n",
      "MathAlign: Linking Formula Identifiers to their Contextual Natural Language Descriptions. Extending machine reading approaches to extract mathematical concepts and their descriptions is useful for a variety of tasks, ranging from mathematical information retrieval to increasing accessibility of scientific documents for the visually impaired. This entails segmenting mathematical formulae into identifiers and linking them to their natural language descriptions. We propose a rule-based approach for this task, which extracts L A T E X representations of formula identifiers and links them to their in-text descriptions, given only the original PDF and the location of the formula of interest. We also present a novel evaluation dataset for this task, as well as the tool used to create it.\n",
      "['rule-based approach']\n",
      "[{'words': ['mathalign'], 'value': 0, 'top_word': 'mathalign'}, {'words': ['machine reading approaches'], 'value': 0, 'top_word': 'machine reading approaches'}, {'words': ['rule - based approach'], 'value': 0, 'top_word': 'rule - based approach'}]\n",
      "89\n",
      "aa:::: ['paraphrasing']\n",
      "[{'words': ['text generation'], 'value': 0, 'top_word': 'text generation'}, {'words': ['text summarization'], 'value': 0, 'top_word': 'text summarization'}, {'words': ['text simplification'], 'value': 0, 'top_word': 'text simplification'}, {'words': ['text translation'], 'value': 0, 'top_word': 'text translation'}]\n",
      "aa:::: ['multi-purpose paraphrasing software tool']\n",
      "[{'words': ['translator friendly multi purpose paraphrasing software'], 'value': 0.3734092712, 'top_word': 'translator friendly multi purpose paraphrasing software'}]\n",
      "ReEscreve: a Translator-friendly Multi-purpose Paraphrasing Software Tool. \n",
      "['multi-purpose paraphrasing software tool']\n",
      "[{'words': ['translator friendly multi purpose paraphrasing software'], 'value': 0.3734092712, 'top_word': 'translator friendly multi purpose paraphrasing software'}]\n",
      "91\n",
      "aa:::: ['battlefield simulations']\n",
      "[{'words': ['battlefield simulations'], 'value': 0, 'top_word': 'battlefield simulations'}, {'words': ['battlefield simulations'], 'value': 0, 'top_word': 'battlefield simulations'}, {'words': ['control simulation system functions'], 'value': 0, 'top_word': 'control simulation system functions'}, {'words': ['exercise - time control'], 'value': 0, 'top_word': 'exercise - time control'}, {'words': ['immediate execution'], 'value': 0, 'top_word': 'immediate execution'}, {'words': ['mod - saf system functions'], 'value': 0, 'top_word': 'mod - saf system functions'}]\n",
      "aa:::: ['nuance speech recognition system', 'gemini natural language parsing', 'contextual-interpretation module', 'spoken-language interface']\n",
      "[{'words': ['commandtalk', 'commandtalk', 'commandtalk'], 'value': 0.4743520518, 'top_word': 'commandtalk'}]\n",
      "CommandTalk: A Spoken-Language Interface for Battlefield Simulations. CommandTalk is a spoken-language interface to battlefield simulations that allows the use of ordinary spoken English to create forces and control measures, assign missions to forces, modify missions during execution, and control simulation system functions. CommandTalk combines a number of separate components integrated through the use of the Open Agent Architecture, including the Nuance speech recognition system, the Gemini naturallanguage parsing and interpretation system, a contextual-interpretation modhle, a \"push-to-talk\" agent, the ModSAF battlefield simulator, and \"Start-It\" (a graphical processing-spawning agent). Com-mandTalk is installed at a number of Government and contractor sites, including NRaD and the Marine Corps Air Ground Combat Center. It is currently being extended to provide exercise-time control of all simulated U.S. forces in DARPA's STOW 97 demonstration. Put Checkpoint 1 at 937 965. Create a point called Checkpoint 2 at 930 960. Objective Alpha is 92 96. Charlie 4 5, at my command, advance in a column to Checkpoint 1. Next, proceed to Checkpoint 2. Then assault Objective Alpha. Charlie 4 5, move out. With the simulation under way, the user can exercise direct control over the simulated forces by giving commands such as the following for immediate execution: Charlie 4 5, speed up. Change formation to echelon right. Get in a line. Withdraw to Checkpoint 2. Examples of voice commands for controlling Mod-SAF system functions include the following: Show contour lines. Center on M1 platoon.\n",
      "['nuance speech recognition system', 'gemini natural language parsing', 'contextual-interpretation module', 'spoken-language interface']\n",
      "[{'words': ['commandtalk', 'commandtalk', 'commandtalk'], 'value': 0.4743520518, 'top_word': 'commandtalk'}]\n",
      "55\n",
      "aa:::: ['parallels between linguistics and biology']\n",
      "[{'words': ['cross-disciplinary research'], 'value': 0, 'top_word': 'cross-disciplinary research'}, {'words': ['new research avenues'], 'value': 0, 'top_word': 'new research avenues'}]\n",
      "aa:::: ['parallel construction', 'analogies']\n",
      "[{'words': ['method1'], 'value': 0, 'top_word': 'method1'}, {'words': ['method2'], 'value': 0, 'top_word': 'method2'}, {'words': ['method3'], 'value': 0, 'top_word': 'method3'}]\n",
      "Parallels between Linguistics and Biology. In this paper we take a fresh look at parallels between linguistics and biology. We expect that this new line of thinking will propel cross fertilization of two disciplines and open up new research avenues.\n",
      "['parallel construction', 'analogies']\n",
      "[{'words': ['method1'], 'value': 0, 'top_word': 'method1'}, {'words': ['method2'], 'value': 0, 'top_word': 'method2'}, {'words': ['method3'], 'value': 0, 'top_word': 'method3'}]\n",
      "29\n",
      "aa:::: ['sentiment analysis']\n",
      "[{'words': ['sentiment analysis', 'sentiment target clustering', 'sentiment prediction'], 'value': 0.1564198186, 'top_word': 'sentiment analysis'}]\n",
      "aa:::: ['semi-supervised bootstrapping algorithm']\n",
      "[{'words': ['semi - supervised bootstrapping algorithm'], 'value': 0, 'top_word': 'semi - supervised bootstrapping algorithm'}, {'words': ['hierarchical bayesian model'], 'value': 0, 'top_word': 'hierarchical bayesian model'}, {'words': ['bootstrapping approach'], 'value': 0, 'top_word': 'bootstrapping approach'}]\n",
      "Sentiment Analysis on the People's Daily. We propose a semi-supervised bootstrapping algorithm for analyzing China's foreign relations from the People's Daily. Our approach addresses sentiment target clustering, subjective lexicons extraction and sentiment prediction in a unified framework. Different from existing algorithms in the literature, time information is considered in our algorithm through a hierarchical bayesian model to guide the bootstrapping approach. We are hopeful that our approach can facilitate quantitative political analysis conducted by social scientists and politicians.\n",
      "['semi-supervised bootstrapping algorithm']\n",
      "[{'words': ['semi - supervised bootstrapping algorithm'], 'value': 0, 'top_word': 'semi - supervised bootstrapping algorithm'}, {'words': ['hierarchical bayesian model'], 'value': 0, 'top_word': 'hierarchical bayesian model'}, {'words': ['bootstrapping approach'], 'value': 0, 'top_word': 'bootstrapping approach'}]\n",
      "95\n",
      "aa:::: ['social media mining']\n",
      "[{'words': ['bigodm system', 'adr classification task', 'classifiers'], 'value': 0.2017435934, 'top_word': 'adr classification task'}]\n",
      "aa:::: ['support vector machines', 'word embedding', 'linear kernel', 'bag-of-word', 'domain-knowledge', 'negation']\n",
      "[{'words': ['vue'], 'value': 0.2828738689, 'top_word': 'vue'}]\n",
      "BIGODM System in the Social Media Mining for Health Applications Shared Task 2019. In this study, we describe our methods to automatically classify Twitter posts conveying events of adverse drug reaction (ADR). Based on our previous experience in tackling the ADR classification task, we empirically applied the vote-based undersampling ensemble approach along with linear support vector machine (SVM) to develop our classifiers as part of our participation in ACL 2019 Social Media Mining for Health Applications (SMM4H) shared task 1. The best-performed model on the test sets were trained on a merged corpus consisting of the datasets released by SMM4H 2017 and 2019. By using VUE, the corpus was randomly under-sampled with 2:1 ratio between the negative and positive classes to create an ensemble using the linear kernel trained with features including bag-of-word, domain knowledge, negation and word embedding. The best performing model achieved an F-measure of 0.551 which is about 5% higher than the average F-scores of 16 teams.\n",
      "['support vector machines', 'word embedding', 'linear kernel', 'bag-of-word', 'domain-knowledge', 'negation']\n",
      "[{'words': ['vue'], 'value': 0.2828738689, 'top_word': 'vue'}]\n",
      "67\n",
      "aa:::: ['analyzing stereotypes']\n",
      "[{'words': ['analyzing stereotypes'], 'value': 0, 'top_word': 'analyzing stereotypes'}, {'words': ['generative text inference tasks'], 'value': 0, 'top_word': 'generative text inference tasks'}, {'words': ['generative language - inference tasks'], 'value': 0, 'top_word': 'generative language - inference tasks'}, {'words': ['language inference)'], 'value': 0, 'top_word': 'language inference)'}, {'words': ['nlp'], 'value': 0, 'top_word': 'nlp'}, {'words': ['generated inferences'], 'value': 0, 'top_word': 'generated inferences'}]\n",
      "aa:::: ['annotation', 'human judgement']\n",
      "[{'words': ['inference)'], 'value': 0, 'top_word': 'inference)'}]\n",
      "Analyzing Stereotypes in Generative Text Inference Tasks. Stereotypes are inferences drawn about people based on their demographic attributes, which may result in harms to users when a system is deployed. In generative language-inference tasks, given a premise, a model produces plausible hypotheses that follow either logically (natural language inference) or commonsensically (commonsense inference). Such tasks are therefore a fruitful setting in which to explore the degree to which NLP systems encode stereotypes. In our work, we study how stereotypes manifest when the potential targets of stereotypes are situated in real-life, neutral contexts. We collect human judgments on the presence of stereotypes in generated inferences, and compare how perceptions of stereotypes vary due to annotator positionality. Domain Target Categories Gender man, woman, non-binary person, trans man, trans woman, cis man, cis woman\n",
      "['annotation', 'human judgement']\n",
      "[{'words': ['inference)'], 'value': 0, 'top_word': 'inference)'}]\n",
      "30\n",
      "aa:::: ['misogyny identification']\n",
      "[{'words': ['identifying misogyny in tweets', 'detecting misogyny'], 'value': 0.4181928635, 'top_word': 'identifying misogyny in tweets'}]\n",
      "aa:::: ['transformers', 'bert']\n",
      "[{'words': ['transfer learning approach'], 'value': 0, 'top_word': 'transfer learning approach'}, {'words': ['monolingual transformers'], 'value': 0, 'top_word': 'monolingual transformers'}, {'words': ['multilingual transformers'], 'value': 0, 'top_word': 'multilingual transformers'}, {'words': ['single - language bert models'], 'value': 0, 'top_word': 'single - language bert models'}, {'words': ['multilingual bert models'], 'value': 0, 'top_word': 'multilingual bert models'}, {'words': ['error analysis'], 'value': 0, 'top_word': 'error analysis'}, {'words': ['multilingual and monolingual models'], 'value': 0, 'top_word': 'multilingual and monolingual models'}]\n",
      "A Checkpoint on Multilingual Misogyny Identification. We address the problem of identifying misogyny in tweets in mono and multilingual settings in three languages: English, Italian and Spanish. We explore model variations considering single and multiple languages both in the pre-training of the transformer and in the training of the downstream task to explore the feasibility of detecting misogyny through a transfer learning approach across multiple languages. That is, we train monolingual transformers with monolingual data and multilingual transformers with both monolingual and multilingual data. Our models reach state-of-the-art performance on all three languages. The single-language BERT models perform the best, closely followed by different configurations of multilingual BERT models. The performance drops in zero-shot classification across languages. Our error analysis shows that multilingual and monolingual models tend to make the same mistakes.\n",
      "['transformers', 'bert']\n",
      "[{'words': ['transfer learning approach'], 'value': 0, 'top_word': 'transfer learning approach'}, {'words': ['monolingual transformers'], 'value': 0, 'top_word': 'monolingual transformers'}, {'words': ['multilingual transformers'], 'value': 0, 'top_word': 'multilingual transformers'}, {'words': ['single - language bert models'], 'value': 0, 'top_word': 'single - language bert models'}, {'words': ['multilingual bert models'], 'value': 0, 'top_word': 'multilingual bert models'}, {'words': ['error analysis'], 'value': 0, 'top_word': 'error analysis'}, {'words': ['multilingual and monolingual models'], 'value': 0, 'top_word': 'multilingual and monolingual models'}]\n",
      "100\n",
      "aa:::: ['recommendation system']\n",
      "[{'words': ['collaborative data relabeling'], 'value': 0, 'top_word': 'collaborative data relabeling'}, {'words': ['robust and diverse voice apps recommendation'], 'value': 0, 'top_word': 'robust and diverse voice apps recommendation'}, {'words': ['intelligent personal assistants'], 'value': 0, 'top_word': 'intelligent personal assistants'}, {'words': ['intelligent personal assistants'], 'value': 0, 'top_word': 'intelligent personal assistants'}, {'words': ['automatic speech recognition (asr) error'], 'value': 0, 'top_word': 'automatic speech recognition (asr) error'}, {'words': ['natural language understanding'], 'value': 0, 'top_word': 'natural language understanding'}, {'words': ['partial observation'], 'value': 0, 'top_word': 'partial observation'}, {'words': ['partial observation problem'], 'value': 0, 'top_word': 'partial observation problem'}]\n",
      "aa:::: ['collaborative data relabeling']\n",
      "[{'words': ['cdr'], 'value': 0.268807888, 'top_word': 'cdr'}]\n",
      "Collaborative Data Relabeling for Robust and Diverse Voice Apps Recommendation in Intelligent Personal Assistants. Intelligent personal assistants (IPAs) such as Amazon Alexa, Google Assistant and Apple Siri extend their built-in capabilities by supporting voice apps developed by third-party developers. Sometimes the smart assistant is not able to successfully respond to user voice commands (aka utterances). There are many reasons including automatic speech recognition (ASR) error, natural language understanding (NLU) error, routing utterances to an irrelevant voice app or simply that the user is asking for a capability that is not supported yet. The failure to handle a voice command leads to customer frustration. In this paper, we introduce a fallback skill recommendation system to suggest a voice app to a customer for an unhandled voice command. One of the prominent challenges of developing a skill recommender system for IPAs is partial observation. To solve the partial observation problem, we propose collaborative data relabeling (CDR) method. In addition, CDR also improves the diversity of the recommended skills. We evaluate the proposed method both offline and online. The offline evaluation results show that the proposed system outperforms the baselines. The online A/B testing results show significant gain of customer experience metrics.\n",
      "['collaborative data relabeling']\n",
      "[{'words': ['cdr'], 'value': 0.268807888, 'top_word': 'cdr'}]\n",
      "33\n",
      "aa:::: ['personalized search web']\n",
      "[{'words': ['personalized search'], 'value': 0, 'top_word': 'personalized search'}, {'words': ['web search personalization'], 'value': 0, 'top_word': 'web search personalization'}, {'words': ['query formulation'], 'value': 0, 'top_word': 'query formulation'}, {'words': ['re - ranking phase'], 'value': 0, 'top_word': 're - ranking phase'}, {'words': ['personalization of web search'], 'value': 0, 'top_word': 'personalization of web search'}]\n",
      "aa:::: ['statistical machine translation models', 'relevance feedback']\n",
      "[{'words': ['statistical machine translation models'], 'value': 0, 'top_word': 'statistical machine translation models'}, {'words': ['relevance feedback'], 'value': 0, 'top_word': 'relevance feedback'}, {'words': ['noisy channel model'], 'value': 0, 'top_word': 'noisy channel model'}, {'words': ['search engine'], 'value': 0, 'top_word': 'search engine'}, {'words': ['search engine'], 'value': 0, 'top_word': 'search engine'}]\n",
      "Statistical Machine Translation Models for Personalized Search. Web search personalization has been well studied in the recent few years. Relevance feedback has been used in various ways to improve relevance of search results. In this paper, we propose a novel usage of relevance feedback to effectively model the process of query formulation and better characterize how a user relates his query to the document that he intends to retrieve using a noisy channel model. We model a user profile as the probabilities of translation of query to document in this noisy channel using the relevance feedback obtained from the user. The user profile thus learnt is applied in a re-ranking phase to rescore the search results retrieved using an underlying search engine. We evaluate our approach by conducting experiments using relevance feedback data collected from users using a popular search engine. The results have shown improvement over baseline, proving that our approach can be applied to personalization of web search. The experiments have also resulted in some valuable observations that learning these user profiles using snippets surrounding the results for a query gives better performance than learning from entire document collection.\n",
      "['statistical machine translation models', 'relevance feedback']\n",
      "[{'words': ['statistical machine translation models'], 'value': 0, 'top_word': 'statistical machine translation models'}, {'words': ['relevance feedback'], 'value': 0, 'top_word': 'relevance feedback'}, {'words': ['noisy channel model'], 'value': 0, 'top_word': 'noisy channel model'}, {'words': ['search engine'], 'value': 0, 'top_word': 'search engine'}, {'words': ['search engine'], 'value': 0, 'top_word': 'search engine'}]\n",
      "100\n",
      "aa:::: ['categorizing offensiveness']\n",
      "[{'words': ['categorizing offensiveness'], 'value': 0, 'top_word': 'categorizing offensiveness'}]\n",
      "aa:::: ['embedding representation', 'multi-layer perceptron', 'bert']\n",
      "[{'words': ['ltl ude', 'ltl udes systems'], 'value': 0.42122802140000004, 'top_word': 'ltl udes systems'}]\n",
      "LTL-UDE at SemEval-2019 Task 6: BERT and Two-Vote Classification for Categorizing Offensiveness. This paper describes LTL-UDE's systems for the SemEval 2019 Shared Task 6. We present results for Subtask A and C. In Subtask A, we experiment with an embedding representation of postings and use a Multi-Layer Perceptron and BERT to categorize postings. Our best result reaches the 10th place (out of 103) using BERT. In Subtask C, we applied a two-vote classification approach with minority fallback, which is placed on the 19th rank (out of 65).\n",
      "['embedding representation', 'multi-layer perceptron', 'bert']\n",
      "[{'words': ['ltl ude', 'ltl udes systems'], 'value': 0.42122802140000004, 'top_word': 'ltl udes systems'}]\n",
      "43\n",
      "aa:::: ['natural legal language processing and document curation']\n",
      "[{'words': ['natural legal language processing'], 'value': 0, 'top_word': 'natural legal language processing'}, {'words': ['document curation services'], 'value': 0, 'top_word': 'document curation services'}, {'words': ['natural legal language processing'], 'value': 0, 'top_word': 'natural legal language processing'}, {'words': ['document curation services'], 'value': 0, 'top_word': 'document curation services'}]\n",
      "aa:::: ['content and document curation workflow manager']\n",
      "[{'words': ['processing services'], 'value': 0, 'top_word': 'processing services'}, {'words': ['microservices architecture'], 'value': 0, 'top_word': 'microservices architecture'}, {'words': ['content and document curation workflow manager'], 'value': 0, 'top_word': 'content and document curation workflow manager'}]\n",
      "Developing and Orchestrating a Portfolio of Natural Legal Language Processing and Document Curation Services. We present a portfolio of natural legal language processing and document curation services currently under development in a collaborative European project. First, we give an overview of the project and the different use cases, while, in the main part of the article, we focus upon the 13 different processing services that are being deployed in different prototype applications using a flexible and scalable microservices architecture. Their orchestration is operationalised using a content and document curation workflow manager.\n",
      "['content and document curation workflow manager']\n",
      "[{'words': ['processing services'], 'value': 0, 'top_word': 'processing services'}, {'words': ['microservices architecture'], 'value': 0, 'top_word': 'microservices architecture'}, {'words': ['content and document curation workflow manager'], 'value': 0, 'top_word': 'content and document curation workflow manager'}]\n",
      "100\n",
      "aa:::: ['sentence classification']\n",
      "[{'words': ['joint sentence classification', 'sentence classification', 'sequential sentence classification'], 'value': 0.6521787643, 'top_word': 'sequential sentence classification'}]\n",
      "aa:::: ['artificial neural networks']\n",
      "[{'words': ['neural networks'], 'value': 0, 'top_word': 'neural networks'}, {'words': ['artificial neural networks'], 'value': 0, 'top_word': 'artificial neural networks'}, {'words': ['sentence classification approaches'], 'value': 0, 'top_word': 'sentence classification approaches'}, {'words': ['conditional random fields'], 'value': 0, 'top_word': 'conditional random fields'}, {'words': ['ann architecture'], 'value': 0, 'top_word': 'ann architecture'}, {'words': ['ann models'], 'value': 0, 'top_word': 'ann models'}]\n",
      "Neural Networks for Joint Sentence Classification in Medical Paper Abstracts. Existing models based on artificial neural networks (ANNs) for sentence classification often do not incorporate the context in which sentences appear, and classify sentences individually. However, traditional sentence classification approaches have been shown to greatly benefit from jointly classifying subsequent sentences, such as with conditional random fields. In this work, we present an ANN architecture that combines the effectiveness of typical ANN models to classify sentences in isolation, with the strength of structured prediction. Our model outperforms the state-ofthe-art results on two different datasets for sequential sentence classification in medical abstracts.\n",
      "['artificial neural networks']\n",
      "[{'words': ['neural networks'], 'value': 0, 'top_word': 'neural networks'}, {'words': ['artificial neural networks'], 'value': 0, 'top_word': 'artificial neural networks'}, {'words': ['sentence classification approaches'], 'value': 0, 'top_word': 'sentence classification approaches'}, {'words': ['conditional random fields'], 'value': 0, 'top_word': 'conditional random fields'}, {'words': ['ann architecture'], 'value': 0, 'top_word': 'ann architecture'}, {'words': ['ann models'], 'value': 0, 'top_word': 'ann models'}]\n",
      "100\n",
      "aa:::: ['detection of propaganda techniques', 'propaganda technique classification']\n",
      "[{'words': ['sequence tagging'], 'value': 0, 'top_word': 'sequence tagging'}, {'words': ['text classification'], 'value': 0, 'top_word': 'text classification'}, {'words': ['semeval - 2020 task'], 'value': 0, 'top_word': 'semeval - 2020 task'}, {'words': ['detection of propaganda techniques'], 'value': 0, 'top_word': 'detection of propaganda techniques'}, {'words': ['relation extraction'], 'value': 0, 'top_word': 'relation extraction'}, {'words': ['propaganda technique classification'], 'value': 0, 'top_word': 'propaganda technique classification'}]\n",
      "aa:::: ['lstm', 'autoregressive transformer decoder']\n",
      "[{'words': ['lstm baselines'], 'value': 0, 'top_word': 'lstm baselines'}, {'words': ['autoregressive transformer decoder'], 'value': 0, 'top_word': 'autoregressive transformer decoder'}]\n",
      "NoPropaganda at SemEval-2020 Task 11: A Borrowed Approach to Sequence Tagging and Text Classification. This paper describes our contribution to SemEval-2020 Task 11: Detection Of Propaganda Techniques In News Articles. We start with simple LSTM baselines and move to an autoregressive transformer decoder to predict long continuous propaganda spans for the first subtask. We also adopt an approach from relation extraction by enveloping spans mentioned above with special tokens for the second subtask of propaganda technique classification. Our models report an F-score of 44.6% and a micro-averaged F-score of 58.2% for those tasks accordingly.\n",
      "['lstm', 'autoregressive transformer decoder']\n",
      "[{'words': ['lstm baselines'], 'value': 0, 'top_word': 'lstm baselines'}, {'words': ['autoregressive transformer decoder'], 'value': 0, 'top_word': 'autoregressive transformer decoder'}]\n",
      "100\n",
      "aa:::: ['propaganda detection']\n",
      "[{'words': ['interpretable propaganda detection', 'online news and media consumption', 'automatic systems'], 'value': 0.1094129928, 'top_word': 'interpretable propaganda detection'}]\n",
      "aa:::: ['qualitatively descriptive features', 'pre-trained language models']\n",
      "[{'words': ['automatic systems'], 'value': 0, 'top_word': 'automatic systems'}, {'words': ['deception techniques'], 'value': 0, 'top_word': 'deception techniques'}, {'words': ['deception techniques'], 'value': 0, 'top_word': 'deception techniques'}, {'words': ['language models'], 'value': 0, 'top_word': 'language models'}]\n",
      "Interpretable Propaganda Detection in News Articles. Online users today are exposed to misleading and propagandistic news articles and media posts on a daily basis. To counter thus, a number of approaches have been designed aiming to achieve a healthier and safer online news and media consumption. Automatic systems are able to support humans in detecting such content; yet, a major impediment to their broad adoption is that besides being accurate, the decisions of such systems need also to be interpretable in order to be trusted and widely adopted by users. Since misleading and propagandistic content influences readers through the use of a number of deception techniques, we propose to detect and to show the use of such techniques as a way to offer interpretability. In particular, we define qualitatively descriptive features and we analyze their suitability for detecting deception techniques. We further show that our interpretable features can be easily combined with pre-trained language models, yielding state-of-the-art results.\n",
      "['qualitatively descriptive features', 'pre-trained language models']\n",
      "[{'words': ['automatic systems'], 'value': 0, 'top_word': 'automatic systems'}, {'words': ['deception techniques'], 'value': 0, 'top_word': 'deception techniques'}, {'words': ['deception techniques'], 'value': 0, 'top_word': 'deception techniques'}, {'words': ['language models'], 'value': 0, 'top_word': 'language models'}]\n",
      "100\n",
      "aa:::: ['misinformation detection', 'detecting news bias', 'verifying rumors']\n",
      "[{'words': ['unifying misinformation detection'], 'value': 0.5123311877, 'top_word': 'unifying misinformation detection'}]\n",
      "aa:::: ['few-shot learning', 'unifiedm2']\n",
      "[{'words': ['unifiedm2', 'unifiedm2', 'unifiedm2s learned representation'], 'value': 0.5888508459, 'top_word': 'unifiedm2'}]\n",
      "On Unifying Misinformation Detection. In this paper, we introduce UNIFIEDM2, a general-purpose misinformation model that jointly models multiple domains of misinformation with a single, unified setup. The model is trained to handle four tasks: detecting news bias, clickbait, fake news and verifying rumors. By grouping these tasks together, UNIFIEDM2 learns a richer representation of misinformation, which leads to stateof-the-art or comparable performance across all tasks. Furthermore, we demonstrate that UNIFIEDM2's learned representation is helpful for few-shot learning of unseen misinformation tasks/datasets and model's generalizability to unseen events. * Work partially done while interning at Facebook AI. † Work partially done while working at Facebook AI.\n",
      "['few-shot learning', 'unifiedm2']\n",
      "[{'words': ['unifiedm2', 'unifiedm2', 'unifiedm2s learned representation'], 'value': 0.5888508459, 'top_word': 'unifiedm2'}]\n",
      "100\n",
      "aa:::: ['clinical document coding', 'document classification']\n",
      "[{'words': ['clinical document coding'], 'value': 0, 'top_word': 'clinical document coding'}, {'words': ['automatic coding of clinical documents'], 'value': 0, 'top_word': 'automatic coding of clinical documents'}, {'words': ['multi - label document classification'], 'value': 0, 'top_word': 'multi - label document classification'}, {'words': ['coding problem'], 'value': 0, 'top_word': 'coding problem'}]\n",
      "aa:::: [' lexically-triggered hidden markov model']\n",
      "[{'words': ['lexically triggered hidden markov models', 'lexically triggered hidden markov model'], 'value': 0.2184042633, 'top_word': 'lexically triggered hidden markov models'}, {'words': ['lt hmm', 'lt hmm'], 'value': 0.24816216530000001, 'top_word': 'lt hmm'}]\n",
      "Lexically-Triggered Hidden Markov Models for Clinical Document Coding. The automatic coding of clinical documents is an important task for today's healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.\n",
      "[' lexically-triggered hidden markov model']\n",
      "[{'words': ['lexically triggered hidden markov models', 'lexically triggered hidden markov model'], 'value': 0.2184042633, 'top_word': 'lexically triggered hidden markov models'}, {'words': ['lt hmm', 'lt hmm'], 'value': 0.24816216530000001, 'top_word': 'lt hmm'}]\n",
      "97\n",
      "aa:::: ['organize scientific concepts']\n",
      "[{'words': ['graph type', 'construction method', 'classification', 'face recognition', 'svm'], 'value': 0.0896247971, 'top_word': 'classification'}]\n",
      "aa:::: ['information extraction techniques']\n",
      "[{'words': ['faceted hierarchy'], 'value': 0, 'top_word': 'faceted hierarchy'}, {'words': ['graph type'], 'value': 0, 'top_word': 'graph type'}, {'words': ['construction method'], 'value': 0, 'top_word': 'construction method'}, {'words': ['svm'], 'value': 0, 'top_word': 'svm'}, {'words': ['knn)'], 'value': 0, 'top_word': 'knn)'}, {'words': ['hierarchy construction methods'], 'value': 0, 'top_word': 'hierarchy construction methods'}, {'words': ['hypernym detection'], 'value': 0, 'top_word': 'hypernym detection'}, {'words': ['information extraction techniques'], 'value': 0, 'top_word': 'information extraction techniques'}, {'words': ['hierarchy growth algorithm'], 'value': 0, 'top_word': 'hierarchy growth algorithm'}]\n",
      "Faceted Hierarchy: A New Graph Type to Organize Scientific Concepts and a Construction Method. On a scientific concept hierarchy, a parent concept may have a few attributes, each of which has multiple values being a group of child concepts. We call these attributes facets: classification has a few facets such as application (e.g., face recognition), model (e.g., svm, knn), and metric (e.g., precision). In this work, we aim at building faceted concept hierarchies from scientific literature. Hierarchy construction methods heavily rely on hypernym detection, however, the faceted relations are parent-to-child links but the hypernym relation is a multi-hop, i.e., ancestor-todescendent link with a specific facet \"type-of\". We use information extraction techniques to find synonyms, sibling concepts, and ancestordescendent relations from a data science corpus. And we propose a hierarchy growth algorithm to infer the parent-child links from the three types of relationships. It resolves conflicts by maintaining the acyclic structure of a hierarchy.\n",
      "['information extraction techniques']\n",
      "[{'words': ['faceted hierarchy'], 'value': 0, 'top_word': 'faceted hierarchy'}, {'words': ['graph type'], 'value': 0, 'top_word': 'graph type'}, {'words': ['construction method'], 'value': 0, 'top_word': 'construction method'}, {'words': ['svm'], 'value': 0, 'top_word': 'svm'}, {'words': ['knn)'], 'value': 0, 'top_word': 'knn)'}, {'words': ['hierarchy construction methods'], 'value': 0, 'top_word': 'hierarchy construction methods'}, {'words': ['hypernym detection'], 'value': 0, 'top_word': 'hypernym detection'}, {'words': ['information extraction techniques'], 'value': 0, 'top_word': 'information extraction techniques'}, {'words': ['hierarchy growth algorithm'], 'value': 0, 'top_word': 'hierarchy growth algorithm'}]\n",
      "100\n",
      "aa:::: ['multilingual generation', 'summarization']\n",
      "[{'words': ['multilingual generation and summarization of job adverts'], 'value': 0, 'top_word': 'multilingual generation and summarization of job adverts'}]\n",
      "aa:::: ['query engine']\n",
      "[{'words': ['multilingual internet - based employment advertisement system'], 'value': 0, 'top_word': 'multilingual internet - based employment advertisement system'}, {'words': ['example - based pattern matcher'], 'value': 0, 'top_word': 'example - based pattern matcher'}, {'words': ['query engine'], 'value': 0, 'top_word': 'query engine'}, {'words': ['symbolic case - based reasoning techniques'], 'value': 0, 'top_word': 'symbolic case - based reasoning techniques'}, {'words': ['generation module'], 'value': 0, 'top_word': 'generation module'}, {'words': ['grammar rules'], 'value': 0, 'top_word': 'grammar rules'}]\n",
      "Multilingual Generation and Summarization of Job Adverts: the TREE Project. A multilingual Internet-based employment advertisement system is described. Job ads are submitted as e-mail texts, analysed by an example-based pattern matcher and stored in language-independent schemas in an object-oriented database. Users can search the database in their own language and get customized summaries of the job ads. The query engine uses symbolic case-based reasoning techniques, while the generation module integrates canned text, templates, and grammar rules to produce texts and hypertexts in a simple way.\n",
      "['query engine']\n",
      "[{'words': ['multilingual internet - based employment advertisement system'], 'value': 0, 'top_word': 'multilingual internet - based employment advertisement system'}, {'words': ['example - based pattern matcher'], 'value': 0, 'top_word': 'example - based pattern matcher'}, {'words': ['query engine'], 'value': 0, 'top_word': 'query engine'}, {'words': ['symbolic case - based reasoning techniques'], 'value': 0, 'top_word': 'symbolic case - based reasoning techniques'}, {'words': ['generation module'], 'value': 0, 'top_word': 'generation module'}, {'words': ['grammar rules'], 'value': 0, 'top_word': 'grammar rules'}]\n",
      "100\n",
      "aa:::: ['bilingual language teaching']\n",
      "[{'words': ['natural language processing', 'automated speech recognition', 'data collection', 'computer assisted processes', 'fine grained error analysis'], 'value': 0.257721817, 'top_word': 'natural language processing'}, {'words': ['bilingual language teaching', 'language teachers'], 'value': 0.16599020920000002, 'top_word': 'bilingual language teaching'}]\n",
      "aa:::: ['speech recognition', 'corpus']\n",
      "[{'words': ['computer - assisted processes'], 'value': 0, 'top_word': 'computer - assisted processes'}, {'words': ['fine - grained error analysis'], 'value': 0, 'top_word': 'fine - grained error analysis'}]\n",
      "Applications of Natural Language Processing in Bilingual Language Teaching: An Indonesian-English Case Study. Multilingual corpora are difficult to compile and a classroom setting adds pedagogy to the mix of factors which make this data so rich and problematic to classify. In this paper, we set out methodological considerations of using automated speech recognition to build a corpus of teacher speech in an Indonesian language classroom. Our preliminary results (64% word error rate) suggest these tools have the potential to speed data collection in this context. We provide practical examples of our data structure, details of our piloted computer-assisted processes, and fine-grained error analysis. Our study is informed and directed by genuine research questions and discussion in both the education and computational linguistics fields. We highlight some of the benefits and risks of using these emerging technologies to analyze the complex work of language teachers and in education more generally.\n",
      "['speech recognition', 'corpus']\n",
      "[{'words': ['computer - assisted processes'], 'value': 0, 'top_word': 'computer - assisted processes'}, {'words': ['fine - grained error analysis'], 'value': 0, 'top_word': 'fine - grained error analysis'}]\n",
      "67\n",
      "aa:::: ['source-free negation detection']\n",
      "[{'words': ['source free negation detection', 'negation detection track'], 'value': 0.4352698922, 'top_word': 'source free negation detection'}, {'words': ['semeval 2021'], 'value': 0.8103166819000001, 'top_word': 'semeval 2021'}]\n",
      "aa:::: ['negationaware pre-training']\n",
      "[{'words': ['negation aware pre training', 'negationaware pre training'], 'value': 0.272423476, 'top_word': 'negation aware pre training'}]\n",
      "MedAI at SemEval-2021 Task 10: Negation-aware Pre-training for Source-free Negation Detection Domain Adaptation. Due to the increasing concerns for data privacy, source-free unsupervised domain adaptation attracts more and more research attention, where only a trained source model is assumed to be available, while the labeled source data remains private. To get promising adaptation results, we need to find effective ways to transfer knowledge learned in source domain and leverage useful domain specific information from target domain at the same time. This paper describes our winning contribution to SemEval 2021 Task 10: Source-Free Domain Adaptation for Semantic Processing. Our key idea is to leverage the model trained on source domain data to generate pseudo labels for target domain samples. Besides, we propose Negationaware Pre-training (NAP) to incorporate negation knowledge into model. Our method wins the 1st place with F1-score of 0.822 on the official blind test set of Negation Detection Track.\n",
      "['negationaware pre-training']\n",
      "[{'words': ['negation aware pre training', 'negationaware pre training'], 'value': 0.272423476, 'top_word': 'negation aware pre training'}]\n",
      "96\n",
      "aa:::: ['biomedical term disambiguation']\n",
      "[{'words': ['biomedical term disambiguation', 'all word disambiguation'], 'value': 0.4234089404, 'top_word': 'biomedical term disambiguation'}]\n",
      "aa:::: ['contextual information']\n",
      "[{'words': ['unsupervised vector approach'], 'value': 0, 'top_word': 'unsupervised vector approach'}, {'words': ['umls'], 'value': 0, 'top_word': 'umls'}, {'words': ['unsupervised vector approach'], 'value': 0, 'top_word': 'unsupervised vector approach'}, {'words': ['unified medical language system'], 'value': 0, 'top_word': 'unified medical language system'}, {'words': ['senseclusters'], 'value': 0, 'top_word': 'senseclusters'}]\n",
      "An Unsupervised Vector Approach to Biomedical Term Disambiguation: Integrating UMLS and Medline. This paper introduces an unsupervised vector approach to disambiguate words in biomedical text that can be applied to all-word disambiguation. We explore using contextual information from the Unified Medical Language System (UMLS) to describe the possible senses of a word. We experiment with automatically creating individualized stoplists to help reduce the noise in our dataset. We compare our results to SenseClusters and Humphrey et al. (2006) using the NLM-WSD dataset and with SenseClusters using conflated data from the 2005 Medline Baseline.\n",
      "['contextual information']\n",
      "[{'words': ['unsupervised vector approach'], 'value': 0, 'top_word': 'unsupervised vector approach'}, {'words': ['umls'], 'value': 0, 'top_word': 'umls'}, {'words': ['unsupervised vector approach'], 'value': 0, 'top_word': 'unsupervised vector approach'}, {'words': ['unified medical language system'], 'value': 0, 'top_word': 'unified medical language system'}, {'words': ['senseclusters'], 'value': 0, 'top_word': 'senseclusters'}]\n",
      "50\n",
      "aa:::: ['supervised economic event extraction']\n",
      "[{'words': ['extracting fine grained economic events', 'supervised economic event extraction', 'event extraction'], 'value': 0.2921973616, 'top_word': 'extracting fine grained economic events'}, {'words': ['classification'], 'value': 0.3153921366, 'top_word': 'classification'}, {'words': ['finegrained event detection setup'], 'value': 0.4459644854, 'top_word': 'finegrained event detection setup'}]\n",
      "aa:::: ['pilot study']\n",
      "[{'words': ['supervised learning'], 'value': 0, 'top_word': 'supervised learning'}, {'words': ['event extraction'], 'value': 0, 'top_word': 'event extraction'}, {'words': ['trigger identification'], 'value': 0, 'top_word': 'trigger identification'}, {'words': ['argument identification'], 'value': 0, 'top_word': 'argument identification'}, {'words': ['classification'], 'value': 0, 'top_word': 'classification'}]\n",
      "Extracting Fine-Grained Economic Events from Business News. Based on a recently developed fine-grained event extraction dataset for the economic domain, we present in a pilot study for supervised economic event extraction. We investigate how a stateof-the-art model for event extraction performs on the trigger and argument identification and classification. While F 1-scores of above 50% are obtained on the task of trigger identification, we observe a large gap in performance compared to results on the benchmark ACE05 dataset. We show that single-token triggers do not provide sufficient discriminative information for a finegrained event detection setup in a closed domain such as economics, since many classes have a large degree of lexico-semantic and contextual overlap.\n",
      "['pilot study']\n",
      "[{'words': ['supervised learning'], 'value': 0, 'top_word': 'supervised learning'}, {'words': ['event extraction'], 'value': 0, 'top_word': 'event extraction'}, {'words': ['trigger identification'], 'value': 0, 'top_word': 'trigger identification'}, {'words': ['argument identification'], 'value': 0, 'top_word': 'argument identification'}, {'words': ['classification'], 'value': 0, 'top_word': 'classification'}]\n",
      "36\n",
      "aa:::: ['academic teaching']\n",
      "[{'words': ['teaching machine translation', 'machine translation', 'mt'], 'value': 0.5982012053, 'top_word': 'teaching machine translation'}]\n",
      "aa:::: ['describing two possible architectures']\n",
      "[{'words': [\"``toy'' systems\"], 'value': 0, 'top_word': \"``toy'' systems\"}, {'words': ['\"toy\" systems'], 'value': 0, 'top_word': '\"toy\" systems'}]\n",
      "Architectures of ``toy'' systems for teaching machine translation. This paper addresses the advantages of practical academic teaching of machine translation by implementations of \"toy\" systems. This is the result of experience from several semesters with different types of courses and different categories of students. In addition to describing two possible architectures for such educational toy systems, we will also discuss how to overcome misconceptions about MT and the evaluation both of the achieved systems and the learning success.\n",
      "['describing two possible architectures']\n",
      "[{'words': [\"``toy'' systems\"], 'value': 0, 'top_word': \"``toy'' systems\"}, {'words': ['\"toy\" systems'], 'value': 0, 'top_word': '\"toy\" systems'}]\n",
      "46\n",
      "aa:::: ['dependency-based relation mining', 'text mining']\n",
      "[{'words': ['dependency based relation mining', 'automatic detection of relationships among domain entities'], 'value': 0.1735263467, 'top_word': 'dependency based relation mining'}]\n",
      "aa:::: ['dependency parser']\n",
      "[{'words': ['dependency parser'], 'value': 0, 'top_word': 'dependency parser'}, {'words': ['syntax - based filters'], 'value': 0, 'top_word': 'syntax - based filters'}]\n",
      "Dependency-Based Relation Mining for Biomedical Literature. We describe techniques for the automatic detection of relationships among domain entities (e.g. genes, proteins, diseases) mentioned in the biomedical literature. Our approach is based on the adaptive selection of candidate interactions sentences, which are then parsed using our own dependency parser. Specific syntax-based filters are used to limit the number of possible candidate interacting pairs. The approach has been implemented as a demonstrator over a corpus of 2000 richly annotated MedLine abstracts, and later tested by participation to a text mining competition. In both cases, the results obtained have proved the adequacy of the proposed approach to the task of interaction detection.\n",
      "['dependency parser']\n",
      "[{'words': ['dependency parser'], 'value': 0, 'top_word': 'dependency parser'}, {'words': ['syntax - based filters'], 'value': 0, 'top_word': 'syntax - based filters'}]\n",
      "100\n",
      "aa:::: ['automatic labeling']\n",
      "[{'words': ['automatic labeling of problem - solving dialogues'], 'value': 0, 'top_word': 'automatic labeling of problem - solving dialogues'}, {'words': ['computational microgenetic learning analytics'], 'value': 0, 'top_word': 'computational microgenetic learning analytics'}, {'words': [\"analysis of students' computational thinking\"], 'value': 0, 'top_word': \"analysis of students' computational thinking\"}, {'words': ['problem - solving dialogue'], 'value': 0, 'top_word': 'problem - solving dialogue'}, {'words': ['robotics challenge'], 'value': 0, 'top_word': 'robotics challenge'}, {'words': ['dialogue segment annotation'], 'value': 0, 'top_word': 'dialogue segment annotation'}, {'words': ['microgenetic analysis of cognitive interactions between students'], 'value': 0, 'top_word': 'microgenetic analysis of cognitive interactions between students'}]\n",
      "aa:::: ['sentence embeddings', 'linear chain crf model', 'rnns', 'lstm-crf', 'microgenetic learning analytics']\n",
      "[{'words': ['recurrent neural network model'], 'value': 0, 'top_word': 'recurrent neural network model'}, {'words': ['linear chain crfs'], 'value': 0, 'top_word': 'linear chain crfs'}, {'words': ['rnns'], 'value': 0, 'top_word': 'rnns'}, {'words': ['crf layer'], 'value': 0, 'top_word': 'crf layer'}, {'words': ['crf)'], 'value': 0, 'top_word': 'crf)'}, {'words': ['linear chain crf model'], 'value': 0, 'top_word': 'linear chain crf model'}, {'words': ['lstm - crf model'], 'value': 0, 'top_word': 'lstm - crf model'}, {'words': ['lstm - crf'], 'value': 0, 'top_word': 'lstm - crf'}, {'words': ['neural network models'], 'value': 0, 'top_word': 'neural network models'}]\n",
      "Automatic Labeling of Problem-Solving Dialogues for Computational Microgenetic Learning Analytics. This paper presents a recurrent neural network model to automate the analysis of students' computational thinking in problem-solving dialogue. We have collected and annotated dialogue transcripts from middle school students solving a robotics challenge, and each dialogue turn is assigned a code. We use sentence embeddings and speaker identities as features, and experiment with linear chain CRFs and RNNs with a CRF layer (LSTM-CRF). Both the linear chain CRF model and the LSTM-CRF model outperform the naïve baselines by a large margin, and LSTM-CRF has an edge between the two. To our knowledge, this is the first study on dialogue segment annotation using neural network models. This study is also a stepping-stone to automating the microgenetic analysis of cognitive interactions between students.\n",
      "['sentence embeddings', 'linear chain crf model', 'rnns', 'lstm-crf', 'microgenetic learning analytics']\n",
      "[{'words': ['recurrent neural network model'], 'value': 0, 'top_word': 'recurrent neural network model'}, {'words': ['linear chain crfs'], 'value': 0, 'top_word': 'linear chain crfs'}, {'words': ['rnns'], 'value': 0, 'top_word': 'rnns'}, {'words': ['crf layer'], 'value': 0, 'top_word': 'crf layer'}, {'words': ['crf)'], 'value': 0, 'top_word': 'crf)'}, {'words': ['linear chain crf model'], 'value': 0, 'top_word': 'linear chain crf model'}, {'words': ['lstm - crf model'], 'value': 0, 'top_word': 'lstm - crf model'}, {'words': ['lstm - crf'], 'value': 0, 'top_word': 'lstm - crf'}, {'words': ['neural network models'], 'value': 0, 'top_word': 'neural network models'}]\n",
      "100\n",
      "aa:::: ['automatic identification of autism spectrum disorders']\n",
      "[{'words': ['automatic identification of autism spectrum disorders'], 'value': 0, 'top_word': 'automatic identification of autism spectrum disorders'}, {'words': ['verbal and non - verbal communication'], 'value': 0, 'top_word': 'verbal and non - verbal communication'}, {'words': ['automatic identification'], 'value': 0, 'top_word': 'automatic identification'}, {'words': ['automatic classifiers'], 'value': 0, 'top_word': 'automatic classifiers'}]\n",
      "aa:::: ['linguistic and acoustic features']\n",
      "[{'words': ['automatic classification'], 'value': 0, 'top_word': 'automatic classification'}, {'words': ['word categories'], 'value': 0, 'top_word': 'word categories'}, {'words': ['prosody'], 'value': 0, 'top_word': 'prosody'}, {'words': ['voice quality'], 'value': 0, 'top_word': 'voice quality'}]\n",
      "Linguistic and Acoustic Features for Automatic Identification of Autism Spectrum Disorders in Children's Narrative. Autism spectrum disorders are developmental disorders characterised as deficits in social and communication skills, and they affect both verbal and non-verbal communication. Previous works measured differences in children with and without autism spectrum disorders in terms of linguistic and acoustic features, although they do not mention automatic identification using integration of these features. In this paper, we perform an exploratory study of several language and speech features of both single utterances and full narratives. We find that there are characteristic differences between children with autism spectrum disorders and typical development with respect to word categories, prosody, and voice quality, and that these differences can be used in automatic classifiers. We also examine the differences between American and Japanese children and find significant differences with regards to pauses before new turns and linguistic cues.\n",
      "['linguistic and acoustic features']\n",
      "[{'words': ['automatic classification'], 'value': 0, 'top_word': 'automatic classification'}, {'words': ['word categories'], 'value': 0, 'top_word': 'word categories'}, {'words': ['prosody'], 'value': 0, 'top_word': 'prosody'}, {'words': ['voice quality'], 'value': 0, 'top_word': 'voice quality'}]\n",
      "47\n",
      "aa:::: ['natural language inference']\n",
      "[{'words': ['biomedical natural language inference', 'natural language inference', 'biomedical nli'], 'value': 0.7655127645, 'top_word': 'natural language inference'}]\n",
      "aa:::: ['pre-trained text encoder', 'syntax encoder', 'ensemble models']\n",
      "[{'words': ['hybrid approach', 'hybrid approach'], 'value': 0.24208025630000002, 'top_word': 'hybrid approach'}]\n",
      "WTMED at MEDIQA 2019: A Hybrid Approach to Biomedical Natural Language Inference. Natural language inference (NLI) is challenging, especially when it is applied to technical domains such as biomedical settings. In this paper, we propose a hybrid approach to biomedical NLI where different types of information are exploited for this task. Our base model includes a pre-trained text encoder as the core component, and a syntax encoder and a feature encoder to capture syntactic and domain-specific information. Then we combine the output of different base models to form more powerful ensemble models. Finally, we design two conflict resolution strategies when the test data contain multiple (premise, hypothesis) pairs with the same premise. We train our models on the MedNLI dataset, yielding the best performance on the test set of the MEDIQA 2019 Task 1.\n",
      "['pre-trained text encoder', 'syntax encoder', 'ensemble models']\n",
      "[{'words': ['hybrid approach', 'hybrid approach'], 'value': 0.24208025630000002, 'top_word': 'hybrid approach'}]\n",
      "33\n",
      "aa:::: ['hyperpartisan news detection']\n",
      "[{'words': ['detecting hyperpartisan news article', 'hyperpartisan news detection task'], 'value': 0.31213906410000003, 'top_word': 'detecting hyperpartisan news article'}]\n",
      "aa:::: ['simple tokens']\n",
      "[{'words': ['tintin', 'cecl'], 'value': 0.21371699500000002, 'top_word': 'tintin'}]\n",
      "Tintin at SemEval-2019 Task 4: Detecting Hyperpartisan News Article with only Simple Tokens. Tintin, the system proposed by the CECL for the Hyperpartisan News Detection task of Se-mEval 2019, is exclusively based on the tokens that make up the documents and a standard supervised learning procedure. It obtained very contrasting results: poor on the main task, but much more effective at distinguishing documents published by hyperpartisan media outlets from unbiased ones, as it ranked first. An analysis of the most important features highlighted the positive aspects, but also some potential limitations of the approach.\n",
      "['simple tokens']\n",
      "[{'words': ['tintin', 'cecl'], 'value': 0.21371699500000002, 'top_word': 'tintin'}]\n",
      "33\n",
      "aa:::: ['text classification']\n",
      "[{'words': ['text classification', 'downstream classification tasks', 'occupation classification'], 'value': 0.3735835652, 'top_word': 'text classification'}]\n",
      "aa:::: ['classifier', 'embeddings']\n",
      "[{'words': ['debiasing embeddings'], 'value': 0, 'top_word': 'debiasing embeddings'}, {'words': ['downstream classifier'], 'value': 0, 'top_word': 'downstream classifier'}]\n",
      "Debiasing Embeddings for Reduced Gender Bias in Text Classification. Bolukbasi et al., 2016) demonstrated that pretrained word embeddings can inherit gender bias from the data they were trained on. We investigate how this bias affects downstream classification tasks, using the case study of occupation classification (De-Arteaga et al., 2019). We show that traditional techniques for debiasing embeddings can actually worsen the bias of the downstream classifier by providing a less noisy channel for communicating gender information. With a relatively minor adjustment, however, we show how these same techniques can be used to simultaneously reduce bias and maintain high classification accuracy.\n",
      "['classifier', 'embeddings']\n",
      "[{'words': ['debiasing embeddings'], 'value': 0, 'top_word': 'debiasing embeddings'}, {'words': ['downstream classifier'], 'value': 0, 'top_word': 'downstream classifier'}]\n",
      "100\n",
      "aa:::: ['deception detection']\n",
      "[{'words': ['deception detection', 'deception detection', 'deception detection'], 'value': 0.7061952154000001, 'top_word': 'deception detection'}]\n",
      "aa:::: ['multimodal dataset', 'statistical analysis']\n",
      "[{'words': ['statistical analysis'], 'value': 0, 'top_word': 'statistical analysis'}]\n",
      "A Multimodal Dataset for Deception Detection. This paper presents the construction of a multimodal dataset for deception detection, including physiological, thermal, and visual responses of human subjects under three deceptive scenarios. We present the experimental protocol, as well as the data acquisition process. To evaluate the usefulness of the dataset for the task of deception detection, we present a statistical analysis of the physiological and thermal modalities associated with the deceptive and truthful conditions. Initial results show that physiological and thermal responses can differentiate between deceptive and truthful states.\n",
      "['multimodal dataset', 'statistical analysis']\n",
      "[{'words': ['statistical analysis'], 'value': 0, 'top_word': 'statistical analysis'}]\n",
      "100\n",
      "aa:::: ['multi-robot dialogue with humans']\n",
      "[{'words': ['multi robot dialogue', 'multibot testing scenario'], 'value': 0.1881504059, 'top_word': 'multi robot dialogue'}]\n",
      "aa:::: ['research platform']\n",
      "[{'words': ['robotic platform'], 'value': 0, 'top_word': 'robotic platform'}, {'words': ['inter - agent communication protocol'], 'value': 0, 'top_word': 'inter - agent communication protocol'}]\n",
      "A Research Platform for Multi-Robot Dialogue with Humans. This paper presents a research platform that supports spoken dialogue interaction with multiple robots. The demonstration showcases our crafted MultiBot testing scenario in which users can verbally issue search, navigate, and follow instructions to two robotic teammates: a simulated ground robot and an aerial robot. This flexible language and robotic platform takes advantage of existing tools for speech recognition and dialogue management that are compatible with new domains, and implements an inter-agent communication protocol (tactical behavior specification), where verbal instructions are encoded for tasks assigned to the appropriate robot.\n",
      "['research platform']\n",
      "[{'words': ['robotic platform'], 'value': 0, 'top_word': 'robotic platform'}, {'words': ['inter - agent communication protocol'], 'value': 0, 'top_word': 'inter - agent communication protocol'}]\n",
      "69\n",
      "aa:::: ['translation dictation', 'automatic speech recognition']\n",
      "[{'words': ['translation dictation', 'translation dictation'], 'value': 0.5527668893000001, 'top_word': 'translation dictation'}, {'words': ['asr', 'asr'], 'value': 0.29110737140000004, 'top_word': 'asr'}, {'words': ['automatic speech recognition'], 'value': 0.46070253850000004, 'top_word': 'automatic speech recognition'}, {'words': ['translation'], 'value': 0.3971374929, 'top_word': 'translation'}]\n",
      "aa:::: ['evaluation']\n",
      "[{'words': ['statistical machine translation', 'smt system', 'smt hypotheses', 'smt'], 'value': 0.2314211018, 'top_word': 'statistical machine translation'}, {'words': ['asr system', 'asr system', 'asr', 'asr', 'asr', 'asr', 'asr'], 'value': 0.2682202842, 'top_word': 'asr'}, {'words': ['hybrid asr mt systems'], 'value': 0.38688144090000004, 'top_word': 'hybrid asr mt systems'}]\n",
      "Evaluating productivity gains of hybrid ASR-MT systems for translation dictation.. This paper is about Translation Dictation with ASR, that is, the use of Automatic Speech Recognition (ASR) by human translators, in order to dictate translations. We are particularly interested in the productivity gains that this could provide over conventional keyboard input, and ways in which such gains might be increased through a combination of ASR and Statistical Machine Translation (SMT). In this hybrid technology, the source language text is presented to both the human translator and a SMT system. The latter produces Nbest translations hypotheses, which are then used to fine tune the ASR language model and vocabulary towards utterances which are probable translations of source text sentences. We conducted an ergonomic experiment with eight professional translators dictating into French, using a top of the line offthe-shelf ASR system (Dragon NatuallySpeaking 8). We found that the ASR system had an average Word Error Rate (WER) of 11.7%, and that translation using this system did not provide statistically significant productivity increases over keyboard input, when following the manufacturer recommended procedure for error correction. However, we found indications that, even in its current imperfect state, French ASR might be beneficial to translators who are already used to dictation (either with ASR or a dictaphone), but more focused experiments are needed to confirm this. We also found that dictation using an ASR with WER of 4% or less would have resulted in statistically significant (p < 0.6) productivity gains in the order of 25.1% to 44.9% Translated Words Per Minute. We also evaluated the extent to which the limited manufacturer provided Domain Adaptation features could be used to positively bias the ASR using SMT hypotheses. We found that the relative gains in WER were much lower than has been reported in the literature for tighter integration of SMT with ASR, pointing the advantages of tight integration approaches and the need for more research in that area.\n",
      "['evaluation']\n",
      "[{'words': ['statistical machine translation', 'smt system', 'smt hypotheses', 'smt'], 'value': 0.2314211018, 'top_word': 'statistical machine translation'}, {'words': ['asr system', 'asr system', 'asr', 'asr', 'asr', 'asr', 'asr'], 'value': 0.2682202842, 'top_word': 'asr'}, {'words': ['hybrid asr mt systems'], 'value': 0.38688144090000004, 'top_word': 'hybrid asr mt systems'}]\n",
      "70\n",
      "aa:::: ['natural language inference']\n",
      "[{'words': ['social bias'], 'value': 0, 'top_word': 'social bias'}, {'words': ['bias and stereotyping'], 'value': 0, 'top_word': 'bias and stereotyping'}]\n",
      "aa:::: ['statistical analysis']\n",
      "[{'words': ['human - elicitation protocol'], 'value': 0, 'top_word': 'human - elicitation protocol'}]\n",
      "Social Bias in Elicited Natural Language Inferences. We analyze the Stanford Natural Language Inference (SNLI) corpus in an investigation of bias and stereotyping in NLP data. The human-elicitation protocol employed in the construction of the SNLI makes it prone to amplifying bias and stereotypical associations, which we demonstrate statistically (using pointwise mutual information) and with qualitative examples.\n",
      "['statistical analysis']\n",
      "[{'words': ['human - elicitation protocol'], 'value': 0, 'top_word': 'human - elicitation protocol'}]\n",
      "35\n",
      "aa:::: ['mental health']\n",
      "[{'words': ['mental health field', 'mental health'], 'value': 0.2078470476, 'top_word': 'mental health'}]\n",
      "aa:::: ['language analysis']\n",
      "[{'words': ['linguistic components'], 'value': 0, 'top_word': 'linguistic components'}]\n",
      "From ADHD to SAD: Analyzing the Language of Mental Health on Twitter through Self-Reported Diagnoses. Many significant challenges exist for the mental health field, but one in particular is a lack of data available to guide research. Language provides a natural lens for studying mental health-much existing work and therapy have strong linguistic components, so the creation of a large, varied, language-centric dataset could provide significant grist for the field of mental health research. We examine a broad range of mental health conditions in Twitter data by identifying self-reported statements of diagnosis. We systematically explore language differences between ten conditions with respect to the general population, and to each other. Our aim is to provide guidance and a roadmap for where deeper exploration is likely to be fruitful.\n",
      "['language analysis']\n",
      "[{'words': ['linguistic components'], 'value': 0, 'top_word': 'linguistic components'}]\n",
      "35\n",
      "aa:::: ['extracting patient clinical profiles']\n",
      "[{'words': ['extracting patient clinical profiles'], 'value': 0, 'top_word': 'extracting patient clinical profiles'}, {'words': ['diagnostic and treatment procedures'], 'value': 0, 'top_word': 'diagnostic and treatment procedures'}, {'words': ['description of clinical case studies'], 'value': 0, 'top_word': 'description of clinical case studies'}]\n",
      "aa:::: ['sentence classification system']\n",
      "[{'words': ['markup tag set'], 'value': 0, 'top_word': 'markup tag set'}, {'words': ['sentence classification system'], 'value': 0, 'top_word': 'sentence classification system'}]\n",
      "Extracting Patient Clinical Profiles from Case Reports. This research aims to extract detailed clinical profiles, such as signs and symptoms, and important laboratory test results of the patient from descriptions of the diagnostic and treatment procedures in journal articles. This paper proposes a novel markup tag set to cover a wide variety of semantics in the description of clinical case studies in the clinical literature. A manually annotated corpus which consists of 75 clinical reports with 5,117 sentences has been created and a sentence classification system is reported as the preliminary attempt to exploit the fast growing online repositories of clinical case reports.\n",
      "['sentence classification system']\n",
      "[{'words': ['markup tag set'], 'value': 0, 'top_word': 'markup tag set'}, {'words': ['sentence classification system'], 'value': 0, 'top_word': 'sentence classification system'}]\n",
      "100\n",
      "aa:::: ['humor and offense recognition']\n",
      "[{'words': ['semeval 2021 task'], 'value': 0.29884070160000004, 'top_word': 'semeval 2021 task'}]\n",
      "aa:::: ['deberta', 'disentangled attention']\n",
      "[{'words': ['deberta architecture', 'deberta model', 'deberta model'], 'value': 0.28205959999999997, 'top_word': 'deberta model'}]\n",
      "HumorHunter at SemEval-2021 Task 7: Humor and Offense Recognition with Disentangled Attention. In this paper, we describe our system submitted to SemEval 2021 Task 7: HaHackathon: Detecting and Rating Humor and Offense. The task aims at predicting whether the given text is humorous, the average humor rating given by the annotators, and whether the humor rating is controversial. In addition, the task also involves predicting how offensive the text is. Our approach adopts the DeBERTa architecture with disentangled attention mechanism, where the attention scores between words are calculated based on their content vectors and relative position vectors. We also took advantage of the pre-trained language models and fine-tuned the DeBERTa model on all the four subtasks. We experimented with several BERT-like structures and found that the large DeBERTa model generally performs better. During the evaluation phase, our system achieved an F-score of 0.9480 on subtask 1a, an RMSE of 0.5510 on subtask 1b, an F-score of 0.4764 on subtask 1c, and an RMSE of 0.4230 on subtask 2a (rank 3 on the leaderboard).\n",
      "['deberta', 'disentangled attention']\n",
      "[{'words': ['deberta architecture', 'deberta model', 'deberta model'], 'value': 0.28205959999999997, 'top_word': 'deberta model'}]\n",
      "100\n",
      "aa:::: ['teaching of terminology']\n",
      "[{'words': ['teaching of terminology'], 'value': 0, 'top_word': 'teaching of terminology'}, {'words': ['educational purposes'], 'value': 0, 'top_word': 'educational purposes'}, {'words': ['reading and writing abilities'], 'value': 0, 'top_word': 'reading and writing abilities'}, {'words': ['pilot program'], 'value': 0, 'top_word': 'pilot program'}, {'words': ['school curriculum'], 'value': 0, 'top_word': 'school curriculum'}, {'words': ['upper secondary education'], 'value': 0, 'top_word': 'upper secondary education'}, {'words': ['exploratory learning environments'], 'value': 0, 'top_word': 'exploratory learning environments'}, {'words': ['language and speech processing'], 'value': 0, 'top_word': 'language and speech processing'}, {'words': ['educational platform'], 'value': 0, 'top_word': 'educational platform'}]\n",
      "aa:::: ['educational platform']\n",
      "[{'words': ['lexiploigissi'], 'value': 0, 'top_word': 'lexiploigissi'}, {'words': ['educational platform'], 'value': 0, 'top_word': 'educational platform'}, {'words': ['lexiploigissi *'], 'value': 0, 'top_word': 'lexiploigissi *'}, {'words': ['educational platform'], 'value': 0, 'top_word': 'educational platform'}]\n",
      "LEXIPLOIGISSI: An Educational Platform for the Teaching of Terminology in Greece. This paper introduces a project, LEXIPLOIGISSI * , which involves use of language resources for educational purposes. More particularly, the aim of the project is to develop written corpora, electronic dictionaries and exercises to enhance students' reading and writing abilities in six different school subjects. It is the product of a small-scale pilot program that will be part of the school curriculum in the three grades of Upper Secondary Education in Greece. The application seeks to create exploratory learning environments in which digital sound, image, text and video are fully integrated through the educational platform and placed under the direct control of users who are able to follow individual pathways through data stores. * The Institute for Language and Speech Processing has undertaken this project as the leading contractor and Kastaniotis Publications as a subcontractor. The first partner was responsible for the design, development and implementation of the educational platform, as well as for the provision of pedagogic scenarios of use; the second partner provided the resources (texts and multimedia material). The starting date of the project was June 1999, the development of the software and the collection of material lasted nine months.\n",
      "['educational platform']\n",
      "[{'words': ['lexiploigissi'], 'value': 0, 'top_word': 'lexiploigissi'}, {'words': ['educational platform'], 'value': 0, 'top_word': 'educational platform'}, {'words': ['lexiploigissi *'], 'value': 0, 'top_word': 'lexiploigissi *'}, {'words': ['educational platform'], 'value': 0, 'top_word': 'educational platform'}]\n",
      "100\n",
      "aa:::: ['domain ontology']\n",
      "[{'words': ['semantic web context'], 'value': 0, 'top_word': 'semantic web context'}, {'words': ['ontology mapping'], 'value': 0, 'top_word': 'ontology mapping'}, {'words': ['inter - operation of heterogeneous resources'], 'value': 0, 'top_word': 'inter - operation of heterogeneous resources'}]\n",
      "aa:::: ['querying', 'extracting']\n",
      "[{'words': ['academic knowledge base'], 'value': 0, 'top_word': 'academic knowledge base'}, {'words': ['bootstrapping paradigm'], 'value': 0, 'top_word': 'bootstrapping paradigm'}]\n",
      "Enriching An Academic knowledge base using Linked Open Data. In this paper we present work done towards populating a domain ontology using a public knowledge base like DBpedia. Using an academic ontology as our target we identify mappings between a subset of its predicates and those in DBpedia and other linked datasets. In the semantic web context, ontology mapping allows linking of independently developed ontologies and inter-operation of heterogeneous resources. Linked open data is an initiative in this direction. We populate our ontology by querying the linked open datasets for extracting instances from these resources. We show how these along with semantic web standards and tools enable us to populate the academic ontology. Resulting instances could then be used as seeds in spirit of the typical bootstrapping paradigm.\n",
      "['querying', 'extracting']\n",
      "[{'words': ['academic knowledge base'], 'value': 0, 'top_word': 'academic knowledge base'}, {'words': ['bootstrapping paradigm'], 'value': 0, 'top_word': 'bootstrapping paradigm'}]\n",
      "60\n",
      "aa:::: ['text anonymization']\n",
      "[{'words': ['user behavioral modeling tasks'], 'value': 0, 'top_word': 'user behavioral modeling tasks'}, {'words': ['textual data anonymization'], 'value': 0, 'top_word': 'textual data anonymization'}, {'words': ['private - attribute leakage'], 'value': 0, 'top_word': 'private - attribute leakage'}, {'words': ['text representations'], 'value': 0, 'top_word': 'text representations'}]\n",
      "aa:::: ['deep reinforcement learning']\n",
      "[{'words': ['deep reinforcement learning based text anonymization', 'reinforcement learning based text anonymizor', 'deep reinforcement learning'], 'value': 0.2485622441, 'top_word': 'deep reinforcement learning based text anonymization'}]\n",
      "Deep Reinforcement Learning-based Text Anonymization against Private-Attribute Inference. User-generated textual data is rich in content and has been used in many user behavioral modeling tasks. However, it could also leak user private-attribute information that they may not want to disclose such as age and location. User's privacy concerns mandate data publishers to protect privacy. One effective way is to anonymize the textual data. In this paper, we study the problem of textual data anonymization and propose a novel Reinforcement Learning-based Text Anonymizor, RLTA, which addresses the problem of private-attribute leakage while preserving the utility of textual data. Our approach first extracts a latent representation of the original text w.r.t. a given task, then leverages deep reinforcement learning to automatically learn an optimal strategy for manipulating text representations w.r.t. the received privacy and utility feedback. Experiments show the effectiveness of this approach in terms of preserving both privacy and utility.\n",
      "['deep reinforcement learning']\n",
      "[{'words': ['deep reinforcement learning based text anonymization', 'reinforcement learning based text anonymizor', 'deep reinforcement learning'], 'value': 0.2485622441, 'top_word': 'deep reinforcement learning based text anonymization'}]\n",
      "100\n",
      "aa:::: ['toxic comment classification']\n",
      "[{'words': ['toxic comment classification', 'toxic comment classification'], 'value': 0.49176511170000003, 'top_word': 'toxic comment classification'}]\n",
      "aa:::: ['data integration']\n",
      "[{'words': ['labeling processes'], 'value': 0, 'top_word': 'labeling processes'}]\n",
      "Data Integration for Toxic Comment Classification: Making More Than 40 Datasets Easily Accessible in One Unified Format. With the rise of research on toxic comment classification, more and more annotated datasets have been released. The wide variety of the task (different languages, different labeling processes and schemes) has led to a large amount of heterogeneous datasets that can be used for training and testing very specific settings. Despite recent efforts to create web pages that provide an overview, most publications still use only a single dataset. They are not stored in one central database, they come in many different data formats and it is difficult to interpret their class labels and how to reuse these labels in other projects.\n",
      "['data integration']\n",
      "[{'words': ['labeling processes'], 'value': 0, 'top_word': 'labeling processes'}]\n",
      "38\n",
      "aa:::: ['revising titles']\n",
      "[{'words': ['revising titles'], 'value': 0, 'top_word': 'revising titles'}, {'words': ['revising titles'], 'value': 0, 'top_word': 'revising titles'}]\n",
      "aa:::: ['support system', 'questionnaire survey']\n",
      "[{'words': ['support system'], 'value': 0, 'top_word': 'support system'}, {'words': ['support system'], 'value': 0, 'top_word': 'support system'}, {'words': ['revision wizard\"'], 'value': 0, 'top_word': 'revision wizard\"'}, {'words': ['title revision wizard'], 'value': 0, 'top_word': 'title revision wizard'}]\n",
      "A Support System for Revising Titles to Stimulate the Lay Reader's Interest in Technical Achievements. When we write a report or an explanation on a newly-developed technology for readers including laypersons, it is very important to compose a title that can stimulate their interest in the technology. However, it is difficult for inexperienced authors to come up with an appealing title. In this research, we developed a support system for revising titles. We call it \"title revision wizard\". The wizard provides a guidance on revising draft title to compose a title meeting three key points, and support tools for coming up with and elaborating on comprehensible or appealing phrases. In order to test the effect of our title revision wizard, we conducted a questionnaire survey on the effect of the titles with or without using the wizard on the interest of lay readers. The survey showed that the wizard is effective and helpful for the authors who cannot compose appealing titles for lay readers by themselves.\n",
      "['support system', 'questionnaire survey']\n",
      "[{'words': ['support system'], 'value': 0, 'top_word': 'support system'}, {'words': ['support system'], 'value': 0, 'top_word': 'support system'}, {'words': ['revision wizard\"'], 'value': 0, 'top_word': 'revision wizard\"'}, {'words': ['title revision wizard'], 'value': 0, 'top_word': 'title revision wizard'}]\n",
      "100\n",
      "aa:::: ['analyzing political bias']\n",
      "[{'words': ['analyzing political bias'], 'value': 0, 'top_word': 'analyzing political bias'}, {'words': ['automatic detection of bias'], 'value': 0, 'top_word': 'automatic detection of bias'}, {'words': ['bias assessment'], 'value': 0, 'top_word': 'bias assessment'}]\n",
      "aa:::: ['corpus', 'neural model']\n",
      "[{'words': ['neural model'], 'value': 0, 'top_word': 'neural model'}]\n",
      "Analyzing Political Bias and Unfairness in News Articles at Different Levels of Granularity. Media organizations bear great reponsibility because of their considerable influence on shaping beliefs and positions of our society. Any form of media can contain overly biased content, e.g., by reporting on political events in a selective or incomplete manner. A relevant question hence is whether and how such form of imbalanced news coverage can be exposed. The research presented in this paper addresses not only the automatic detection of bias but goes one step further in that it explores how political bias and unfairness are manifested linguistically. In this regard we utilize a new corpus of 6964 news articles with labels derived from adfontesmedia.com and develop a neural model for bias assessment. By analyzing this model on article excerpts, we find insightful bias patterns at different levels of text granularity, from single words to the whole article discourse.\n",
      "['corpus', 'neural model']\n",
      "[{'words': ['neural model'], 'value': 0, 'top_word': 'neural model'}]\n",
      "100\n",
      "aa:::: ['sequence labeling', 'named entity recognition', 'information extraction']\n",
      "[{'words': ['named entity recognition'], 'value': 0.47310033440000004, 'top_word': 'named entity recognition'}]\n",
      "aa:::: ['conditional random field', 'recurrent neural networks', 'crf-lstm model']\n",
      "[{'words': ['structured prediction models'], 'value': 0, 'top_word': 'structured prediction models'}, {'words': ['conditional random field based structured learning models'], 'value': 0, 'top_word': 'conditional random field based structured learning models'}, {'words': ['recurrent neural networks'], 'value': 0, 'top_word': 'recurrent neural networks'}, {'words': ['crf - lstm model'], 'value': 0, 'top_word': 'crf - lstm model'}, {'words': ['explicit modeling of pairwise potentials'], 'value': 0, 'top_word': 'explicit modeling of pairwise potentials'}, {'words': ['approximate version'], 'value': 0, 'top_word': 'approximate version'}, {'words': ['skip - chain crf inference'], 'value': 0, 'top_word': 'skip - chain crf inference'}, {'words': ['rnn potentials'], 'value': 0, 'top_word': 'rnn potentials'}]\n",
      "Structured prediction models for RNN based sequence labeling in clinical text. Sequence labeling is a widely used method for named entity recognition and information extraction from unstructured natural language data. In the clinical domain one major application of sequence labeling involves extraction of relevant entities such as medication, indication, and side-effects from Electronic Health Record Narratives. Sequence labeling in this domain presents its own set of challenges and objectives. In this work we experiment with Conditional Random Field based structured learning models with Recurrent Neural Networks. We extend the previously studied CRF-LSTM model with explicit modeling of pairwise potentials. We also propose an approximate version of skip-chain CRF inference with RNN potentials. We use these methods 1 for structured prediction in order to improve the exact phrase detection of clinical entities.\n",
      "['conditional random field', 'recurrent neural networks', 'crf-lstm model']\n",
      "[{'words': ['structured prediction models'], 'value': 0, 'top_word': 'structured prediction models'}, {'words': ['conditional random field based structured learning models'], 'value': 0, 'top_word': 'conditional random field based structured learning models'}, {'words': ['recurrent neural networks'], 'value': 0, 'top_word': 'recurrent neural networks'}, {'words': ['crf - lstm model'], 'value': 0, 'top_word': 'crf - lstm model'}, {'words': ['explicit modeling of pairwise potentials'], 'value': 0, 'top_word': 'explicit modeling of pairwise potentials'}, {'words': ['approximate version'], 'value': 0, 'top_word': 'approximate version'}, {'words': ['skip - chain crf inference'], 'value': 0, 'top_word': 'skip - chain crf inference'}, {'words': ['rnn potentials'], 'value': 0, 'top_word': 'rnn potentials'}]\n",
      "100\n",
      "aa:::: ['symptom diagnosis']\n",
      "[{'words': ['dialogue symptom diagnosis', 'symptom diagnosis', 'symptom diagnosis', 'dialogue symptom diagnosis', 'symptom diagnosis', 'dialogue symptom diagnosis'], 'value': 0.705699861, 'top_word': 'dialogue symptom diagnosis'}]\n",
      "aa:::: ['global attention mechanism', 'symptom graph']\n",
      "[{'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}, {'words': ['global attention mechanism'], 'value': 0, 'top_word': 'global attention mechanism'}, {'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}, {'words': ['global attention'], 'value': 0, 'top_word': 'global attention'}, {'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}]\n",
      "Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph. Symptom diagnosis is a challenging yet profound problem in natural language processing. Most previous research focus on investigating the standard electronic medical records for symptom diagnosis, while the dialogues between doctors and patients that contain more rich information are not well studied. In this paper, we first construct a dialogue symptom diagnosis dataset based on an online medical forum with a large amount of dialogues between patients and doctors. Then, we provide some benchmark models on this dataset to boost the research of dialogue symptom diagnosis. In order to further enhance the performance of symptom diagnosis over dialogues, we propose a global attention mechanism to capture more symptom related information, and build a symptom graph to model the associations between symptoms rather than treating each symptom independently. Experimental results show that both the global attention and symptom graph are effective to boost dialogue symptom diagnosis. In particular, our proposed model achieves the state-of-the-art performance on the constructed dataset.\n",
      "['global attention mechanism', 'symptom graph']\n",
      "[{'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}, {'words': ['global attention mechanism'], 'value': 0, 'top_word': 'global attention mechanism'}, {'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}, {'words': ['global attention'], 'value': 0, 'top_word': 'global attention'}, {'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}]\n",
      "100\n",
      "aa:::: ['automatic related work summarization']\n",
      "[{'words': ['summarization', 'automatic related work summarization', 'summarization', 'summarization'], 'value': 0.5889991671, 'top_word': 'summarization'}]\n",
      "aa:::: ['summarization system']\n",
      "[{'words': ['rewos'], 'value': 0, 'top_word': 'rewos'}, {'words': ['multi - document summarization baselines'], 'value': 0, 'top_word': 'multi - document summarization baselines'}]\n",
      "Towards Automated Related Work Summarization. We introduce the novel problem of automatic related work summarization. Given multiple articles (e.g., conference/journal papers) as input, a related work summarization system creates a topic-biased summary of related work specific to the target paper. Our prototype Related Work Summarization system, ReWoS, takes in set of keywords arranged in a hierarchical fashion that describes a target paper's topics, to drive the creation of an extractive summary using two different strategies for locating appropriate sentences for general topics as well as detailed ones. Our initial results show an improvement over generic multi-document summarization baselines in a human evaluation.\n",
      "['summarization system']\n",
      "[{'words': ['rewos'], 'value': 0, 'top_word': 'rewos'}, {'words': ['multi - document summarization baselines'], 'value': 0, 'top_word': 'multi - document summarization baselines'}]\n",
      "80\n",
      "aa:::: ['automatic extraction']\n",
      "[{'words': ['automatic extraction of reasoning chains'], 'value': 0, 'top_word': 'automatic extraction of reasoning chains'}, {'words': ['automatic extraction of reasoning chains'], 'value': 0, 'top_word': 'automatic extraction of reasoning chains'}, {'words': ['aviation investigation reports'], 'value': 0, 'top_word': 'aviation investigation reports'}]\n",
      "aa:::: ['graph-based text representation', 'natural language processing tools', 'syntactic and discourse parsers']\n",
      "[{'words': ['graph - based text representation'], 'value': 0, 'top_word': 'graph - based text representation'}, {'words': ['natural language processing tools'], 'value': 0, 'top_word': 'natural language processing tools'}, {'words': ['syntactic and discourse parsers'], 'value': 0, 'top_word': 'syntactic and discourse parsers'}, {'words': ['reasoning chains'], 'value': 0, 'top_word': 'reasoning chains'}]\n",
      "Automatic Extraction of Reasoning Chains from Textual Reports. Many organizations possess large collections of textual reports that document how a problem is solved or analysed, e.g. medical patient records, industrial accident reports, lawsuit records and investigation reports. Effective use of expert knowledge contained in these reports may greatly increase productivity of the organization. In this article, we propose a method for automatic extraction of reasoning chains that contain information used by the author of a report to analyse the problem at hand. For this purpose, we developed a graph-based text representation that makes the relations between textual units explicit. This representation is acquired automatically from a report using natural language processing tools including syntactic and discourse parsers. When applied to aviation investigation reports, our method generates reasoning chains that reveal the connection between initial information about the aircraft incident and its causes.\n",
      "['graph-based text representation', 'natural language processing tools', 'syntactic and discourse parsers']\n",
      "[{'words': ['graph - based text representation'], 'value': 0, 'top_word': 'graph - based text representation'}, {'words': ['natural language processing tools'], 'value': 0, 'top_word': 'natural language processing tools'}, {'words': ['syntactic and discourse parsers'], 'value': 0, 'top_word': 'syntactic and discourse parsers'}, {'words': ['reasoning chains'], 'value': 0, 'top_word': 'reasoning chains'}]\n",
      "100\n",
      "aa:::: ['automatic term extraction']\n",
      "[{'words': ['norwegian to english mt'], 'value': 0.3539590836, 'top_word': 'norwegian to english mt'}, {'words': ['automatic term extraction', 'automatic extraction of term candidates'], 'value': 0.3088204339, 'top_word': 'automatic term extraction'}]\n",
      "aa:::: ['statistical filtering']\n",
      "[{'words': ['kb - n'], 'value': 0, 'top_word': 'kb - n'}, {'words': ['web - accessible searchable knowledge bank'], 'value': 0, 'top_word': 'web - accessible searchable knowledge bank'}, {'words': ['lexical and statistical filtering'], 'value': 0, 'top_word': 'lexical and statistical filtering'}, {'words': ['term base'], 'value': 0, 'top_word': 'term base'}]\n",
      "Automatic Term Extraction from Knowledge Bank of Economics. KB-N is a web-accessible searchable Knowledge Bank comprising A) a parallel corpus of quality assured and calibrated English and Norwegian text drawn from economic-administrative knowledge domains, and B) a domain-focused database representing that knowledge universe in terms of defined concepts and their respective bilingual terminological entries. A central mechanism in connecting A and B is an algorithm for the automatic extraction of term candidates from aligned translation pairs on the basis of linguistic, lexical and statistical filtering (first ever for Norwegian). The system is designed and programmed by Paul Meurer at Aksis (UiB). An important pilot application of the term base is subdomain and collocations based word-sense disambiguation for LOGON, a system for Norwegian-to-English MT currently being developed.\n",
      "['statistical filtering']\n",
      "[{'words': ['kb - n'], 'value': 0, 'top_word': 'kb - n'}, {'words': ['web - accessible searchable knowledge bank'], 'value': 0, 'top_word': 'web - accessible searchable knowledge bank'}, {'words': ['lexical and statistical filtering'], 'value': 0, 'top_word': 'lexical and statistical filtering'}, {'words': ['term base'], 'value': 0, 'top_word': 'term base'}]\n",
      "100\n",
      "aa:::: ['peer-review score prediction']\n",
      "[{'words': ['multi task peer review score prediction', 'peer review aspect scores'], 'value': 0.29438569400000003, 'top_word': 'multi task peer review score prediction'}]\n",
      "aa:::: ['multi-task shared structure encoding approach', 'peer-review datasets']\n",
      "[{'words': ['multi - task approach'], 'value': 0, 'top_word': 'multi - task approach'}, {'words': ['multi - task models'], 'value': 0, 'top_word': 'multi - task models'}, {'words': ['multi - task shared structure encoding approach'], 'value': 0, 'top_word': 'multi - task shared structure encoding approach'}, {'words': ['single - task method'], 'value': 0, 'top_word': 'single - task method'}, {'words': ['multi - task methods'], 'value': 0, 'top_word': 'multi - task methods'}]\n",
      "Multi-task Peer-Review Score Prediction. Automatic prediction of the peer-review aspect scores of academic papers can be a useful assistant tool for both reviewers and authors. To handle the small size of published datasets on the target aspect of scores, we propose a multi-task approach to leverage additional information from other aspects of scores for improving the performance of the target aspect. Because one of the problems of building multi-task models is how to select the proper resources of auxiliary tasks and how to select the proper shared structures, we thus propose a multi-task shared structure encoding approach that automatically selects good shared network structures as well as good auxiliary resources. The experiments based on peer-review datasets show that our approach is effective and has better performance on the target scores than the single-task method and naïve multi-task methods.\n",
      "['multi-task shared structure encoding approach', 'peer-review datasets']\n",
      "[{'words': ['multi - task approach'], 'value': 0, 'top_word': 'multi - task approach'}, {'words': ['multi - task models'], 'value': 0, 'top_word': 'multi - task models'}, {'words': ['multi - task shared structure encoding approach'], 'value': 0, 'top_word': 'multi - task shared structure encoding approach'}, {'words': ['single - task method'], 'value': 0, 'top_word': 'single - task method'}, {'words': ['multi - task methods'], 'value': 0, 'top_word': 'multi - task methods'}]\n",
      "96\n",
      "aa:::: ['personalisation system']\n",
      "[{'words': ['personalisation of digital newspapers'], 'value': 0, 'top_word': 'personalisation of digital newspapers'}, {'words': ['representation of information needs'], 'value': 0, 'top_word': 'representation of information needs'}]\n",
      "aa:::: ['evaluation collection']\n",
      "[{'words': ['personalisation system'], 'value': 0, 'top_word': 'personalisation system'}, {'words': ['user model'], 'value': 0, 'top_word': 'user model'}, {'words': ['representation frameworks'], 'value': 0, 'top_word': 'representation frameworks'}, {'words': ['personalization system'], 'value': 0, 'top_word': 'personalization system'}]\n",
      "Development and Use of an Evaluation Collection for Personalisation of Digital Newspapers. This paper presents the process of development and the characteristics of an evaluation collection for a personalisation system for digital newspapers. This system selects, adapts and presents contents according to a user model that define information needs. The collection presented here contains data that are cross-related over four different axes: a set of news items from an electronic newspaper, collected into subsets corresponding to a particular sequence of days, packaged together and cross-indexed with a set of user profiles that represent the particular evolution of interests of a set of real users over the given days, expressed in each case according to four different representation frameworks: newspaper sections, Yahoo categories, keywords, and relevance feedback over the set of news items for the previous day. This information provides a minimum starting material over which one can evaluate for a given system how it addresses the first two observations-adapting to different users and adapting to particular users over time-providing that the particular system implements the representation of information needs according to the four frameworks employed in the collection. This collection has been successfully used to perform some different experiments to determine the effectiveness of the personalization system presented.\n",
      "['evaluation collection']\n",
      "[{'words': ['personalisation system'], 'value': 0, 'top_word': 'personalisation system'}, {'words': ['user model'], 'value': 0, 'top_word': 'user model'}, {'words': ['representation frameworks'], 'value': 0, 'top_word': 'representation frameworks'}, {'words': ['personalization system'], 'value': 0, 'top_word': 'personalization system'}]\n",
      "48\n",
      "aa:::: ['textbook question answering']\n",
      "[{'words': ['textbook question answering', 'textbook question answering', 'qa problems', 'learning qa problems'], 'value': 0.5479186177, 'top_word': 'textbook question answering'}, {'words': ['tqa problems', 'tqa problems'], 'value': 0.3707527369, 'top_word': 'tqa problems'}]\n",
      "aa:::: ['multi-modal context graph understanding', 'self-supervised open-set comprehension', 'graph convolutional networks (gcn)']\n",
      "[{'words': ['module f gcn', 'f gcn'], 'value': 0.45613715050000003, 'top_word': 'module f gcn'}]\n",
      "Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension. In this work, we introduce a novel algorithm for solving the textbook question answering (TQA) task which describes more realistic QA problems compared to other recent tasks. We mainly focus on two related issues with analysis of the TQA dataset. First, solving the TQA problems requires to comprehend multimodal contexts in complicated input data. To tackle this issue of extracting knowledge features from long text lessons and merging them with visual features, we establish a context graph from texts and images, and propose a new module f-GCN based on graph convolutional networks (GCN). Second, scientific terms are not spread over the chapters and subjects are split in the TQA dataset. To overcome this so called 'out-of-domain' issue, before learning QA problems, we introduce a novel self-supervised open-set learning process without any annotations. The experimental results show that our model significantly outperforms prior state-of-the-art methods. Moreover, ablation studies validate that both methods of incorporating f-GCN for extracting knowledge from multi-modal contexts and our newly proposed self-supervised learning process are effective for TQA problems.\n",
      "['multi-modal context graph understanding', 'self-supervised open-set comprehension', 'graph convolutional networks (gcn)']\n",
      "[{'words': ['module f gcn', 'f gcn'], 'value': 0.45613715050000003, 'top_word': 'module f gcn'}]\n",
      "80\n",
      "aa:::: ['sign language generation']\n",
      "[{'words': ['sign language generation', 'sign language generation'], 'value': 0.4236453921, 'top_word': 'sign language generation'}]\n",
      "aa:::: ['supervised intensity tagger', 'transformer']\n",
      "[{'words': ['computational approach'], 'value': 0, 'top_word': 'computational approach'}, {'words': ['sign language generation models'], 'value': 0, 'top_word': 'sign language generation models'}, {'words': ['data - driven manner'], 'value': 0, 'top_word': 'data - driven manner'}, {'words': ['supervised intensity tagger'], 'value': 0, 'top_word': 'supervised intensity tagger'}, {'words': ['transformer models'], 'value': 0, 'top_word': 'transformer models'}]\n",
      "Modeling Intensification for Sign Language Generation: A Computational Approach. End-to-end sign language generation models do not accurately represent the prosody in sign language. A lack of temporal and spatial variations leads to poor-quality generated presentations that confuse human interpreters. In this paper, we aim to improve the prosody in generated sign languages by modeling intensification in a data-driven manner. We present different strategies grounded in linguistics of sign language that inform how intensity modifiers can be represented in gloss annotations. To employ our strategies, we first annotate a subset of the benchmark PHOENIX-14T, a German Sign Language dataset, with different levels of intensification. We then use a supervised intensity tagger to extend the annotated dataset and obtain labels for the remaining portion of it. This enhanced dataset is then used to train state-of-the-art transformer models for sign language generation. We find that our efforts in intensification modeling yield better results when evaluated with automatic metrics. Human evaluation also indicates a higher preference of the videos generated using our model.\n",
      "['supervised intensity tagger', 'transformer']\n",
      "[{'words': ['computational approach'], 'value': 0, 'top_word': 'computational approach'}, {'words': ['sign language generation models'], 'value': 0, 'top_word': 'sign language generation models'}, {'words': ['data - driven manner'], 'value': 0, 'top_word': 'data - driven manner'}, {'words': ['supervised intensity tagger'], 'value': 0, 'top_word': 'supervised intensity tagger'}, {'words': ['transformer models'], 'value': 0, 'top_word': 'transformer models'}]\n",
      "100\n",
      "aa:::: ['information extraction']\n",
      "[{'words': ['extraction and exploration of correlations'], 'value': 0, 'top_word': 'extraction and exploration of correlations'}, {'words': ['automatic processing of hospital patient records'], 'value': 0, 'top_word': 'automatic processing of hospital patient records'}, {'words': ['retrieval of status descriptions'], 'value': 0, 'top_word': 'retrieval of status descriptions'}, {'words': ['shallow analysis'], 'value': 0, 'top_word': 'shallow analysis'}]\n",
      "aa:::: ['algorithm for exploring the correlations']\n",
      "[{'words': ['information extraction approach', 'ie'], 'value': 0.1501079081, 'top_word': 'ie'}]\n",
      "Extraction and Exploration of Correlations in Patient Status Data. The paper discusses an Information Extraction approach, which is applied for the automatic processing of hospital Patient Records (PRs) in Bulgarian language. The main task reported here is retrieval of status descriptions related to anatomical organs. Due to the specific telegraphic PR style, the approach is focused on shallow analysis. Missing text descriptions and default values are another obstacle. To overcome it, we propose an algorithm for exploring the correlations between patient status data and the corresponding diagnosis. Rules for interdependencies of the patient status data are generated by clustering according to chosen metrics. In this way it becomes possible to fill in status templates for each patient when explicit descriptions are unavailable in the text. The article summarises evaluation results which concern the performance of the current IE prototype.\n",
      "['algorithm for exploring the correlations']\n",
      "[{'words': ['information extraction approach', 'ie'], 'value': 0.1501079081, 'top_word': 'ie'}]\n",
      "50\n",
      "aa:::: ['gender bias detection']\n",
      "[{'words': ['assessing gender bias'], 'value': 0, 'top_word': 'assessing gender bias'}, {'words': ['nlp'], 'value': 0, 'top_word': 'nlp'}]\n",
      "aa:::: ['analysis']\n",
      "[{'words': ['data collection'], 'value': 0, 'top_word': 'data collection'}, {'words': ['data analysis'], 'value': 0, 'top_word': 'data analysis'}, {'words': ['natural language processing'], 'value': 0, 'top_word': 'natural language processing'}]\n",
      "Assessing Gender Bias in Wikipedia: Inequalities in Article Titles. Potential gender biases existing in Wikipedia's content can contribute to biased behaviors in a variety of downstream NLP systems. Yet, efforts in understanding what inequalities in portraying women and men occur in Wikipedia focused so far only on biographies, leaving open the question of how often such harmful patterns occur in other topics. In this paper, we investigate gender-related asymmetries in Wikipedia titles from all domains. We assess that for only half of gender-related articles, i.e., articles with words such as women or male in their titles, symmetrical counterparts describing the same concept for the other gender (and clearly stating it in their titles) exist. Among the remaining imbalanced cases, the vast majority of articles concern sports-and social-related issues. We provide insights on how such asymmetries can influence other Wikipedia components and propose steps towards reducing the frequency of observed patterns.\n",
      "['analysis']\n",
      "[{'words': ['data collection'], 'value': 0, 'top_word': 'data collection'}, {'words': ['data analysis'], 'value': 0, 'top_word': 'data analysis'}, {'words': ['natural language processing'], 'value': 0, 'top_word': 'natural language processing'}]\n",
      "100\n",
      "aa:::: ['identifying nuances in fake news']\n",
      "[{'words': ['identifying nuances'], 'value': 0, 'top_word': 'identifying nuances'}, {'words': ['automatically classifying fake news'], 'value': 0, 'top_word': 'automatically classifying fake news'}, {'words': ['satire'], 'value': 0, 'top_word': 'satire'}]\n",
      "aa:::: ['semantic representation', 'contextual language model', 'linguistic feature']\n",
      "[{'words': ['machine learning method'], 'value': 0, 'top_word': 'machine learning method'}, {'words': ['semantic representation'], 'value': 0, 'top_word': 'semantic representation'}, {'words': ['contextual language model'], 'value': 0, 'top_word': 'contextual language model'}, {'words': ['language - based baseline'], 'value': 0, 'top_word': 'language - based baseline'}]\n",
      "Identifying Nuances in Fake News vs. Satire: Using Semantic and Linguistic Cues. The blurry line between nefarious fake news and protected-speech satire has been a notorious struggle for social media platforms. Further to the efforts of reducing exposure to misinformation on social media, purveyors of fake news have begun to masquerade as satire sites to avoid being demoted. In this work, we address the challenge of automatically classifying fake news versus satire. Previous work have studied whether fake news and satire can be distinguished based on language differences. Contrary to fake news, satire stories are usually humorous and carry some political or social message. We hypothesize that these nuances could be identified using semantic and linguistic cues. Consequently, we train a machine learning method using semantic representation, with a state-of-the-art contextual language model, and with linguistic features based on textual coherence metrics. Empirical evaluation attests to the merits of our approach compared to the language-based baseline and sheds light on the nuances between fake news and satire. As avenues for future work, we consider studying additional linguistic features related to the humor aspect, and enriching the data with current news events, to help identify a political or social message.\n",
      "['semantic representation', 'contextual language model', 'linguistic feature']\n",
      "[{'words': ['machine learning method'], 'value': 0, 'top_word': 'machine learning method'}, {'words': ['semantic representation'], 'value': 0, 'top_word': 'semantic representation'}, {'words': ['contextual language model'], 'value': 0, 'top_word': 'contextual language model'}, {'words': ['language - based baseline'], 'value': 0, 'top_word': 'language - based baseline'}]\n",
      "100\n",
      "aa:::: ['patent translation']\n",
      "[{'words': ['japanese to english patent translation', 'japanese to english translation system'], 'value': 0.48515015840000003, 'top_word': 'japanese to english patent translation'}, {'words': ['mt'], 'value': 0.5951254964, 'top_word': 'mt'}]\n",
      "aa:::: ['mt system', 'data collection']\n",
      "[{'words': ['moses decoder'], 'value': 0, 'top_word': 'moses decoder'}, {'words': ['5 - grams language model'], 'value': 0, 'top_word': '5 - grams language model'}]\n",
      "Exploiting multiple resources for Japanese to English patent translation. This paper describes the development of a Japanese to English translation system using multiple resources and NTCIR-10 Patent translation collection. The MT system is based on different training data, the Wiktionary as a bilingual dictionary and Moses decoder. Due to the lack of parallel data on the patent domain, additional training data of the general domain was extracted from Wikipedia. Experiments using NTCIR-10 Patent translation data collection showed an improvement of the BLEU score when using a 5-grams language model and when adding the data extracted from Wikipedia but no improvement when adding the Wiktionary.\n",
      "['mt system', 'data collection']\n",
      "[{'words': ['moses decoder'], 'value': 0, 'top_word': 'moses decoder'}, {'words': ['5 - grams language model'], 'value': 0, 'top_word': '5 - grams language model'}]\n",
      "44\n",
      "aa:::: ['dementia detection']\n",
      "[{'words': ['detecting dementia', 'automatic detection of alzheimers disease', 'dementia detection'], 'value': 0.29908896490000003, 'top_word': 'detecting dementia'}]\n",
      "aa:::: ['transfer learning']\n",
      "[{'words': ['transfer learning'], 'value': 0.27751755710000003, 'top_word': 'transfer learning'}]\n",
      "Detecting dementia in Mandarin Chinese using transfer learning from a parallel corpus. Machine learning has shown promise for automatic detection of Alzheimer's disease (AD) through speech; however, efforts are hampered by a scarcity of data, especially in languages other than English. We propose a method to learn a correspondence between independently engineered lexicosyntactic features in two languages, using a large parallel corpus of outof-domain movie dialogue data. We apply it to dementia detection in Mandarin Chinese, and demonstrate that our method outperforms both unilingual and machine translation-based baselines. This appears to be the first study that transfers feature domains in detecting cognitive decline.\n",
      "['transfer learning']\n",
      "[{'words': ['transfer learning'], 'value': 0.27751755710000003, 'top_word': 'transfer learning'}]\n",
      "100\n",
      "aa:::: ['analysis of verbs']\n",
      "[{'words': ['stock price movement'], 'value': 0, 'top_word': 'stock price movement'}, {'words': ['price movement'], 'value': 0, 'top_word': 'price movement'}]\n",
      "aa:::: ['discrete machine learning algorithm']\n",
      "[{'words': ['discrete machine learning algorithm'], 'value': 0, 'top_word': 'discrete machine learning algorithm'}]\n",
      "An Analysis of Verbs in Financial News Articles and their Impact on Stock Price. Article terms can move stock prices. By analyzing verbs in financial news articles and coupling their usage with a discrete machine learning algorithm tied to stock price movement, we can build a model of price movement based upon the verbs used, to not only identify those terms that can move a stock price the most, but also whether they move the predicted price up or down.\n",
      "['discrete machine learning algorithm']\n",
      "[{'words': ['discrete machine learning algorithm'], 'value': 0, 'top_word': 'discrete machine learning algorithm'}]\n",
      "100\n",
      "aa:::: ['emotion in dialogue']\n",
      "[{'words': ['modulation of cooperation and emotion in dialogue', 'cooperation'], 'value': 0.17548814140000002, 'top_word': 'cooperation'}]\n",
      "aa:::: ['emotive corpus', 'kappa statistic', 'coding scheme']\n",
      "[{'words': ['multimodal annotation scheme'], 'value': 0, 'top_word': 'multimodal annotation scheme'}, {'words': ['coding scheme'], 'value': 0, 'top_word': 'coding scheme'}, {'words': ['logistic regression'], 'value': 0, 'top_word': 'logistic regression'}]\n",
      "The Modulation of Cooperation and Emotion in Dialogue: The REC Corpus. In this paper we describe the Rovereto Emotive Corpus (REC) which we collected to investigate the relationship between emotion and cooperation in dialogue tasks. It is an area where still many unsolved questions are present. One of the main open issues is the annotation of the socalled \"blended\" emotions and their recognition. Usually, there is a low agreement among raters in annotating emotions and, surprisingly, emotion recognition is higher in a condition of modality deprivation (i. e. only acoustic or only visual modality vs. bimodal display of emotion). Because of these previous results, we collected a corpus in which \"emotive\" tokens are pointed out during the recordings by psychophysiological indexes (ElectroCardioGram, and Galvanic Skin Conductance). From the output values of these indexes a general recognition of each emotion arousal is allowed. After this selection we will annotate emotive interactions with our multimodal annotation scheme, performing a kappa statistic on annotation results to validate our coding scheme. In the near future, a logistic regression on annotated data will be performed to find out correlations between cooperation and negative emotions. A final step will be an fMRI experiment on emotion recognition of blended emotions from face displays.\n",
      "['emotive corpus', 'kappa statistic', 'coding scheme']\n",
      "[{'words': ['multimodal annotation scheme'], 'value': 0, 'top_word': 'multimodal annotation scheme'}, {'words': ['coding scheme'], 'value': 0, 'top_word': 'coding scheme'}, {'words': ['logistic regression'], 'value': 0, 'top_word': 'logistic regression'}]\n",
      "100\n",
      "aa:::: ['hope speech detection']\n",
      "[{'words': ['hope speech detection', 'hope speech detection shared task'], 'value': 0.5462485552, 'top_word': 'hope speech detection'}]\n",
      "aa:::: ['bert embeddings', 'attention mechanism']\n",
      "[{'words': ['attention mechanism', 'attention mechanism'], 'value': 0.38918802140000003, 'top_word': 'attention mechanism'}, {'words': ['bert'], 'value': 0.3831139803, 'top_word': 'bert'}]\n",
      "IDIAP\\_TIET@LT-EDI-ACL2022 : Hope Speech Detection in Social Media using Contextualized BERT with Attention Mechanism. With the increase of users on social media platforms, manipulating or provoking masses of people has become a piece of cake. This spread of hatred among people, which has become a loophole for freedom of speech, must be minimized. Hence, it is essential to have a system that automatically classifies the hatred content, especially on social media, to take it down. This paper presents a simple modular pipeline classifier with BERT embeddings and attention mechanism to classify hope speech content in the Hope Speech Detection shared task for Equality, Diversity, and Inclusion-ACL 2022. Our system submission ranks fourth with an F1-score of 0.84. We release our code-base here https: //github.com/Deepanshu-beep/ hope-speech-attention.\n",
      "['bert embeddings', 'attention mechanism']\n",
      "[{'words': ['attention mechanism', 'attention mechanism'], 'value': 0.38918802140000003, 'top_word': 'attention mechanism'}, {'words': ['bert'], 'value': 0.3831139803, 'top_word': 'bert'}]\n",
      "100\n",
      "aa:::: ['detection of sockpuppeteering']\n",
      "[{'words': ['sockpuppet detection', 'detection of sockpuppeteering', 'sockpuppet cases'], 'value': 0.4393684566, 'top_word': 'sockpuppet detection'}]\n",
      "aa:::: ['authorship attribution', 'voting scheme']\n",
      "[{'words': ['authorship attribution methods'], 'value': 0, 'top_word': 'authorship attribution methods'}, {'words': ['sockpuppets'], 'value': 0, 'top_word': 'sockpuppets'}, {'words': ['voting scheme'], 'value': 0, 'top_word': 'voting scheme'}, {'words': ['human process'], 'value': 0, 'top_word': 'human process'}]\n",
      "A Case Study of Sockpuppet Detection in Wikipedia. This paper presents preliminary results of using authorship attribution methods for the detection of sockpuppeteering in Wikipedia. Sockpuppets are fake accounts created by malicious users to bypass Wikipedia's regulations. Our dataset is composed of the comments made by the editors on the talk pages. To overcome the limitations of the short lengths of these comments, we use an voting scheme to combine predictions made on individual user entries. We show that this approach is promising and that it can be a viable alternative to the current human process that Wikipedia uses to resolve suspected sockpuppet cases.\n",
      "['authorship attribution', 'voting scheme']\n",
      "[{'words': ['authorship attribution methods'], 'value': 0, 'top_word': 'authorship attribution methods'}, {'words': ['sockpuppets'], 'value': 0, 'top_word': 'sockpuppets'}, {'words': ['voting scheme'], 'value': 0, 'top_word': 'voting scheme'}, {'words': ['human process'], 'value': 0, 'top_word': 'human process'}]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for i,d in test_set.iterrows():\n",
    "    actual=d['task_annotation']\n",
    "    actual = [x for x in actual if str(x) != 'nan']\n",
    "    \n",
    "    actual_m=d['method_annotation']\n",
    "    actual_m = [x for x in actual_m if str(x) != 'nan']\n",
    "    \n",
    "    predicted_sci=d['task_scirex']\n",
    "    ratio_sci=lev_sim(actual, predicted_sci)\n",
    "    test_set.loc[i,'task_sci_ratio']=ratio_sci\n",
    "    \n",
    "    predicted_sci_m=d['method_scirex']\n",
    "    ratio_sci_m=lev_sim(actual_m, predicted_sci_m)\n",
    "    test_set.loc[i,'method_sci_ratio']=ratio_sci_m\n",
    "    \n",
    "    print(d['text'])\n",
    "    #print(actual_m)\n",
    "    #print(predicted_m)\n",
    "    #print(ratio_m)\n",
    "    \n",
    "    print(actual_m)\n",
    "    print(predicted_sci_m)\n",
    "    print(ratio_sci_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d243bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_set=test_set.assign(correct_ratio_sci_task=np.where(test_set.task_sci_ratio>=75,1,0))\n",
    "test_set=test_set.assign(correct_ratio_sci_method=np.where(test_set.method_sci_ratio>=75,1,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ed86ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_colors(actual,predicted):\n",
    "    if predicted == []:\n",
    "        return (0,0,0,[],[],[],[],[])\n",
    "    act_set=list(dict.fromkeys(actual))\n",
    "    len_pred=len(predicted)\n",
    "    len_act=len(act_set)\n",
    "    act_matches=[]\n",
    "    match_list=set()\n",
    "    golden=set()\n",
    "    golden_match=set()\n",
    "    unmatch=set()\n",
    "    match_group=set()\n",
    "    for a in act_set:\n",
    "        scores=[]\n",
    "        match=0\n",
    "        score_max=0\n",
    "        value_max=''\n",
    "        val_max_int=''\n",
    "        position=0\n",
    "        position_max=None\n",
    "        abb_flag=''\n",
    "        for p in predicted:\n",
    "            internal_max=0\n",
    "            for pp in p['words']:\n",
    "                unmatch.add(pp)\n",
    "                ratio = fuzz.partial_ratio(a.lower(), pp.lower())\n",
    "                abb=\"\".join(e[0] for e in pp.split())\n",
    "                print(\"comparing \",a,\" :with: \",pp,\" ::result::\",ratio)\n",
    "                if  (ratio>internal_max):\n",
    "                    internal_max=ratio\n",
    "                    val_max_int=pp\n",
    "                if abb==a:\n",
    "                    internal_max=80\n",
    "                    val_max_int=pp\n",
    "                    \n",
    "            if (internal_max>=75) & (internal_max>score_max):\n",
    "                score_max=internal_max\n",
    "                value_max=val_max_int\n",
    "                position_max=position\n",
    "                match=1\n",
    "            position+=1\n",
    "        \n",
    "        golden.add(a)\n",
    "        if value_max!='':\n",
    "            match_list.add(value_max)\n",
    "            unmatch.remove(value_max)\n",
    "            golden.remove(a)\n",
    "            golden_match.add(a)\n",
    "            match_group=match_group.union(predicted[position_max][\"words\"])\n",
    "            match_group.remove(value_max)\n",
    "            predicted.pop(position_max)\n",
    "            \n",
    "        \n",
    "        act_matches.append(match)\n",
    "    unmatch = [e for e in unmatch if e not in match_group]\n",
    "    correct_complete=sum(act_matches)\n",
    "    precision = correct_complete / len_pred\n",
    "    recall = correct_complete / len_act\n",
    "    if (precision+recall>0):\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "    else:\n",
    "        f1=0\n",
    "    return (f1,precision,recall,golden,golden_match,match_list,unmatch,match_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "370758d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>task_annotation</th>\n",
       "      <th>method_annotation</th>\n",
       "      <th>org_annotation</th>\n",
       "      <th>tasks</th>\n",
       "      <th>methods</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "      <th>organization</th>\n",
       "      <th>task_sci_ratio</th>\n",
       "      <th>method_sci_ratio</th>\n",
       "      <th>correct_ratio_sci_task</th>\n",
       "      <th>correct_ratio_sci_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, text, task_annotation, method_annotation, org_annotation, tasks, methods, task_scirex, method_scirex, organization, task_sci_ratio, method_sci_ratio, correct_ratio_sci_task, correct_ratio_sci_method]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.loc[test_set.task_scirex.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47ce4078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>task_annotation</th>\n",
       "      <th>method_annotation</th>\n",
       "      <th>org_annotation</th>\n",
       "      <th>tasks</th>\n",
       "      <th>methods</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "      <th>organization</th>\n",
       "      <th>task_sci_ratio</th>\n",
       "      <th>method_sci_ratio</th>\n",
       "      <th>correct_ratio_sci_task</th>\n",
       "      <th>correct_ratio_sci_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soh-etal-2019-legal</td>\n",
       "      <td>Legal Area Classification: A Comparative Study...</td>\n",
       "      <td>[legal area classification]</td>\n",
       "      <td>[topic model, word embedding, language model]</td>\n",
       "      <td>[singapore academy of law, singapore supreme c...</td>\n",
       "      <td>[text classification, topic modeling, word emb...</td>\n",
       "      <td>[topic modeling, word embedding, language mode...</td>\n",
       "      <td>[{'words': ['legal area classification', 'clas...</td>\n",
       "      <td>[{'words': ['text classifiers'], 'value': 0, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                               text  \\\n",
       "1  soh-etal-2019-legal  Legal Area Classification: A Comparative Study...   \n",
       "\n",
       "               task_annotation                              method_annotation  \\\n",
       "1  [legal area classification]  [topic model, word embedding, language model]   \n",
       "\n",
       "                                      org_annotation  \\\n",
       "1  [singapore academy of law, singapore supreme c...   \n",
       "\n",
       "                                               tasks  \\\n",
       "1  [text classification, topic modeling, word emb...   \n",
       "\n",
       "                                             methods  \\\n",
       "1  [topic modeling, word embedding, language mode...   \n",
       "\n",
       "                                         task_scirex  \\\n",
       "1  [{'words': ['legal area classification', 'clas...   \n",
       "\n",
       "                                       method_scirex organization  \\\n",
       "1  [{'words': ['text classifiers'], 'value': 0, '...          NaN   \n",
       "\n",
       "   task_sci_ratio  method_sci_ratio  correct_ratio_sci_task  \\\n",
       "1           100.0             100.0                       1   \n",
       "\n",
       "   correct_ratio_sci_method  \n",
       "1                         1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.loc[test_set.ID=='soh-etal-2019-legal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b66203c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=test_set.loc[~test_set.task_scirex.isna(),:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6707b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['task_unmatch_golden']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['task_match_golden']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['task_match_predicted']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['task_unmatch_pred']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['task_match_group']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['task_match_total']=[list() for _ in range(test_set.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f34942af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['method_unmatch_golden']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['method_match_golden']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['method_match_predicted']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['method_unmatch_pred']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['method_match_group']=[list() for _ in range(test_set.shape[0])]\n",
    "test_set['method_match_total']=[list() for _ in range(test_set.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28dacfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Towards Automatic Distinction between Specialized and Non-Specialized Occurrences of Verbs in Medical Corpora. The medical field gathers people of different social statuses, such as students, pharmacists, managers, biologists, nurses and mainly medical doctors and patients, who represent the main actors. Despite their different levels of expertise, these actors need to interact and understand each other but the communication is not always easy and effective. This paper describes a method for a contrastive automatic analysis of verbs in medical corpora, based on the semantic annotation of the verbs nominal co-occurents. The corpora used are specialized in cardiology and distinguished according to their levels of expertise (high and low). The semantic annotation of these corpora is performed by using an existing medical terminology. The results indicate that the same verbs occurring in the two corpora show different specialization levels, which are indicated by the words (nouns and adjectives derived from medical terms) they occur with.\n",
      "predicted task:  [{'words': ['automatic distinction'], 'value': 0, 'top_word': 'automatic distinction'}, {'words': ['contrastive automatic analysis of verbs'], 'value': 0, 'top_word': 'contrastive automatic analysis of verbs'}, {'words': ['semantic annotation'], 'value': 0, 'top_word': 'semantic annotation'}, {'words': ['semantic annotation'], 'value': 0, 'top_word': 'semantic annotation'}]\n",
      "predicted method:  [{'words': ['semantic annotation'], 'value': 0, 'top_word': 'semantic annotation'}, {'words': ['contrastive analysis'], 'value': 0, 'top_word': 'contrastive analysis'}, {'words': ['medical terminology'], 'value': 0, 'top_word': 'medical terminology'}]\n",
      "actual task:  ['contrastive automatic analysis of verbs']\n",
      "actual method:  ['semantic annotation']\n",
      "comparing  contrastive automatic analysis of verbs  :with:  automatic distinction  ::result:: 62\n",
      "comparing  contrastive automatic analysis of verbs  :with:  contrastive automatic analysis of verbs  ::result:: 100\n",
      "comparing  contrastive automatic analysis of verbs  :with:  semantic annotation  ::result:: 58\n",
      "comparing  contrastive automatic analysis of verbs  :with:  semantic annotation  ::result:: 58\n",
      "comparing  semantic annotation  :with:  semantic annotation  ::result:: 100\n",
      "comparing  semantic annotation  :with:  contrastive analysis  ::result:: 44\n",
      "comparing  semantic annotation  :with:  medical terminology  ::result:: 37\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Legal Area Classification: A Comparative Study of Text Classifiers on Singapore Supreme Court Judgments. This paper conducts a comparative study on the performance of various machine learning (\"ML\") approaches for classifying judgments into legal areas. Using a novel dataset of 6,227 Singapore Supreme Court judgments, we investigate how state-of-the-art NLP methods compare against traditional statistical models when applied to a legal corpus that comprised few but lengthy documents. All approaches tested, including topic model, word embedding, and language model-based classifiers, performed well with as little as a few hundred judgments. However, more work needs to be done to optimize state-of-the-art methods for the legal domain.\n",
      "predicted task:  [{'words': ['legal area classification', 'classifying judgments into legal areas'], 'value': 0.31437352300000004, 'top_word': 'legal area classification'}]\n",
      "predicted method:  [{'words': ['text classifiers'], 'value': 0, 'top_word': 'text classifiers'}, {'words': ['machine learning (\"ml\") approaches'], 'value': 0, 'top_word': 'machine learning (\"ml\") approaches'}, {'words': ['nlp methods'], 'value': 0, 'top_word': 'nlp methods'}, {'words': ['statistical models'], 'value': 0, 'top_word': 'statistical models'}, {'words': ['topic model'], 'value': 0, 'top_word': 'topic model'}, {'words': ['word embedding'], 'value': 0, 'top_word': 'word embedding'}, {'words': ['language model - based classifiers'], 'value': 0, 'top_word': 'language model - based classifiers'}]\n",
      "actual task:  ['legal area classification']\n",
      "actual method:  ['topic model', 'word embedding', 'language model']\n",
      "comparing  legal area classification  :with:  legal area classification  ::result:: 100\n",
      "comparing  legal area classification  :with:  classifying judgments into legal areas  ::result:: 44\n",
      "comparing  topic model  :with:  text classifiers  ::result:: 27\n",
      "comparing  topic model  :with:  machine learning (\"ml\") approaches  ::result:: 36\n",
      "comparing  topic model  :with:  nlp methods  ::result:: 48\n",
      "comparing  topic model  :with:  statistical models  ::result:: 82\n",
      "comparing  topic model  :with:  topic model  ::result:: 100\n",
      "comparing  topic model  :with:  word embedding  ::result:: 36\n",
      "comparing  topic model  :with:  language model - based classifiers  ::result:: 55\n",
      "comparing  word embedding  :with:  text classifiers  ::result:: 14\n",
      "comparing  word embedding  :with:  machine learning (\"ml\") approaches  ::result:: 36\n",
      "comparing  word embedding  :with:  nlp methods  ::result:: 36\n",
      "comparing  word embedding  :with:  statistical models  ::result:: 21\n",
      "comparing  word embedding  :with:  word embedding  ::result:: 100\n",
      "comparing  word embedding  :with:  language model - based classifiers  ::result:: 43\n",
      "comparing  language model  :with:  text classifiers  ::result:: 21\n",
      "comparing  language model  :with:  machine learning (\"ml\") approaches  ::result:: 50\n",
      "comparing  language model  :with:  nlp methods  ::result:: 45\n",
      "comparing  language model  :with:  statistical models  ::result:: 50\n",
      "comparing  language model  :with:  language model - based classifiers  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "TEAM HUB@LT-EDI-EACL2021: Hope Speech Detection Based On Pre-trained Language Model. This article introduces the system description of TEAM HUB team participating in LT-EDI 2021: Hope Speech Detection. This shared task is the first task related to the desired voice detection. The data set in the shared task consists of three different languages (English, Tamil, and Malayalam). The task type is text classification. Based on the analysis and understanding of the task description and data set, we designed a system based on a pre-trained language model to complete this shared task. In this system, we use methods and models that combine the XLM-RoBERTa pre-trained language model and the Tf-Idf algorithm. In the final result ranking announced by the task organizer, our system obtained F1 scores of 0.93, 0.84, 0.59 on the English dataset, Malayalam dataset, and Tamil dataset. Our submission results are ranked 1, 2, and 3 respectively.\n",
      "predicted task:  [{'words': ['hope speech detection', 'hope speech detection', 'voice detection'], 'value': 0.5902768075, 'top_word': 'hope speech detection'}, {'words': ['lt edi 2021'], 'value': 0.2862163186, 'top_word': 'lt edi 2021'}]\n",
      "predicted method:  [{'words': ['pre - trained language model'], 'value': 0, 'top_word': 'pre - trained language model'}, {'words': ['language model'], 'value': 0, 'top_word': 'language model'}, {'words': ['xlm - roberta pre - trained language model'], 'value': 0, 'top_word': 'xlm - roberta pre - trained language model'}, {'words': ['tf - idf algorithm'], 'value': 0, 'top_word': 'tf - idf algorithm'}]\n",
      "actual task:  ['hope speech detection', 'text classification']\n",
      "actual method:  ['language model', 'xlm-roberta', 'tf-idf']\n",
      "comparing  hope speech detection  :with:  hope speech detection  ::result:: 100\n",
      "comparing  hope speech detection  :with:  hope speech detection  ::result:: 100\n",
      "comparing  hope speech detection  :with:  voice detection  ::result:: 73\n",
      "comparing  hope speech detection  :with:  lt edi 2021  ::result:: 27\n",
      "comparing  text classification  :with:  lt edi 2021  ::result:: 27\n",
      "comparing  language model  :with:  pre - trained language model  ::result:: 100\n",
      "comparing  language model  :with:  language model  ::result:: 100\n",
      "comparing  language model  :with:  xlm - roberta pre - trained language model  ::result:: 100\n",
      "comparing  language model  :with:  tf - idf algorithm  ::result:: 21\n",
      "comparing  xlm-roberta  :with:  language model  ::result:: 27\n",
      "comparing  xlm-roberta  :with:  xlm - roberta pre - trained language model  ::result:: 82\n",
      "comparing  xlm-roberta  :with:  tf - idf algorithm  ::result:: 36\n",
      "comparing  tf-idf  :with:  language model  ::result:: 17\n",
      "comparing  tf-idf  :with:  tf - idf algorithm  ::result:: 67\n",
      "0.5\n",
      "0.6666666666666666\n",
      "\n",
      "Flytxt\\_NTNU at SemEval-2018 Task 8: Identifying and Classifying Malware Text Using Conditional Random Fields and Na\\\"\\ive Bayes Classifiers. Cybersecurity risks such as malware threaten the personal safety of users, but to identify malware text is a major challenge. The paper proposes a supervised learning approach to identifying malware sentences given a document (subTask1 of SemEval 2018, Task 8), as well as to classifying malware tokens in the sentences (subTask2). The approach achieved good results, ranking second of twelve participants for both subtasks, with F-scores of 57% for subTask1 and 28% for subTask2.\n",
      "predicted task:  [{'words': ['identifying and classifying malware text'], 'value': 0, 'top_word': 'identifying and classifying malware text'}, {'words': ['semeval 2018'], 'value': 0, 'top_word': 'semeval 2018'}]\n",
      "predicted method:  [{'words': ['conditional random fields'], 'value': 0, 'top_word': 'conditional random fields'}, {'words': ['na\\\\\"\\\\ive bayes classifiers'], 'value': 0, 'top_word': 'na\\\\\"\\\\ive bayes classifiers'}, {'words': ['supervised learning approach'], 'value': 0, 'top_word': 'supervised learning approach'}]\n",
      "actual task:  ['identifying and classifying malware text']\n",
      "actual method:  ['supervised learning', 'conditional random fields']\n",
      "comparing  identifying and classifying malware text  :with:  identifying and classifying malware text  ::result:: 100\n",
      "comparing  identifying and classifying malware text  :with:  semeval 2018  ::result:: 33\n",
      "comparing  supervised learning  :with:  conditional random fields  ::result:: 26\n",
      "comparing  supervised learning  :with:  na\\\"\\ive bayes classifiers  ::result:: 32\n",
      "comparing  supervised learning  :with:  supervised learning approach  ::result:: 100\n",
      "comparing  conditional random fields  :with:  conditional random fields  ::result:: 100\n",
      "comparing  conditional random fields  :with:  na\\\"\\ive bayes classifiers  ::result:: 33\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Compiling an Interactive Literary Translation Web Site for Education Purposes. The project under discussion represents an attempt to exploit the potential of web resources for higher education and, more particularly, on a domain (that of literary translation) which is traditionally considered not very much in relation to technology and computer science. Translation and Interpreting students at the Universidad de Málaga are offered the possibility to take an English-Spanish Literary Translation module, which epitomises the need for debate in the field of Humanities. Sadly enough, implementation of course methodology is rendered very difficult or impossible owing to time restrictions and overcrowded classrooms. It is our contention that the setting up of a web site may solve some of these issues. We intend to provide both students and the literary translation-aware Internet audience with an integrated, scalable, multifunctional debate forum. Project contents will include a detailed course description, relevant reference materials and interaction services (mailing list, debate forum and chat rooms). This is obviously without limitation, as the Forum is open to any other contents that users may consider necessary or convenient, with a view to a more interdisciplinary approach, further research on the field of Literary Translation and future developments within the project framework.\n",
      "predicted task:  [{'words': ['interactive literary translation', 'literary translation', 'literary translation', 'literary translation'], 'value': 0.4173472673, 'top_word': 'literary translation'}]\n",
      "predicted method:  [{'words': ['web resources'], 'value': 0, 'top_word': 'web resources'}, {'words': ['course methodology'], 'value': 0, 'top_word': 'course methodology'}]\n",
      "actual task:  ['compiling an interactive literary translation site']\n",
      "actual method:  ['web site']\n",
      "comparing  compiling an interactive literary translation site  :with:  interactive literary translation  ::result:: 100\n",
      "comparing  compiling an interactive literary translation site  :with:  literary translation  ::result:: 100\n",
      "comparing  compiling an interactive literary translation site  :with:  literary translation  ::result:: 100\n",
      "comparing  compiling an interactive literary translation site  :with:  literary translation  ::result:: 100\n",
      "comparing  web site  :with:  web resources  ::result:: 62\n",
      "comparing  web site  :with:  course methodology  ::result:: 38\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Avoiding and Resolving Initiative Conflicts in Dialogue. In this paper, we report on an empirical study on initiative conflicts in human-human conversation. We examined these conflicts in two corpora of task-oriented dialogues. The results show that conversants try to avoid initiative conflicts, but when these conflicts occur, they are efficiently resolved by linguistic devices, such as volume.\n",
      "predicted task:  [{'words': ['avoiding and resolving initiative conflicts'], 'value': 0, 'top_word': 'avoiding and resolving initiative conflicts'}, {'words': ['dialogue'], 'value': 0, 'top_word': 'dialogue'}, {'words': ['initiative conflicts'], 'value': 0, 'top_word': 'initiative conflicts'}, {'words': ['human - human conversation'], 'value': 0, 'top_word': 'human - human conversation'}]\n",
      "predicted method:  [{'words': ['empirical study'], 'value': 0, 'top_word': 'empirical study'}, {'words': ['corpus analysis'], 'value': 0, 'top_word': 'corpus analysis'}, {'words': ['linguistic analysis'], 'value': 0, 'top_word': 'linguistic analysis'}]\n",
      "actual task:  ['avoiding and resolving initiative conflicts']\n",
      "actual method:  ['empirical study']\n",
      "comparing  avoiding and resolving initiative conflicts  :with:  avoiding and resolving initiative conflicts  ::result:: 100\n",
      "comparing  avoiding and resolving initiative conflicts  :with:  dialogue  ::result:: 38\n",
      "comparing  avoiding and resolving initiative conflicts  :with:  initiative conflicts  ::result:: 100\n",
      "comparing  avoiding and resolving initiative conflicts  :with:  human - human conversation  ::result:: 38\n",
      "comparing  empirical study  :with:  empirical study  ::result:: 100\n",
      "comparing  empirical study  :with:  corpus analysis  ::result:: 29\n",
      "comparing  empirical study  :with:  linguistic analysis  ::result:: 40\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Words are the Window to the Soul: Language-based User Representations for Fake News Detection. Cognitive and social traits of individuals are reflected in language use. Moreover, individuals who are prone to spread fake news online often share common traits. Building on these ideas, we introduce a model that creates representations of individuals on social media based only on the language they produce, and use them to detect fake news. We show that language-based user representations are beneficial for this task. We also present an extended analysis of the language of fake news spreaders, showing that its main features are mostly domain independent and consistent across two English datasets. Finally, we exploit the relation between language use and connections in the social graph to assess the presence of the Echo Chamber effect in our data.\n",
      "predicted task:  [{'words': ['fake news detection', 'language of fake news spreaders'], 'value': 0.2366785277, 'top_word': 'fake news detection'}]\n",
      "predicted method:  [{'words': ['language - based user representations'], 'value': 0, 'top_word': 'language - based user representations'}, {'words': ['language - based user representations'], 'value': 0, 'top_word': 'language - based user representations'}]\n",
      "actual task:  ['fake news detection']\n",
      "actual method:  ['language-based user representations']\n",
      "comparing  fake news detection  :with:  fake news detection  ::result:: 100\n",
      "comparing  fake news detection  :with:  language of fake news spreaders  ::result:: 63\n",
      "comparing  language-based user representations  :with:  language - based user representations  ::result:: 94\n",
      "comparing  language-based user representations  :with:  language - based user representations  ::result:: 94\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Constructing Multimodal Language Learner Texts Using LARA: Experiences with Nine Languages. LARA (Learning and Reading Assistant) is an open source platform whose purpose is to support easy conversion of plain texts into multimodal online versions suitable for use by language learners. This involves semi-automatically tagging the text, adding other annotations and recording audio. The platform is suitable for creating texts in multiple languages via crowdsourcing techniques that can be used for teaching a language via reading and listening. We present results of initial experiments by various collaborators where we measure the time required to produce substantial LARA resources, up to the length of short novels, in Dutch, English, Farsi, French, German, Icelandic, Irish, Swedish and Turkish. The first results are encouraging. Although there are some startup problems, the conversion task seems manageable for the languages tested so far. The resulting enriched texts are posted online and are freely available in both source and compiled form.\n",
      "predicted task:  [{'words': ['multimodal language learner texts'], 'value': 0, 'top_word': 'multimodal language learner texts'}, {'words': ['conversion of plain texts'], 'value': 0, 'top_word': 'conversion of plain texts'}, {'words': ['multimodal online versions'], 'value': 0, 'top_word': 'multimodal online versions'}, {'words': ['language learners'], 'value': 0, 'top_word': 'language learners'}, {'words': ['reading and listening'], 'value': 0, 'top_word': 'reading and listening'}, {'words': ['conversion task'], 'value': 0, 'top_word': 'conversion task'}]\n",
      "predicted method:  [{'words': ['lara'], 'value': 0, 'top_word': 'lara'}, {'words': ['lara (learning and reading assistant)'], 'value': 0, 'top_word': 'lara (learning and reading assistant)'}, {'words': ['crowdsourcing techniques'], 'value': 0, 'top_word': 'crowdsourcing techniques'}, {'words': ['lara'], 'value': 0, 'top_word': 'lara'}]\n",
      "actual task:  ['conversion of plain texts']\n",
      "actual method:  ['learning and reading assistant']\n",
      "comparing  conversion of plain texts  :with:  multimodal language learner texts  ::result:: 48\n",
      "comparing  conversion of plain texts  :with:  conversion of plain texts  ::result:: 100\n",
      "comparing  conversion of plain texts  :with:  multimodal online versions  ::result:: 40\n",
      "comparing  conversion of plain texts  :with:  language learners  ::result:: 41\n",
      "comparing  conversion of plain texts  :with:  reading and listening  ::result:: 44\n",
      "comparing  conversion of plain texts  :with:  conversion task  ::result:: 73\n",
      "comparing  learning and reading assistant  :with:  lara  ::result:: 75\n",
      "comparing  learning and reading assistant  :with:  lara (learning and reading assistant)  ::result:: 100\n",
      "comparing  learning and reading assistant  :with:  crowdsourcing techniques  ::result:: 38\n",
      "comparing  learning and reading assistant  :with:  lara  ::result:: 75\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Effects of Lexical Properties on Viewing Time per Word in Autistic and Neurotypical Readers. Eye tracking studies from the past few decades have shaped the way we think of word complexity and cognitive load: words that are long, rare and ambiguous are more difficult to read. However, online processing techniques have been scarcely applied to investigating the reading difficulties of people with autism and what vocabulary is challenging for them. We present parallel gaze data obtained from adult readers with autism and a control group of neurotypical readers and show that the former required higher cognitive effort to comprehend the texts as evidenced by three gaze-based measures. We divide all words into four classes based on their viewing times for both groups and investigate the relationship between longer viewing times and word length, word frequency, and four cognitively-based measures (word concreteness, familiarity, age of acquisition and imagability).\n",
      "predicted task:  [{'words': ['eye tracking studies'], 'value': 0, 'top_word': 'eye tracking studies'}, {'words': ['reading difficulties'], 'value': 0, 'top_word': 'reading difficulties'}]\n",
      "predicted method:  [{'words': ['online processing techniques'], 'value': 0, 'top_word': 'online processing techniques'}]\n",
      "actual task:  ['eye-tracking']\n",
      "actual method:  ['lexical properties', ' parallel gaze data']\n",
      "comparing  eye-tracking  :with:  eye tracking studies  ::result:: 92\n",
      "comparing  eye-tracking  :with:  reading difficulties  ::result:: 42\n",
      "comparing  lexical properties  :with:  online processing techniques  ::result:: 44\n",
      "comparing   parallel gaze data  :with:  online processing techniques  ::result:: 37\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Extracting Symptoms and their Status from Clinical Conversations. This paper describes novel models tailored for a new application, that of extracting the symptoms mentioned in clinical conversations along with their status. Lack of any publicly available corpus in this privacy-sensitive domain led us to develop our own corpus, consisting of about 3K conversations annotated by professional medical scribes. We propose two novel deep learning approaches to infer the symptom names and their status: (1) a new hierarchical span-attribute tagging (SA-T) model, trained using curriculum learning, and (2) a variant of sequence-to-sequence model which decodes the symptoms and their status from a few speaker turns within a sliding window over the conversation. This task stems from a realistic application of assisting medical providers in capturing symptoms mentioned by patients from their clinical conversations. To reflect this application, we define multiple metrics. From inter-rater agreement, we find that the task is inherently difficult. We conduct comprehensive evaluations on several contrasting conditions and observe that the performance of the models range from an F-score of 0.5 to 0.8 depending on the condition. Our analysis not only reveals the inherent challenges of the task, but also provides useful directions to improve the models.\n",
      "predicted task:  [{'words': ['extracting symptoms'], 'value': 0, 'top_word': 'extracting symptoms'}, {'words': ['medical providers'], 'value': 0, 'top_word': 'medical providers'}]\n",
      "predicted method:  [{'words': ['deep learning approaches'], 'value': 0, 'top_word': 'deep learning approaches'}, {'words': ['hierarchical span - attribute tagging (sa - t) model'], 'value': 0, 'top_word': 'hierarchical span - attribute tagging (sa - t) model'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}, {'words': ['sequence - to - sequence model'], 'value': 0, 'top_word': 'sequence - to - sequence model'}]\n",
      "actual task:  ['extracting symptoms']\n",
      "actual method:  ['curriculum learning', 'sequence-to-sequence', 'hierarchical span-attribute tagging (sa-t) model']\n",
      "comparing  extracting symptoms  :with:  extracting symptoms  ::result:: 100\n",
      "comparing  extracting symptoms  :with:  medical providers  ::result:: 29\n",
      "comparing  curriculum learning  :with:  deep learning approaches  ::result:: 47\n",
      "comparing  curriculum learning  :with:  hierarchical span - attribute tagging (sa - t) model  ::result:: 42\n",
      "comparing  curriculum learning  :with:  curriculum learning  ::result:: 100\n",
      "comparing  curriculum learning  :with:  sequence - to - sequence model  ::result:: 21\n",
      "comparing  sequence-to-sequence  :with:  deep learning approaches  ::result:: 25\n",
      "comparing  sequence-to-sequence  :with:  hierarchical span - attribute tagging (sa - t) model  ::result:: 30\n",
      "comparing  sequence-to-sequence  :with:  sequence - to - sequence model  ::result:: 80\n",
      "comparing  hierarchical span-attribute tagging (sa-t) model  :with:  deep learning approaches  ::result:: 42\n",
      "comparing  hierarchical span-attribute tagging (sa-t) model  :with:  hierarchical span - attribute tagging (sa - t) model  ::result:: 92\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Pre-trained Transformer-based Classification and Span Detection Models for Social Media Health Applications. This paper describes our approach for six classification tasks (Tasks 1a, 3a, 3b, 4 and 5) and one span detection task (Task 1b) from the Social Media Mining for Health (SMM4H) 2021 shared tasks. We developed two separate systems for classification and span detection, both based on pre-trained Transformer-based models. In addition, we applied oversampling and classifier ensembling in the classification tasks. The results of our submissions are over the median scores in all tasks except for Task 1a. Furthermore, our model achieved first place in Task 4 and obtained a 7% higher F 1-score than the median in Task 1b.\n",
      "predicted task:  [{'words': ['classification tasks', 'classification tasks'], 'value': 0.2862141579, 'top_word': 'classification tasks'}, {'words': ['span detection task', 'classification and span detection'], 'value': 0.3522171974, 'top_word': 'span detection task'}]\n",
      "predicted method:  [{'words': ['transformer based models'], 'value': 0.2669769824, 'top_word': 'transformer based models'}]\n",
      "actual task:  ['span detection', 'classification']\n",
      "actual method:  ['pre-trained transformer', 'classifier ensembling']\n",
      "comparing  span detection  :with:  classification tasks  ::result:: 43\n",
      "comparing  span detection  :with:  classification tasks  ::result:: 43\n",
      "comparing  span detection  :with:  span detection task  ::result:: 100\n",
      "comparing  span detection  :with:  classification and span detection  ::result:: 100\n",
      "comparing  classification  :with:  classification tasks  ::result:: 100\n",
      "comparing  classification  :with:  classification tasks  ::result:: 100\n",
      "comparing  pre-trained transformer  :with:  transformer based models  ::result:: 48\n",
      "comparing  classifier ensembling  :with:  transformer based models  ::result:: 43\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Question Answering in the Biomedical Domain. Question answering techniques have mainly been investigated in open domains. However, there are particular challenges in extending these open-domain techniques to extend into the biomedical domain. Question answering focusing on patients is less studied. We find that there are some challenges in patient question answering such as limited annotated data, lexical gap and quality of answer spans. We aim to address some of these gaps by extending and developing upon the literature to design a question answering system that can decide on the most appropriate answers for patients attempting to self-diagnose while including the ability to abstain from answering when confidence is low.\n",
      "predicted task:  [{'words': ['question answering', 'answering', 'question answering', 'question answering'], 'value': 0.7436277717, 'top_word': 'question answering'}]\n",
      "predicted method:  [{'words': ['open - domain techniques'], 'value': 0, 'top_word': 'open - domain techniques'}, {'words': ['question answering system'], 'value': 0, 'top_word': 'question answering system'}]\n",
      "actual task:  ['question answering']\n",
      "actual method:  ['question answering system']\n",
      "comparing  question answering  :with:  question answering  ::result:: 100\n",
      "comparing  question answering  :with:  answering  ::result:: 100\n",
      "comparing  question answering  :with:  question answering  ::result:: 100\n",
      "comparing  question answering  :with:  question answering  ::result:: 100\n",
      "comparing  question answering system  :with:  open - domain techniques  ::result:: 38\n",
      "comparing  question answering system  :with:  question answering system  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Unsupervised Term Discovery for Continuous Sign Language. Most of the sign language recognition (SLR) systems rely on supervision for training and available annotated sign language resources are scarce due to the difficulties of manual labeling. Unsupervised discovery of lexical units would facilitate the annotation process and thus lead to better SLR systems. Inspired by the unsupervised spoken term discovery in speech processing field, we investigate whether a similar approach can be applied in sign language to discover repeating lexical units. We adapt an algorithm that is designed for spoken term discovery by using hand shape and pose features instead of speech features. The experiments are run on a large scale continuous sign corpus and the performance is evaluated using gloss level annotations. This work introduces a new task for sign language processing that has not been addressed before.\n",
      "predicted task:  [{'words': ['unsupervised term discovery', 'unsupervised spoken term discovery', 'spoken term discovery'], 'value': 0.25085994100000003, 'top_word': 'unsupervised spoken term discovery'}, {'words': ['continuous sign language', 'sign language recognition', 'slr'], 'value': 0.425698638, 'top_word': 'slr'}]\n",
      "predicted method:  [{'words': ['unsupervised learning'], 'value': 0, 'top_word': 'unsupervised learning'}, {'words': ['spoken term discovery'], 'value': 0, 'top_word': 'spoken term discovery'}, {'words': ['hand shape and pose features'], 'value': 0, 'top_word': 'hand shape and pose features'}]\n",
      "actual task:  ['sign language recognition']\n",
      "actual method:  ['unsupervised term discovery']\n",
      "comparing  sign language recognition  :with:  unsupervised term discovery  ::result:: 32\n",
      "comparing  sign language recognition  :with:  unsupervised spoken term discovery  ::result:: 36\n",
      "comparing  sign language recognition  :with:  spoken term discovery  ::result:: 33\n",
      "comparing  sign language recognition  :with:  continuous sign language  ::result:: 50\n",
      "comparing  sign language recognition  :with:  sign language recognition  ::result:: 100\n",
      "comparing  sign language recognition  :with:  slr  ::result:: 33\n",
      "comparing  unsupervised term discovery  :with:  unsupervised learning  ::result:: 76\n",
      "comparing  unsupervised term discovery  :with:  spoken term discovery  ::result:: 81\n",
      "comparing  unsupervised term discovery  :with:  hand shape and pose features  ::result:: 38\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Improving Relevance Quality in Product Search using High-Precision Query-Product Semantic Similarity. Ensuring relevance quality in product search is a critical task as it impacts the customer's ability to find intended products in the short-term as well as the general perception and trust of the e-commerce system in the long term. In this work we leverage a high-precision crossencoder BERT model for semantic similarity between customer query and products and survey its effectiveness for three ranking applications where offline-generated scores could be used: (1) as an offline metric for estimating relevance quality impact, (2) as a re-ranking feature covering head/torso queries, and (3) as a training objective for optimization. We present results on effectiveness of this strategy for the large e-commerce setting, which has general applicability for choice of other high-precision models and tasks in ranking.\n",
      "predicted task:  [{'words': ['product search'], 'value': 0, 'top_word': 'product search'}, {'words': ['high - precision query - product semantic similarity'], 'value': 0, 'top_word': 'high - precision query - product semantic similarity'}, {'words': ['product search'], 'value': 0, 'top_word': 'product search'}, {'words': ['e - commerce system'], 'value': 0, 'top_word': 'e - commerce system'}, {'words': ['semantic similarity'], 'value': 0, 'top_word': 'semantic similarity'}, {'words': ['ranking applications'], 'value': 0, 'top_word': 'ranking applications'}, {'words': ['re - ranking feature'], 'value': 0, 'top_word': 're - ranking feature'}, {'words': ['optimization'], 'value': 0, 'top_word': 'optimization'}, {'words': ['e - commerce setting'], 'value': 0, 'top_word': 'e - commerce setting'}, {'words': ['ranking'], 'value': 0, 'top_word': 'ranking'}]\n",
      "predicted method:  [{'words': ['high - precision crossencoder bert model'], 'value': 0, 'top_word': 'high - precision crossencoder bert model'}, {'words': ['high - precision models'], 'value': 0, 'top_word': 'high - precision models'}]\n",
      "actual task:  ['relevance quality in product search']\n",
      "actual method:  ['bert']\n",
      "comparing  relevance quality in product search  :with:  product search  ::result:: 100\n",
      "comparing  relevance quality in product search  :with:  high - precision query - product semantic similarity  ::result:: 60\n",
      "comparing  relevance quality in product search  :with:  product search  ::result:: 100\n",
      "comparing  relevance quality in product search  :with:  e - commerce system  ::result:: 37\n",
      "comparing  relevance quality in product search  :with:  semantic similarity  ::result:: 47\n",
      "comparing  relevance quality in product search  :with:  ranking applications  ::result:: 50\n",
      "comparing  relevance quality in product search  :with:  re - ranking feature  ::result:: 36\n",
      "comparing  relevance quality in product search  :with:  optimization  ::result:: 33\n",
      "comparing  relevance quality in product search  :with:  e - commerce setting  ::result:: 36\n",
      "comparing  relevance quality in product search  :with:  ranking  ::result:: 43\n",
      "comparing  bert  :with:  high - precision crossencoder bert model  ::result:: 100\n",
      "comparing  bert  :with:  high - precision models  ::result:: 25\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Initial Draft Guidelines for the Development of the Next-Generation Spoken Language Systems Speech Research Database. To best serve the strategic needs of the DARPA SLS research program by creating the next-generation speech database(s).\n",
      "predicted task:  [{'words': ['next - generation spoken language systems'], 'value': 0, 'top_word': 'next - generation spoken language systems'}]\n",
      "predicted method:  [{'words': ['tokenization'], 'value': 0, 'top_word': 'tokenization'}, {'words': ['part-of-speech tagging'], 'value': 0, 'top_word': 'part-of-speech tagging'}, {'words': ['parsing'], 'value': 0, 'top_word': 'parsing'}]\n",
      "actual task:  ['spoken language systems']\n",
      "actual method:  ['guidelines']\n",
      "comparing  spoken language systems  :with:  next - generation spoken language systems  ::result:: 100\n",
      "comparing  guidelines  :with:  tokenization  ::result:: 30\n",
      "comparing  guidelines  :with:  part-of-speech tagging  ::result:: 32\n",
      "comparing  guidelines  :with:  parsing  ::result:: 29\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "MEDAR: Collaboration between European and Mediterranean Arabic Partners to Support the Development of Language Technology for Arabic. After the successful completion of the NEMLAR project 2003-2005, a new opportunity for a project was opened by the European Commission, and a group of largely the same partners is now executing the MEDAR project. MEDAR will be updating the surveys and BLARK for Arabic already made, and will then focus on machine translation (and other tools for translation) and information retrieval with a focus on language resources, tools and evaluation for these applications. A very important part of the MEDAR project is to reinforce and extend the NEMLAR network and to create a cooperation roadmap for Human Language Technologies for Arabic. It is expected that the cooperation roadmap will attract wide attention from other parties and that it can help create a larger platform for collaborative projects. Finally, the project will focus on dissemination of knowledge about existing resources and tools, as well as actors and activities; this will happen through newsletter, website and an international conference which will follow up on the Cairo conference of 2004. Dissemination to user communities will also be important, e.g. through participation in translators' conferences. The goal of these activities is to create a stronger and lasting collaboration between EU countries and Arabic speaking countries.\n",
      "predicted task:  [{'words': ['machine translation', 'translation'], 'value': 0.3741724193, 'top_word': 'translation'}]\n",
      "predicted method:  [{'words': ['medar'], 'value': 0, 'top_word': 'medar'}, {'words': ['medar'], 'value': 0, 'top_word': 'medar'}, {'words': ['nemlar network'], 'value': 0, 'top_word': 'nemlar network'}]\n",
      "actual task:  ['machine translation', 'information retrieval']\n",
      "actual method:  ['surveys', 'questionnaires']\n",
      "comparing  machine translation  :with:  machine translation  ::result:: 100\n",
      "comparing  machine translation  :with:  translation  ::result:: 100\n",
      "comparing  surveys  :with:  medar  ::result:: 20\n",
      "comparing  surveys  :with:  medar  ::result:: 20\n",
      "comparing  surveys  :with:  nemlar network  ::result:: 29\n",
      "comparing  questionnaires  :with:  medar  ::result:: 40\n",
      "comparing  questionnaires  :with:  medar  ::result:: 40\n",
      "comparing  questionnaires  :with:  nemlar network  ::result:: 29\n",
      "0.5\n",
      "0.0\n",
      "\n",
      "Exploring Stylistic Variation with Age and Income on Twitter. Writing style allows NLP tools to adjust to the traits of an author. In this paper, we explore the relation between stylistic and syntactic features and authors' age and income. We confirm our hypothesis that for numerous feature types writing style is predictive of income even beyond age. We analyze the predictive power of writing style features in a regression task on two data sets of around 5,000 Twitter users each. Additionally, we use our validated features to study daily variations in writing style of users from distinct income groups. Temporal stylistic patterns not only provide novel psychological insight into user behavior, but are useful for future research and applications in social media.\n",
      "predicted task:  [{'words': ['regression task'], 'value': 0, 'top_word': 'regression task'}, {'words': ['social media'], 'value': 0, 'top_word': 'social media'}]\n",
      "predicted method:  [{'words': ['nlp tools'], 'value': 0, 'top_word': 'nlp tools'}]\n",
      "actual task:  ['exploring stylistic variation']\n",
      "actual method:  ['regression', 'stylistic features']\n",
      "comparing  exploring stylistic variation  :with:  regression task  ::result:: 40\n",
      "comparing  exploring stylistic variation  :with:  social media  ::result:: 42\n",
      "comparing  regression  :with:  nlp tools  ::result:: 11\n",
      "comparing  stylistic features  :with:  nlp tools  ::result:: 33\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "ReINTEL Challenge 2020: Vietnamese Fake News Detection usingEnsemble Model with PhoBERT embeddings. Along with the increasing traffic of social networks in Vietnam in recent years, the number of unreliable news has also grown rapidly. As we make decisions based on the information we come across daily, fake news, depending on the severity of the matter, can lead to disastrous consequences. This paper presents our approach for the Fake News Detection on Social Network Sites (SNSs), using an ensemble method with linguistic features extracted using PhoBERT (Nguyen and Nguyen, 2020). Our method achieves AUC score of 0.9521 and got 1 st place on the private test at the 7 th International Workshop on Vietnamese Language and Speech Processing (VLSP). For reproducing the result, the code can be found at https://gitlab.com/thuan.\n",
      "predicted task:  [{'words': ['vietnamese fake news detection', 'fake news detection on social network sites'], 'value': 0.5039985180000001, 'top_word': 'vietnamese fake news detection'}]\n",
      "predicted method:  [{'words': ['phobert embeddings'], 'value': 0, 'top_word': 'phobert embeddings'}, {'words': ['ensemble method'], 'value': 0, 'top_word': 'ensemble method'}, {'words': ['phobert'], 'value': 0, 'top_word': 'phobert'}]\n",
      "actual task:  ['fake news detection']\n",
      "actual method:  ['phobert embeddings', 'ensemble method']\n",
      "comparing  fake news detection  :with:  vietnamese fake news detection  ::result:: 100\n",
      "comparing  fake news detection  :with:  fake news detection on social network sites  ::result:: 100\n",
      "comparing  phobert embeddings  :with:  phobert embeddings  ::result:: 100\n",
      "comparing  phobert embeddings  :with:  ensemble method  ::result:: 41\n",
      "comparing  phobert embeddings  :with:  phobert  ::result:: 100\n",
      "comparing  ensemble method  :with:  ensemble method  ::result:: 100\n",
      "comparing  ensemble method  :with:  phobert  ::result:: 43\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Prta: A System to Support the Analysis of Propaganda Techniques in the News. Recent events, such as the 2016 US Presidential Campaign, Brexit and the COVID-19 \"infodemic\", have brought into the spotlight the dangers of online disinformation. There has been a lot of research focusing on factchecking and disinformation detection. However, little attention has been paid to the specific rhetorical and psychological techniques used to convey propaganda messages. Revealing the use of such techniques can help promote media literacy and critical thinking, and eventually contribute to limiting the impact of \"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion Techniques Analyzer) allows users to explore the articles crawled on a regular basis by highlighting the spans in which propaganda techniques occur and to compare them on the basis of their use of propaganda techniques. The system further reports statistics about the use of such techniques, overall and over time, or according to filtering criteria specified by the user based on time interval, keywords, and/or political orientation of the media. Moreover, it allows users to analyze any text or URL through a dedicated interface or via an API. The system is available online: https://www.tanbih.org/prta.\n",
      "predicted task:  [{'words': ['analysis of propaganda techniques'], 'value': 0, 'top_word': 'analysis of propaganda techniques'}, {'words': ['factchecking and disinformation detection'], 'value': 0, 'top_word': 'factchecking and disinformation detection'}, {'words': ['media literacy'], 'value': 0, 'top_word': 'media literacy'}, {'words': ['critical thinking'], 'value': 0, 'top_word': 'critical thinking'}, {'words': ['disinformation campaigns'], 'value': 0, 'top_word': 'disinformation campaigns'}]\n",
      "predicted method:  [{'words': ['prta', 'prta propaganda persuasion techniques analyzer'], 'value': 0.2848195657, 'top_word': 'prta'}]\n",
      "actual task:  ['analysis of propaganda techniques']\n",
      "actual method:  ['propaganda persuasion techniques analyzer']\n",
      "comparing  analysis of propaganda techniques  :with:  analysis of propaganda techniques  ::result:: 100\n",
      "comparing  analysis of propaganda techniques  :with:  factchecking and disinformation detection  ::result:: 42\n",
      "comparing  analysis of propaganda techniques  :with:  media literacy  ::result:: 43\n",
      "comparing  analysis of propaganda techniques  :with:  critical thinking  ::result:: 35\n",
      "comparing  analysis of propaganda techniques  :with:  disinformation campaigns  ::result:: 38\n",
      "comparing  propaganda persuasion techniques analyzer  :with:  prta  ::result:: 50\n",
      "comparing  propaganda persuasion techniques analyzer  :with:  prta propaganda persuasion techniques analyzer  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Conversation Initiation by Diverse News Contents Introduction. In our everyday chitchat , there is a conversation initiator, who proactively casts an initial utterance to start chatting. However, most existing conversation systems cannot play this role. Previous studies on conversation systems assume that the user always initiates conversation, and have placed emphasis on how to respond to the given user's utterance. As a result, existing conversation systems become passive. Namely they continue waiting until being spoken to by the users. In this paper, we consider the system as a conversation initiator and propose a novel task of generating the initial utterance in open-domain non-task-oriented conversation. Here, in order not to make users bored, it is necessary to generate diverse utterances to initiate conversation without relying on boilerplate utterances like greetings. To this end, we propose to generate initial utterance by summarizing and chatting about news articles, which provide fresh and various contents everyday. To address the lack of the training data for this task, we constructed a novel largescale dataset through crowd-sourcing. We also analyzed the dataset in detail to examine how humans initiate conversations (the dataset will be released to facilitate future research activities). We present several approaches to conversation initiation including information retrieval based and generation based models. Experimental results showed that the proposed models trained on our dataset performed reasonably well and outperformed baselines that utilize automatically collected training data in both automatic and manual evaluation. * This work was done during research internship at Yahoo Japan Corporation. 1 \"Conversation\" in this paper refers to open-domain nontask-oriented conversations and chitchat .\n",
      "predicted task:  [{'words': ['conversation initiation', 'conversation initiator', 'conversation initiation'], 'value': 0.17704412220000001, 'top_word': 'conversation initiation'}]\n",
      "predicted method:  [{'words': ['conversation initiator'], 'value': 0, 'top_word': 'conversation initiator'}, {'words': ['conversation systems'], 'value': 0, 'top_word': 'conversation systems'}, {'words': ['conversation systems'], 'value': 0, 'top_word': 'conversation systems'}, {'words': ['information retrieval'], 'value': 0, 'top_word': 'information retrieval'}, {'words': ['generation based models'], 'value': 0, 'top_word': 'generation based models'}]\n",
      "actual task:  ['conversation systems']\n",
      "actual method:  ['information retrieval', 'generation models']\n",
      "comparing  conversation systems  :with:  conversation initiation  ::result:: 70\n",
      "comparing  conversation systems  :with:  conversation initiator  ::result:: 70\n",
      "comparing  conversation systems  :with:  conversation initiation  ::result:: 70\n",
      "comparing  information retrieval  :with:  conversation initiator  ::result:: 52\n",
      "comparing  information retrieval  :with:  conversation systems  ::result:: 50\n",
      "comparing  information retrieval  :with:  conversation systems  ::result:: 50\n",
      "comparing  information retrieval  :with:  information retrieval  ::result:: 100\n",
      "comparing  information retrieval  :with:  generation based models  ::result:: 52\n",
      "comparing  generation models  :with:  conversation initiator  ::result:: 53\n",
      "comparing  generation models  :with:  conversation systems  ::result:: 59\n",
      "comparing  generation models  :with:  conversation systems  ::result:: 59\n",
      "comparing  generation models  :with:  generation based models  ::result:: 71\n",
      "0.0\n",
      "0.5\n",
      "\n",
      "Categorizing Offensive Language in Social Networks: A Chinese Corpus, Systems and an Explainable Tool. Recently, more and more data have been generated in the online world, filled with offensive language such as threats, swear words or straightforward insults. It is disgraceful for a progressive society, and then the question arises on how language resources and technologies can cope with this challenge. However, previous work only analyzes the problem as a whole but fails to detect particular types of offensive content in a more fine-grained way, mainly because of the lack of annotated data. In this work, we present a densely annotated data-set COLA (Categorizing Offensive LAnguage), consists of fine-grained insulting language, antisocial language and illegal language. We study different strategies for automatically identifying offensive language on COLA data. Further, we design a capsule system with hierarchical attention to aggregate and fully utilize information, which obtains a state-of-the-art result. Results from experiments prove that our hierarchical attention capsule network (HACN) performs significantly better than existing methods in offensive classification with the precision of 94.37% and recall of 95.28%. We also explain what our model has learned with an explanation tool called Integrated Gradients. Meanwhile, our system's processing speed can handle each sentence in 10msec, suggesting the potential for efficient deployment in real situations.\n",
      "predicted task:  [{'words': ['automatically identifying offensive language', 'offensive classification'], 'value': 0.4135538936, 'top_word': 'offensive classification'}, {'words': ['categorizing offensive language in social networks'], 'value': 0.4670377672, 'top_word': 'categorizing offensive language in social networks'}]\n",
      "predicted method:  [{'words': ['hierarchical attention', 'hierarchical attention capsule network'], 'value': 0.4923342392, 'top_word': 'hierarchical attention capsule network'}, {'words': ['capsule system'], 'value': 0.2974184453, 'top_word': 'capsule system'}]\n",
      "actual task:  ['categorizing offensive language']\n",
      "actual method:  ['hierarchical attention capsule network', 'integrated gradients']\n",
      "comparing  categorizing offensive language  :with:  automatically identifying offensive language  ::result:: 77\n",
      "comparing  categorizing offensive language  :with:  offensive classification  ::result:: 62\n",
      "comparing  categorizing offensive language  :with:  categorizing offensive language in social networks  ::result:: 100\n",
      "comparing  hierarchical attention capsule network  :with:  hierarchical attention  ::result:: 100\n",
      "comparing  hierarchical attention capsule network  :with:  hierarchical attention capsule network  ::result:: 100\n",
      "comparing  hierarchical attention capsule network  :with:  capsule system  ::result:: 64\n",
      "comparing  integrated gradients  :with:  capsule system  ::result:: 29\n",
      "1.0\n",
      "0.5\n",
      "\n",
      "Boosting Low-Resource Biomedical QA via Entity-Aware Masking Strategies. Biomedical question-answering (QA) has gained increased attention for its capability to provide users with high-quality information from a vast scientific literature. Although an increasing number of biomedical QA datasets has been recently made available, those resources are still rather limited and expensive to produce. Transfer learning via pre-trained language models (LMs) has been shown as a promising approach to leverage existing general-purpose knowledge. However, finetuning these large models can be costly and time consuming, often yielding limited benefits when adapting to specific themes of specialised domains, such as the COVID-19 literature. To bootstrap further their domain adaptation, we propose a simple yet unexplored approach, which we call biomedical entity-aware masking (BEM). We encourage masked language models to learn entity-centric knowledge based on the pivotal entities characterizing the domain at hand, and employ those entities to drive the LM fine-tuning. The resulting strategy is a downstream process applicable to a wide variety of masked LMs, not requiring additional memory or components in the neural architectures. Experimental results show performance on par with state-of-the-art models on several biomedical QA datasets.\n",
      "predicted task:  [{'words': ['boosting low resource biomedical qa', 'biomedical question answering'], 'value': 0.5877873451, 'top_word': 'biomedical question answering'}]\n",
      "predicted method:  [{'words': ['entity aware masking strategies', 'biomedical entity aware masking'], 'value': 0.5193934441, 'top_word': 'biomedical entity aware masking'}]\n",
      "actual task:  ['question answering', 'domain adaptaion', 'transfer learning']\n",
      "actual method:  ['masked language models', 'language models', 'entity-aware masking']\n",
      "comparing  question answering  :with:  boosting low resource biomedical qa  ::result:: 39\n",
      "comparing  question answering  :with:  biomedical question answering  ::result:: 100\n",
      "comparing  masked language models  :with:  entity aware masking strategies  ::result:: 45\n",
      "comparing  masked language models  :with:  biomedical entity aware masking  ::result:: 41\n",
      "comparing  language models  :with:  entity aware masking strategies  ::result:: 40\n",
      "comparing  language models  :with:  biomedical entity aware masking  ::result:: 40\n",
      "comparing  entity-aware masking  :with:  entity aware masking strategies  ::result:: 95\n",
      "comparing  entity-aware masking  :with:  biomedical entity aware masking  ::result:: 95\n",
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "\n",
      "A Statistical Modeling of the Correlation between Island Effects and Working-memory Capacity for L2 Learners. The cause of island effects has evoked considerable debate within syntax and other fields of linguistics. The two competing approaches stand out: the grammatical analysis; and the working-memory (WM)-based processing analysis. In this paper we report three experiments designed to test one of the premises of the WM-based processing analysis: that the strength of island effects should vary as a function of individual differences in WM capacity. The results show that island effects present even for L2 learners are more likely attributed to grammatical constraints than to limited processing resources.\n",
      "predicted task:  [{'words': ['linguistics'], 'value': 0, 'top_word': 'linguistics'}]\n",
      "predicted method:  [{'words': ['statistical modeling'], 'value': 0, 'top_word': 'statistical modeling'}, {'words': ['working - memory capacity'], 'value': 0, 'top_word': 'working - memory capacity'}, {'words': ['grammatical analysis;'], 'value': 0, 'top_word': 'grammatical analysis;'}, {'words': ['working - memory (wm) - based processing analysis'], 'value': 0, 'top_word': 'working - memory (wm) - based processing analysis'}, {'words': ['wm - based processing analysis'], 'value': 0, 'top_word': 'wm - based processing analysis'}, {'words': ['wm'], 'value': 0, 'top_word': 'wm'}, {'words': ['l2 learners'], 'value': 0, 'top_word': 'l2 learners'}]\n",
      "actual task:  ['statistical modeling']\n",
      "actual method:  ['grammatical analysis', 'working-memory-based processing']\n",
      "comparing  statistical modeling  :with:  linguistics  ::result:: 45\n",
      "comparing  grammatical analysis  :with:  statistical modeling  ::result:: 45\n",
      "comparing  grammatical analysis  :with:  working - memory capacity  ::result:: 36\n",
      "comparing  grammatical analysis  :with:  grammatical analysis;  ::result:: 100\n",
      "comparing  grammatical analysis  :with:  working - memory (wm) - based processing analysis  ::result:: 55\n",
      "comparing  grammatical analysis  :with:  wm - based processing analysis  ::result:: 55\n",
      "comparing  grammatical analysis  :with:  wm  ::result:: 50\n",
      "comparing  grammatical analysis  :with:  l2 learners  ::result:: 45\n",
      "comparing  working-memory-based processing  :with:  statistical modeling  ::result:: 40\n",
      "comparing  working-memory-based processing  :with:  working - memory capacity  ::result:: 68\n",
      "comparing  working-memory-based processing  :with:  working - memory (wm) - based processing analysis  ::result:: 74\n",
      "comparing  working-memory-based processing  :with:  wm - based processing analysis  ::result:: 71\n",
      "comparing  working-memory-based processing  :with:  wm  ::result:: 50\n",
      "comparing  working-memory-based processing  :with:  l2 learners  ::result:: 36\n",
      "0.0\n",
      "0.5\n",
      "\n",
      "A Large-Scale English Multi-Label Twitter Dataset for Cyberbullying and Online Abuse Detection. In this paper, we introduce a new English Twitter-based dataset for online abuse and cyberbullying detection. Comprising 62,587 tweets, this dataset was sourced from Twitter using specific query terms designed to retrieve tweets with high probabilities of various forms of bullying and offensive content, including insult, profanity, sarcasm, threat, porn and exclusion. Analysis performed on the dataset confirmed common cyberbullying themes reported by other studies and revealed interesting relationships between the classes. The dataset was used to train a number of transformer-based deep learning models returning impressive results.\n",
      "predicted task:  [{'words': ['online abuse and cyberbullying detection'], 'value': 0.5617464185000001, 'top_word': 'online abuse and cyberbullying detection'}]\n",
      "predicted method:  [{'words': ['transformer - based deep learning models'], 'value': 0, 'top_word': 'transformer - based deep learning models'}]\n",
      "actual task:  ['online abuse detection']\n",
      "actual method:  ['transformers', 'dataset']\n",
      "comparing  online abuse detection  :with:  online abuse and cyberbullying detection  ::result:: 68\n",
      "comparing  transformers  :with:  transformer - based deep learning models  ::result:: 92\n",
      "0.0\n",
      "0.5\n",
      "\n",
      "The N2 corpus: A semantically annotated collection of Islamist extremist stories. We describe the N2 (Narrative Networks) Corpus, a new language resource. The corpus is unique in three important ways. First, every text in the corpus is a story, which is in contrast to other language resources that may contain stories or story-like texts, but are not specifically curated to contain only stories. Second, the unifying theme of the corpus is material relevant to Islamist Extremists, having been produced by or often referenced by them. Third, every text in the corpus has been annotated for 14 layers of syntax and semantics, including: referring expressions and co-reference; events, time expressions, and temporal relationships; semantic roles; and word senses. In cases where analyzers were not available to do high-quality automatic annotations, layers were manually doubleannotated and adjudicated by trained annotators. The corpus comprises 100 texts and 42,480 words. Most of the texts were originally in Arabic but all are provided in English translation. We explain the motivation for constructing the corpus, the process for selecting the texts, the detailed contents of the corpus itself, the rationale behind the choice of annotation layers, and the annotation procedure.\n",
      "predicted task:  [{'words': ['annotation procedure'], 'value': 0, 'top_word': 'annotation procedure'}]\n",
      "predicted method:  [{'words': ['syntax'], 'value': 0, 'top_word': 'syntax'}, {'words': ['semantics'], 'value': 0, 'top_word': 'semantics'}, {'words': ['co-reference'], 'value': 0, 'top_word': 'co-reference'}, {'words': ['events'], 'value': 0, 'top_word': 'events'}, {'words': ['time expressions'], 'value': 0, 'top_word': 'time expressions'}, {'words': ['temporal relationships'], 'value': 0, 'top_word': 'temporal relationships'}, {'words': ['semantic roles'], 'value': 0, 'top_word': 'semantic roles'}, {'words': ['word senses'], 'value': 0, 'top_word': 'word senses'}]\n",
      "actual task:  ['corpus']\n",
      "actual method:  ['multi-layed annotation', 'annotation procedure']\n",
      "comparing  corpus  :with:  annotation procedure  ::result:: 33\n",
      "comparing  multi-layed annotation  :with:  syntax  ::result:: 50\n",
      "comparing  multi-layed annotation  :with:  semantics  ::result:: 44\n",
      "comparing  multi-layed annotation  :with:  co-reference  ::result:: 25\n",
      "comparing  multi-layed annotation  :with:  events  ::result:: 33\n",
      "comparing  multi-layed annotation  :with:  time expressions  ::result:: 32\n",
      "comparing  multi-layed annotation  :with:  temporal relationships  ::result:: 37\n",
      "comparing  multi-layed annotation  :with:  semantic roles  ::result:: 43\n",
      "comparing  multi-layed annotation  :with:  word senses  ::result:: 27\n",
      "comparing  annotation procedure  :with:  syntax  ::result:: 50\n",
      "comparing  annotation procedure  :with:  semantics  ::result:: 33\n",
      "comparing  annotation procedure  :with:  co-reference  ::result:: 42\n",
      "comparing  annotation procedure  :with:  events  ::result:: 33\n",
      "comparing  annotation procedure  :with:  time expressions  ::result:: 38\n",
      "comparing  annotation procedure  :with:  temporal relationships  ::result:: 35\n",
      "comparing  annotation procedure  :with:  semantic roles  ::result:: 50\n",
      "comparing  annotation procedure  :with:  word senses  ::result:: 27\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Detecting Cognitive Distortions from Patient-Therapist Interactions. An important part of Cognitive Behavioral Therapy (CBT) is to recognize and restructure certain negative thinking patterns that are also known as cognitive distortions. This project aims to detect these distortions using natural language processing. We compare and contrast different types of linguistic features as well as different classification algorithms and explore the limitations of applying these techniques on a small dataset. We find that pretrained Sentence-BERT embeddings to train an SVM classifier yields the best results with an F1-score of 0.79. Lastly, we discuss how this work provides insights into the types of linguistic features that are inherent in cognitive distortions.\n",
      "predicted task:  [{'words': ['detecting cognitive distortions'], 'value': 0, 'top_word': 'detecting cognitive distortions'}, {'words': ['cognitive behavioral therapy'], 'value': 0, 'top_word': 'cognitive behavioral therapy'}]\n",
      "predicted method:  [{'words': ['natural language processing'], 'value': 0, 'top_word': 'natural language processing'}, {'words': ['classification algorithms'], 'value': 0, 'top_word': 'classification algorithms'}, {'words': ['svm classifier'], 'value': 0, 'top_word': 'svm classifier'}]\n",
      "actual task:  ['cognitive distortion detection']\n",
      "actual method:  ['pretrained sentence-bert embeddings', 'svm classifier']\n",
      "comparing  cognitive distortion detection  :with:  detecting cognitive distortions  ::result:: 78\n",
      "comparing  cognitive distortion detection  :with:  cognitive behavioral therapy  ::result:: 57\n",
      "comparing  pretrained sentence-bert embeddings  :with:  natural language processing  ::result:: 33\n",
      "comparing  pretrained sentence-bert embeddings  :with:  classification algorithms  ::result:: 28\n",
      "comparing  pretrained sentence-bert embeddings  :with:  svm classifier  ::result:: 29\n",
      "comparing  svm classifier  :with:  natural language processing  ::result:: 36\n",
      "comparing  svm classifier  :with:  classification algorithms  ::result:: 57\n",
      "comparing  svm classifier  :with:  svm classifier  ::result:: 100\n",
      "1.0\n",
      "0.5\n",
      "\n",
      "Memes in the Wild: Assessing the Generalizability of the Hateful Memes Challenge Dataset. Hateful memes pose a unique challenge for current machine learning systems because their message is derived from both text-and visual-modalities. To this effect, Facebook released the Hateful Memes Challenge, a dataset of memes with pre-extracted text captions, but it is unclear whether these synthetic examples generalize to 'memes in the wild'. In this paper, we collect hateful and non-hateful memes from Pinterest to evaluate out-of-sample performance on models pre-trained on the Facebook dataset. We find that memes in the wild differ in two key aspects: 1) Captions must be extracted via OCR, injecting noise and diminishing performance of multimodal models, and 2) Memes are more diverse than 'traditional memes', including screenshots of conversations or text on a plain background. This paper thus serves as a reality check for the current benchmark of hateful meme detection and its applicability for detecting real world hate.\n",
      "predicted task:  [{'words': ['hateful meme detection', 'detecting real world hate'], 'value': 0.39759027960000004, 'top_word': 'detecting real world hate'}]\n",
      "predicted method:  [{'words': ['machine learning systems'], 'value': 0, 'top_word': 'machine learning systems'}, {'words': ['ocr'], 'value': 0, 'top_word': 'ocr'}, {'words': ['multimodal models'], 'value': 0, 'top_word': 'multimodal models'}]\n",
      "actual task:  ['assessing dataset generalizability', 'hateful memes challenge', 'hateful meme detection']\n",
      "actual method:  ['ocr', 'multimodal models']\n",
      "comparing  assessing dataset generalizability  :with:  hateful meme detection  ::result:: 36\n",
      "comparing  assessing dataset generalizability  :with:  detecting real world hate  ::result:: 40\n",
      "comparing  hateful memes challenge  :with:  hateful meme detection  ::result:: 68\n",
      "comparing  hateful memes challenge  :with:  detecting real world hate  ::result:: 35\n",
      "comparing  hateful meme detection  :with:  hateful meme detection  ::result:: 100\n",
      "comparing  hateful meme detection  :with:  detecting real world hate  ::result:: 36\n",
      "comparing  ocr  :with:  machine learning systems  ::result:: 33\n",
      "comparing  ocr  :with:  ocr  ::result:: 100\n",
      "comparing  ocr  :with:  multimodal models  ::result:: 33\n",
      "comparing  multimodal models  :with:  machine learning systems  ::result:: 29\n",
      "comparing  multimodal models  :with:  multimodal models  ::result:: 100\n",
      "0.3333333333333333\n",
      "1.0\n",
      "\n",
      "Encoding Terms from a Scientific Domain in a Terminological Database: Methodology and Criteria. This paper reports on the main phases of a research which aims at enhancing a maritime terminological database by means of a set of terms belonging to meteorology. The structure of the terminological database, according to EuroWordNet/ItalWordNet model is described; the criteria used to build corpora of specialized texts are explained as well as the use of the corpora as source for term selection and extraction. The contribution of the semantic databases is taken into account: on the one hand, the most recent version of the Princeton WordNet has been exploited as reference for comparing and evaluating synsets; on the other hand, the Italian WordNet has been employed as source for exporting synsets to be coded in the terminological resource. The set of semantic relations useful to codify new terms belonging to the discipline of meteorology is examined, revising the semantic relations provided by the IWN model, introducing new relations which are more suitably tailored to specific requirements either scientific or pragmatic. The need for a particular relation is highlighted to represent the mental association which is made when a term intuitively recalls another term, but they are neither synonyms nor connected by means of a hyperonymy/hyponymy relation.\n",
      "predicted task:  [{'words': ['encoding terms'], 'value': 0, 'top_word': 'encoding terms'}, {'words': ['maritime terminological database'], 'value': 0, 'top_word': 'maritime terminological database'}, {'words': ['term selection and extraction'], 'value': 0, 'top_word': 'term selection and extraction'}, {'words': ['evaluating synsets;'], 'value': 0, 'top_word': 'evaluating synsets;'}, {'words': ['exporting synsets'], 'value': 0, 'top_word': 'exporting synsets'}, {'words': ['meteorology'], 'value': 0, 'top_word': 'meteorology'}]\n",
      "predicted method:  [{'words': ['eurowordnet/italwordnet model'], 'value': 0, 'top_word': 'eurowordnet/italwordnet model'}, {'words': ['iwn model'], 'value': 0, 'top_word': 'iwn model'}, {'words': ['hyperonymy/hyponymy relation'], 'value': 0, 'top_word': 'hyperonymy/hyponymy relation'}]\n",
      "actual task:  ['terminological database']\n",
      "actual method:  ['encoding terms']\n",
      "comparing  terminological database  :with:  encoding terms  ::result:: 36\n",
      "comparing  terminological database  :with:  maritime terminological database  ::result:: 100\n",
      "comparing  terminological database  :with:  term selection and extraction  ::result:: 39\n",
      "comparing  terminological database  :with:  evaluating synsets;  ::result:: 32\n",
      "comparing  terminological database  :with:  exporting synsets  ::result:: 41\n",
      "comparing  terminological database  :with:  meteorology  ::result:: 64\n",
      "comparing  encoding terms  :with:  eurowordnet/italwordnet model  ::result:: 36\n",
      "comparing  encoding terms  :with:  iwn model  ::result:: 44\n",
      "comparing  encoding terms  :with:  hyperonymy/hyponymy relation  ::result:: 29\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Invited Talk: Lessons from the MALACH Project: Applying New Technologies to Improve Intellectual Access to Large Oral History Collections. In this talk I will describe the goals of the MALACH project (Multilingual Access to Large Spoken Archives) and our research results. I'll begin by describing the unique characteristics of the oral history collection that we used, in which Holocaust survivors, witnesses and rescuers were interviewed in several languages. Each interview has been digitized and extensively catalogued by subject matter experts, thus producing a remarkably rich collection for the application of machine learning techniques. Automatic speech recognition techniques originally developed for the domain of conversational telephone speech were adapted to process these materials with word error rates that are adequate to provide useful features to support interactive search and automated clustering, boundary detection, and topic classification tasks. As I describe our results, I will focus particularly on the evaluation methods that that we have used to assess the potential utility of this technology. I'll conclude with some remarks about possible future directions for research on applying new technologies to improve intellectual access to oral history and other spoken word collections.\n",
      "predicted task:  [{'words': ['malach project'], 'value': 0, 'top_word': 'malach project'}, {'words': ['interactive search'], 'value': 0, 'top_word': 'interactive search'}, {'words': ['automated clustering'], 'value': 0, 'top_word': 'automated clustering'}, {'words': ['boundary detection'], 'value': 0, 'top_word': 'boundary detection'}, {'words': ['topic classification tasks'], 'value': 0, 'top_word': 'topic classification tasks'}]\n",
      "predicted method:  [{'words': ['malach project'], 'value': 0, 'top_word': 'malach project'}, {'words': ['machine learning techniques'], 'value': 0, 'top_word': 'machine learning techniques'}, {'words': ['automatic speech recognition techniques'], 'value': 0, 'top_word': 'automatic speech recognition techniques'}]\n",
      "actual task:  ['intellectual access to large oral history collections', 'topic classification', 'boundary detection']\n",
      "actual method:  ['automated clustering', 'automatic speech recognition techniques']\n",
      "comparing  intellectual access to large oral history collections  :with:  malach project  ::result:: 43\n",
      "comparing  intellectual access to large oral history collections  :with:  interactive search  ::result:: 50\n",
      "comparing  intellectual access to large oral history collections  :with:  automated clustering  ::result:: 45\n",
      "comparing  intellectual access to large oral history collections  :with:  boundary detection  ::result:: 56\n",
      "comparing  intellectual access to large oral history collections  :with:  topic classification tasks  ::result:: 42\n",
      "comparing  topic classification  :with:  malach project  ::result:: 29\n",
      "comparing  topic classification  :with:  interactive search  ::result:: 29\n",
      "comparing  topic classification  :with:  automated clustering  ::result:: 47\n",
      "comparing  topic classification  :with:  boundary detection  ::result:: 33\n",
      "comparing  topic classification  :with:  topic classification tasks  ::result:: 100\n",
      "comparing  boundary detection  :with:  malach project  ::result:: 36\n",
      "comparing  boundary detection  :with:  interactive search  ::result:: 33\n",
      "comparing  boundary detection  :with:  automated clustering  ::result:: 46\n",
      "comparing  boundary detection  :with:  boundary detection  ::result:: 100\n",
      "comparing  automated clustering  :with:  malach project  ::result:: 36\n",
      "comparing  automated clustering  :with:  machine learning techniques  ::result:: 45\n",
      "comparing  automated clustering  :with:  automatic speech recognition techniques  ::result:: 55\n",
      "comparing  automatic speech recognition techniques  :with:  malach project  ::result:: 50\n",
      "comparing  automatic speech recognition techniques  :with:  machine learning techniques  ::result:: 67\n",
      "comparing  automatic speech recognition techniques  :with:  automatic speech recognition techniques  ::result:: 100\n",
      "0.6666666666666666\n",
      "0.5\n",
      "\n",
      "Contrastive Analysis with Predictive Power: Typology Driven Estimation of Grammatical Error Distributions in ESL. This work examines the impact of crosslinguistic transfer on grammatical errors in English as Second Language (ESL) texts. Using a computational framework that formalizes the theory of Contrastive Analysis (CA), we demonstrate that language specific error distributions in ESL writing can be predicted from the typological properties of the native language and their relation to the typology of English. Our typology driven model enables to obtain accurate estimates of such distributions without access to any ESL data for the target languages. Furthermore, we present a strategy for adjusting our method to low-resource languages that lack typological documentation using a bootstrapping approach which approximates native language typology from ESL texts. Finally, we show that our framework is instrumental for linguistic inquiry seeking to identify first language factors that contribute to a wide range of difficulties in second language acquisition.\n",
      "predicted task:  [{'words': ['esl', 'esl', 'esl'], 'value': 0.6191312571, 'top_word': 'esl'}]\n",
      "predicted method:  [{'words': ['contrastive analysis', 'theory of contrastive analysis'], 'value': 0.1391729303, 'top_word': 'contrastive analysis'}]\n",
      "actual task:  ['contrastive analysis', 'typology driven estimation']\n",
      "actual method:  ['bootstrapping']\n",
      "comparing  contrastive analysis  :with:  esl  ::result:: 33\n",
      "comparing  contrastive analysis  :with:  esl  ::result:: 33\n",
      "comparing  contrastive analysis  :with:  esl  ::result:: 33\n",
      "comparing  typology driven estimation  :with:  esl  ::result:: 67\n",
      "comparing  typology driven estimation  :with:  esl  ::result:: 67\n",
      "comparing  typology driven estimation  :with:  esl  ::result:: 67\n",
      "comparing  bootstrapping  :with:  contrastive analysis  ::result:: 38\n",
      "comparing  bootstrapping  :with:  theory of contrastive analysis  ::result:: 38\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "HUB@DravidianLangTech-EACL2021: Identify and Classify Offensive Text in Multilingual Code Mixing in Social Media. This paper introduces the system description of the HUB team participating in Dravidian-LangTech-EACL2021: Offensive Language Identification in Dravidian Languages. The theme of this shared task is the detection of offensive content in social media. Among the known tasks related to offensive speech detection, this is the first task to detect offensive comments posted in social media comments in the Dravidian language. The task organizer team provided us with the code-mixing task data set mainly composed of three different languages: Malayalam, Kannada, and Tamil. The tasks on the code mixed data in these three different languages can be seen as three different comment/post-level classification tasks. The task on the Malayalam data set is a five-category classification task, and the Kannada and Tamil language data sets are two six-category classification tasks. Based on our analysis of the task description and task data set, we chose to use the multilingual BERT model to complete this task. In this paper, we will discuss our fine-tuning methods, models, experiments, and results.\n",
      "predicted task:  [{'words': ['detection of offensive content in social media', 'offensive speech detection'], 'value': 0.2880212888, 'top_word': 'offensive speech detection'}, {'words': ['classify offensive text', 'commentpost level classification tasks', 'five category classification task', 'six category classification tasks'], 'value': 0.2782902457, 'top_word': 'five category classification task'}, {'words': ['offensive language identification'], 'value': 0.5059614778, 'top_word': 'offensive language identification'}]\n",
      "predicted method:  [{'words': ['hub@dravidianlangtech - eacl2021'], 'value': 0, 'top_word': 'hub@dravidianlangtech - eacl2021'}, {'words': ['multilingual bert model'], 'value': 0, 'top_word': 'multilingual bert model'}, {'words': ['fine - tuning methods'], 'value': 0, 'top_word': 'fine - tuning methods'}]\n",
      "actual task:  ['offensive language identification']\n",
      "actual method:  ['multilingual bert']\n",
      "comparing  offensive language identification  :with:  detection of offensive content in social media  ::result:: 55\n",
      "comparing  offensive language identification  :with:  offensive speech detection  ::result:: 62\n",
      "comparing  offensive language identification  :with:  classify offensive text  ::result:: 48\n",
      "comparing  offensive language identification  :with:  commentpost level classification tasks  ::result:: 55\n",
      "comparing  offensive language identification  :with:  five category classification task  ::result:: 52\n",
      "comparing  offensive language identification  :with:  six category classification tasks  ::result:: 45\n",
      "comparing  offensive language identification  :with:  offensive language identification  ::result:: 100\n",
      "comparing  multilingual bert  :with:  hub@dravidianlangtech - eacl2021  ::result:: 35\n",
      "comparing  multilingual bert  :with:  multilingual bert model  ::result:: 100\n",
      "comparing  multilingual bert  :with:  fine - tuning methods  ::result:: 41\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "On the unification of syntactic annotations under the Stanford dependency scheme: A case study on BioInfer and GENIA. Several incompatible syntactic annotation schemes are currently used by parsers and corpora in biomedical information extraction. The recently introduced Stanford dependency scheme has been suggested to be a suitable unifying syntax formalism. In this paper, we present a step towards such unification by creating a conversion from the Link Grammar to the Stanford scheme. Further, we create a version of the BioInfer corpus with syntactic annotation in this scheme. We present an application-oriented evaluation of the transformation and assess the suitability of the scheme and our conversion to the unification of the syntactic annotations of BioInfer and the GENIA Treebank. We find that a highly reliable conversion is both feasible to create and practical, increasing the applicability of both the parser and the corpus to information extraction.\n",
      "predicted task:  [{'words': ['biomedical information extraction', 'information extraction'], 'value': 0.1767408028, 'top_word': 'biomedical information extraction'}]\n",
      "predicted method:  [{'words': ['stanford dependency scheme'], 'value': 0, 'top_word': 'stanford dependency scheme'}, {'words': ['syntactic annotation schemes'], 'value': 0, 'top_word': 'syntactic annotation schemes'}, {'words': ['parsers'], 'value': 0, 'top_word': 'parsers'}, {'words': ['corpora'], 'value': 0, 'top_word': 'corpora'}, {'words': ['stanford dependency scheme'], 'value': 0, 'top_word': 'stanford dependency scheme'}, {'words': ['unifying syntax formalism'], 'value': 0, 'top_word': 'unifying syntax formalism'}, {'words': ['link grammar'], 'value': 0, 'top_word': 'link grammar'}, {'words': ['stanford scheme'], 'value': 0, 'top_word': 'stanford scheme'}, {'words': ['bioinfer'], 'value': 0, 'top_word': 'bioinfer'}, {'words': ['parser'], 'value': 0, 'top_word': 'parser'}]\n",
      "actual task:  ['biomedical information extraction']\n",
      "actual method:  ['dependency schemes', 'bioinfer', 'genia treebank']\n",
      "comparing  biomedical information extraction  :with:  biomedical information extraction  ::result:: 100\n",
      "comparing  biomedical information extraction  :with:  information extraction  ::result:: 100\n",
      "comparing  dependency schemes  :with:  stanford dependency scheme  ::result:: 97\n",
      "comparing  dependency schemes  :with:  syntactic annotation schemes  ::result:: 56\n",
      "comparing  dependency schemes  :with:  parsers  ::result:: 43\n",
      "comparing  dependency schemes  :with:  corpora  ::result:: 14\n",
      "comparing  dependency schemes  :with:  stanford dependency scheme  ::result:: 97\n",
      "comparing  dependency schemes  :with:  unifying syntax formalism  ::result:: 28\n",
      "comparing  dependency schemes  :with:  link grammar  ::result:: 25\n",
      "comparing  dependency schemes  :with:  stanford scheme  ::result:: 60\n",
      "comparing  dependency schemes  :with:  bioinfer  ::result:: 25\n",
      "comparing  dependency schemes  :with:  parser  ::result:: 33\n",
      "comparing  bioinfer  :with:  syntactic annotation schemes  ::result:: 38\n",
      "comparing  bioinfer  :with:  parsers  ::result:: 31\n",
      "comparing  bioinfer  :with:  corpora  ::result:: 29\n",
      "comparing  bioinfer  :with:  stanford dependency scheme  ::result:: 38\n",
      "comparing  bioinfer  :with:  unifying syntax formalism  ::result:: 38\n",
      "comparing  bioinfer  :with:  link grammar  ::result:: 38\n",
      "comparing  bioinfer  :with:  stanford scheme  ::result:: 38\n",
      "comparing  bioinfer  :with:  bioinfer  ::result:: 100\n",
      "comparing  bioinfer  :with:  parser  ::result:: 33\n",
      "comparing  genia treebank  :with:  syntactic annotation schemes  ::result:: 36\n",
      "comparing  genia treebank  :with:  parsers  ::result:: 43\n",
      "comparing  genia treebank  :with:  corpora  ::result:: 29\n",
      "comparing  genia treebank  :with:  stanford dependency scheme  ::result:: 36\n",
      "comparing  genia treebank  :with:  unifying syntax formalism  ::result:: 43\n",
      "comparing  genia treebank  :with:  link grammar  ::result:: 33\n",
      "comparing  genia treebank  :with:  stanford scheme  ::result:: 29\n",
      "comparing  genia treebank  :with:  parser  ::result:: 50\n",
      "1.0\n",
      "0.6666666666666666\n",
      "\n",
      "A Participant-based Approach for Event Summarization Using Twitter Streams. Twitter offers an unprecedented advantage on live reporting of the events happening around the world. However, summarizing the Twitter event has been a challenging task that was not fully explored in the past. In this paper, we propose a participant-based event summarization approach that \"zooms-in\" the Twitter event streams to the participant level, detects the important sub-events associated with each participant using a novel mixture model that combines the \"burstiness\" and \"cohesiveness\" properties of the event tweets, and generates the event summaries progressively. We evaluate the proposed approach on different event types. Results show that the participantbased approach can effectively capture the sub-events that have otherwise been shadowed by the long-tail of other dominant sub-events, yielding summaries with considerably better coverage than the state-of-the-art.\n",
      "predicted task:  [{'words': ['event summarization', 'summarization'], 'value': 0.5334043801, 'top_word': 'summarization'}]\n",
      "predicted method:  [{'words': ['participant - based approach'], 'value': 0, 'top_word': 'participant - based approach'}, {'words': ['mixture model'], 'value': 0, 'top_word': 'mixture model'}, {'words': ['participantbased approach'], 'value': 0, 'top_word': 'participantbased approach'}]\n",
      "actual task:  ['event summarization']\n",
      "actual method:  ['participant-based approach']\n",
      "comparing  event summarization  :with:  event summarization  ::result:: 100\n",
      "comparing  event summarization  :with:  summarization  ::result:: 100\n",
      "comparing  participant-based approach  :with:  participant - based approach  ::result:: 92\n",
      "comparing  participant-based approach  :with:  mixture model  ::result:: 31\n",
      "comparing  participant-based approach  :with:  participantbased approach  ::result:: 96\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents. We present ADVISER 1-an open-source, multi-domain dialog system toolkit that enables the development of multi-modal (incorporating speech, text and vision), sociallyengaged (e.g. emotion recognition, engagement level prediction and backchanneling) conversational agents. The final Python-based implementation of our toolkit is flexible, easy to use, and easy to extend not only for technically experienced users, such as machine learning researchers, but also for less technically experienced users, such as linguists or cognitive scientists, thereby providing a flexible platform for collaborative research.\n",
      "predicted task:  [{'words': ['multi - modal , multi - domain and socially - engaged conversational agents'], 'value': 0, 'top_word': 'multi - modal , multi - domain and socially - engaged conversational agents'}, {'words': ['multi - modal (incorporating speech'], 'value': 0, 'top_word': 'multi - modal (incorporating speech'}, {'words': ['vision)'], 'value': 0, 'top_word': 'vision)'}, {'words': ['emotion recognition'], 'value': 0, 'top_word': 'emotion recognition'}, {'words': ['engagement level prediction'], 'value': 0, 'top_word': 'engagement level prediction'}, {'words': ['backchanneling) conversational agents'], 'value': 0, 'top_word': 'backchanneling) conversational agents'}, {'words': ['machine learning researchers'], 'value': 0, 'top_word': 'machine learning researchers'}, {'words': ['linguists'], 'value': 0, 'top_word': 'linguists'}, {'words': ['collaborative research'], 'value': 0, 'top_word': 'collaborative research'}]\n",
      "predicted method:  [{'words': ['adviser', 'adviser'], 'value': 0.7977035344000001, 'top_word': 'adviser'}]\n",
      "actual task:  ['multi-domain dialog system']\n",
      "actual method:  ['python']\n",
      "comparing  multi-domain dialog system  :with:  multi - modal , multi - domain and socially - engaged conversational agents  ::result:: 62\n",
      "comparing  multi-domain dialog system  :with:  multi - modal (incorporating speech  ::result:: 46\n",
      "comparing  multi-domain dialog system  :with:  vision)  ::result:: 29\n",
      "comparing  multi-domain dialog system  :with:  emotion recognition  ::result:: 42\n",
      "comparing  multi-domain dialog system  :with:  engagement level prediction  ::result:: 23\n",
      "comparing  multi-domain dialog system  :with:  backchanneling) conversational agents  ::result:: 38\n",
      "comparing  multi-domain dialog system  :with:  machine learning researchers  ::result:: 38\n",
      "comparing  multi-domain dialog system  :with:  linguists  ::result:: 44\n",
      "comparing  multi-domain dialog system  :with:  collaborative research  ::result:: 27\n",
      "comparing  python  :with:  adviser  ::result:: 0\n",
      "comparing  python  :with:  adviser  ::result:: 0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Legal NERC with ontologies, Wikipedia and curriculum learning. In this paper, we present a Wikipediabased approach to develop resources for the legal domain. We establish a mapping between a legal domain ontology, LKIF (Hoekstra et al., 2007), and a Wikipediabased ontology, YAGO (Suchanek et al., 2007), and through that we populate LKIF. Moreover, we use the mentions of those entities in Wikipedia text to train a specific Named Entity Recognizer and Classifier. We find that this classifier works well in the Wikipedia, but, as could be expected, performance decreases in a corpus of judgments of the European Court of Human Rights. However, this tool will be used as a preprocess for human annotation. We resort to a technique called curriculum learning aimed to overcome problems of overfitting by learning increasingly more complex concepts. However, we find that in this particular setting, the method works best by learning from most specific to most general concepts, not the other way round.\n",
      "predicted task:  [{'words': ['legal nerc', 'wikipediabased approach'], 'value': 0.3475280972, 'top_word': 'legal nerc'}]\n",
      "predicted method:  [{'words': ['wikipedia'], 'value': 0, 'top_word': 'wikipedia'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}, {'words': ['wikipediabased approach'], 'value': 0, 'top_word': 'wikipediabased approach'}, {'words': ['lkif'], 'value': 0, 'top_word': 'lkif'}, {'words': ['lkif'], 'value': 0, 'top_word': 'lkif'}, {'words': ['named entity recognizer and classifier'], 'value': 0, 'top_word': 'named entity recognizer and classifier'}, {'words': ['curriculum learning'], 'value': 0, 'top_word': 'curriculum learning'}]\n",
      "actual task:  ['legal domain ontology']\n",
      "actual method:  ['named entity recognizer', 'classifier']\n",
      "comparing  legal domain ontology  :with:  legal nerc  ::result:: 60\n",
      "comparing  legal domain ontology  :with:  wikipediabased approach  ::result:: 24\n",
      "comparing  named entity recognizer  :with:  wikipedia  ::result:: 22\n",
      "comparing  named entity recognizer  :with:  curriculum learning  ::result:: 32\n",
      "comparing  named entity recognizer  :with:  wikipediabased approach  ::result:: 26\n",
      "comparing  named entity recognizer  :with:  lkif  ::result:: 25\n",
      "comparing  named entity recognizer  :with:  lkif  ::result:: 25\n",
      "comparing  named entity recognizer  :with:  named entity recognizer and classifier  ::result:: 100\n",
      "comparing  named entity recognizer  :with:  curriculum learning  ::result:: 32\n",
      "comparing  classifier  :with:  wikipedia  ::result:: 33\n",
      "comparing  classifier  :with:  curriculum learning  ::result:: 30\n",
      "comparing  classifier  :with:  wikipediabased approach  ::result:: 40\n",
      "comparing  classifier  :with:  lkif  ::result:: 50\n",
      "comparing  classifier  :with:  lkif  ::result:: 50\n",
      "comparing  classifier  :with:  curriculum learning  ::result:: 30\n",
      "0.0\n",
      "0.5\n",
      "\n",
      "Safety Information Mining --- What can NLP do in a disaster---. This paper describes efforts of NLP researchers to create a system to aid the relief efforts during the 2011 East Japan Earthquake. Specifically, we created a system to mine information regarding the safety of people in the disaster-stricken area from Twitter, a massive yet highly unorganized information source. We describe the large scale collaborative effort to rapidly create robust and effective systems for word segmentation, named entity recognition, and tweet classification. As a result of our efforts, we were able to effectively deliver new information about the safety of over 100 people in the disasterstricken area to a central repository for safety information.\n",
      "predicted task:  [{'words': ['safety information mining'], 'value': 0, 'top_word': 'safety information mining'}, {'words': ['nlp researchers'], 'value': 0, 'top_word': 'nlp researchers'}, {'words': ['relief efforts'], 'value': 0, 'top_word': 'relief efforts'}, {'words': ['word segmentation'], 'value': 0, 'top_word': 'word segmentation'}, {'words': ['named entity recognition'], 'value': 0, 'top_word': 'named entity recognition'}, {'words': ['tweet classification'], 'value': 0, 'top_word': 'tweet classification'}, {'words': ['safety information'], 'value': 0, 'top_word': 'safety information'}]\n",
      "predicted method:  [{'words': ['nlp'], 'value': 0, 'top_word': 'nlp'}]\n",
      "actual task:  ['information mining']\n",
      "actual method:  ['robust and effective systems']\n",
      "comparing  information mining  :with:  safety information mining  ::result:: 100\n",
      "comparing  information mining  :with:  nlp researchers  ::result:: 20\n",
      "comparing  information mining  :with:  relief efforts  ::result:: 21\n",
      "comparing  information mining  :with:  word segmentation  ::result:: 48\n",
      "comparing  information mining  :with:  named entity recognition  ::result:: 44\n",
      "comparing  information mining  :with:  tweet classification  ::result:: 39\n",
      "comparing  information mining  :with:  safety information  ::result:: 76\n",
      "comparing  robust and effective systems  :with:  nlp  ::result:: 33\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "When does text prediction benefit from additional context? An exploration of contextual signals for chat and email messages. Email and chat communication tools are increasingly important for completing daily tasks. Accurate real-time phrase completion can save time and bolster productivity. Modern text prediction algorithms are based on large language models which typically rely on the prior words in a message to predict a completion. We examine how additional contextual signals (from previous messages, time, and subject) affect the performance of a commercial text prediction model. We compare contextual text prediction in chat and email messages from two of the largest commercial platforms Microsoft Teams and Outlook, finding that contextual signals contribute to performance differently between these scenarios. On emails, time context is most beneficial with small relative gains of 2% over baseline. Whereas, in chat scenarios, using a tailored set of previous messages as context yields relative improvements over the baseline between 9.3% and 18.6% across various critical serviceoriented text prediction metrics.\n",
      "predicted task:  [{'words': ['text prediction', 'contextual text prediction'], 'value': 0.7365233898, 'top_word': 'contextual text prediction'}]\n",
      "predicted method:  [{'words': ['text prediction algorithms'], 'value': 0, 'top_word': 'text prediction algorithms'}, {'words': ['large language models'], 'value': 0, 'top_word': 'large language models'}, {'words': ['text prediction model'], 'value': 0, 'top_word': 'text prediction model'}]\n",
      "actual task:  ['text prediction']\n",
      "actual method:  ['large language models']\n",
      "comparing  text prediction  :with:  text prediction  ::result:: 100\n",
      "comparing  text prediction  :with:  contextual text prediction  ::result:: 100\n",
      "comparing  large language models  :with:  text prediction algorithms  ::result:: 33\n",
      "comparing  large language models  :with:  large language models  ::result:: 100\n",
      "comparing  large language models  :with:  text prediction model  ::result:: 44\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "An Annotated Corpus for Machine Reading of Instructions in Wet Lab Protocols. We describe an effort to annotate a corpus of natural language instructions consisting of 622 wet lab protocols to facilitate automatic or semi-automatic conversion of protocols into a machine-readable format and benefit biological research. Experimental results demonstrate the utility of our corpus for developing machine learning approaches to shallow semantic parsing of instructional texts. We make our annotated Wet Lab Protocol Corpus available to the research community. 1 1 The dataset is available on the authors' websites.\n",
      "predicted task:  [{'words': ['machine reading of instructions'], 'value': 0, 'top_word': 'machine reading of instructions'}, {'words': ['wet lab protocols'], 'value': 0, 'top_word': 'wet lab protocols'}, {'words': ['automatic or semi - automatic conversion of protocols'], 'value': 0, 'top_word': 'automatic or semi - automatic conversion of protocols'}, {'words': ['machine - readable format'], 'value': 0, 'top_word': 'machine - readable format'}, {'words': ['biological research'], 'value': 0, 'top_word': 'biological research'}, {'words': ['shallow semantic parsing of instructional texts'], 'value': 0, 'top_word': 'shallow semantic parsing of instructional texts'}]\n",
      "predicted method:  [{'words': ['machine learning approaches'], 'value': 0, 'top_word': 'machine learning approaches'}]\n",
      "actual task:  ['conversion of protocols into a machine-readable format']\n",
      "actual method:  ['annotated corpus']\n",
      "comparing  conversion of protocols into a machine-readable format  :with:  machine reading of instructions  ::result:: 48\n",
      "comparing  conversion of protocols into a machine-readable format  :with:  wet lab protocols  ::result:: 65\n",
      "comparing  conversion of protocols into a machine-readable format  :with:  automatic or semi - automatic conversion of protocols  ::result:: 43\n",
      "comparing  conversion of protocols into a machine-readable format  :with:  machine - readable format  ::result:: 96\n",
      "comparing  conversion of protocols into a machine-readable format  :with:  biological research  ::result:: 32\n",
      "comparing  conversion of protocols into a machine-readable format  :with:  shallow semantic parsing of instructional texts  ::result:: 38\n",
      "comparing  annotated corpus  :with:  machine learning approaches  ::result:: 38\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Stance Classification, Outcome Prediction, and Impact Assessment: NLP Tasks for Studying Group Decision-Making. In group decision-making, the nuanced process of conflict and resolution that leads to consensus formation is closely tied to the quality of decisions made. Behavioral scientists rarely have rich access to process variables, though, as unstructured discussion transcripts are difficult to analyze. Here, we define ways for NLP researchers to contribute to the study of groups and teams. We introduce three tasks alongside a large new corpus of over 400,000 group debates on Wikipedia. We describe the tasks and their importance, then provide baselines showing that BERT contextualized word embeddings consistently outperform other language representations.\n",
      "predicted task:  [{'words': ['stance classification'], 'value': 0, 'top_word': 'stance classification'}, {'words': ['outcome prediction'], 'value': 0, 'top_word': 'outcome prediction'}, {'words': ['impact assessment'], 'value': 0, 'top_word': 'impact assessment'}, {'words': ['nlp tasks'], 'value': 0, 'top_word': 'nlp tasks'}, {'words': ['group decision - making'], 'value': 0, 'top_word': 'group decision - making'}, {'words': ['group decision - making'], 'value': 0, 'top_word': 'group decision - making'}, {'words': ['nuanced process of conflict and resolution'], 'value': 0, 'top_word': 'nuanced process of conflict and resolution'}, {'words': ['consensus formation'], 'value': 0, 'top_word': 'consensus formation'}, {'words': ['behavioral scientists'], 'value': 0, 'top_word': 'behavioral scientists'}, {'words': ['nlp researchers'], 'value': 0, 'top_word': 'nlp researchers'}]\n",
      "predicted method:  [{'words': ['bert contextualized word embeddings'], 'value': 0, 'top_word': 'bert contextualized word embeddings'}, {'words': ['language representations'], 'value': 0, 'top_word': 'language representations'}]\n",
      "actual task:  ['stance classification', 'outcome prediction', 'and impact assessment']\n",
      "actual method:  ['corpus', 'bert']\n",
      "comparing  stance classification  :with:  stance classification  ::result:: 100\n",
      "comparing  stance classification  :with:  outcome prediction  ::result:: 50\n",
      "comparing  stance classification  :with:  impact assessment  ::result:: 41\n",
      "comparing  stance classification  :with:  nlp tasks  ::result:: 56\n",
      "comparing  stance classification  :with:  group decision - making  ::result:: 33\n",
      "comparing  stance classification  :with:  group decision - making  ::result:: 33\n",
      "comparing  stance classification  :with:  nuanced process of conflict and resolution  ::result:: 57\n",
      "comparing  stance classification  :with:  consensus formation  ::result:: 53\n",
      "comparing  stance classification  :with:  behavioral scientists  ::result:: 29\n",
      "comparing  stance classification  :with:  nlp researchers  ::result:: 27\n",
      "comparing  outcome prediction  :with:  outcome prediction  ::result:: 100\n",
      "comparing  outcome prediction  :with:  impact assessment  ::result:: 29\n",
      "comparing  outcome prediction  :with:  nlp tasks  ::result:: 22\n",
      "comparing  outcome prediction  :with:  group decision - making  ::result:: 44\n",
      "comparing  outcome prediction  :with:  group decision - making  ::result:: 44\n",
      "comparing  outcome prediction  :with:  nuanced process of conflict and resolution  ::result:: 44\n",
      "comparing  outcome prediction  :with:  consensus formation  ::result:: 44\n",
      "comparing  outcome prediction  :with:  behavioral scientists  ::result:: 28\n",
      "comparing  outcome prediction  :with:  nlp researchers  ::result:: 27\n",
      "comparing  and impact assessment  :with:  impact assessment  ::result:: 100\n",
      "comparing  and impact assessment  :with:  nlp tasks  ::result:: 56\n",
      "comparing  and impact assessment  :with:  group decision - making  ::result:: 29\n",
      "comparing  and impact assessment  :with:  group decision - making  ::result:: 29\n",
      "comparing  and impact assessment  :with:  nuanced process of conflict and resolution  ::result:: 48\n",
      "comparing  and impact assessment  :with:  consensus formation  ::result:: 37\n",
      "comparing  and impact assessment  :with:  behavioral scientists  ::result:: 39\n",
      "comparing  and impact assessment  :with:  nlp researchers  ::result:: 40\n",
      "comparing  corpus  :with:  bert contextualized word embeddings  ::result:: 33\n",
      "comparing  corpus  :with:  language representations  ::result:: 33\n",
      "comparing  bert  :with:  bert contextualized word embeddings  ::result:: 100\n",
      "comparing  bert  :with:  language representations  ::result:: 50\n",
      "1.0\n",
      "0.5\n",
      "\n",
      "Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning. How fake news goes viral via social media? How does its propagation pattern differ from real stories? In this paper, we attempt to address the problem of identifying rumors, i.e., fake information, out of microblog posts based on their propagation structure. We firstly model microblog posts diffusion with propagation trees, which provide valuable clues on how an original message is transmitted and developed over time. We then propose a kernel-based method called Propagation Tree Kernel, which captures high-order patterns differentiating different types of rumors by evaluating the similarities between their propagation tree structures. Experimental results on two real-world datasets demonstrate that the proposed kernel-based approach can detect rumors more quickly and accurately than state-ofthe-art rumor detection models.\n",
      "predicted task:  [{'words': ['detect rumors', 'identifying rumors'], 'value': 0.29276865350000003, 'top_word': 'detect rumors'}]\n",
      "predicted method:  [{'words': ['kernel learning'], 'value': 0, 'top_word': 'kernel learning'}, {'words': ['kernel - based method'], 'value': 0, 'top_word': 'kernel - based method'}, {'words': ['propagation tree kernel'], 'value': 0, 'top_word': 'propagation tree kernel'}, {'words': ['kernel - based approach'], 'value': 0, 'top_word': 'kernel - based approach'}, {'words': ['rumor detection models'], 'value': 0, 'top_word': 'rumor detection models'}]\n",
      "actual task:  ['identifying rumors']\n",
      "actual method:  ['propogation trees', 'kernel-based method']\n",
      "comparing  identifying rumors  :with:  detect rumors  ::result:: 54\n",
      "comparing  identifying rumors  :with:  identifying rumors  ::result:: 100\n",
      "comparing  propogation trees  :with:  kernel learning  ::result:: 27\n",
      "comparing  propogation trees  :with:  kernel - based method  ::result:: 29\n",
      "comparing  propogation trees  :with:  propagation tree kernel  ::result:: 88\n",
      "comparing  propogation trees  :with:  kernel - based approach  ::result:: 24\n",
      "comparing  propogation trees  :with:  rumor detection models  ::result:: 41\n",
      "comparing  kernel-based method  :with:  kernel learning  ::result:: 53\n",
      "comparing  kernel-based method  :with:  kernel - based method  ::result:: 89\n",
      "comparing  kernel-based method  :with:  kernel - based approach  ::result:: 68\n",
      "comparing  kernel-based method  :with:  rumor detection models  ::result:: 37\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Beyond Sentential Semantic Parsing: Tackling the Math SAT with a Cascade of Tree Transducers. We present an approach for answering questions that span multiple sentences and exhibit sophisticated cross-sentence anaphoric phenomena, evaluating on a rich source of such questions-the math portion of the Scholastic Aptitude Test (SAT). By using a tree transducer cascade as its basic architecture, our system (called EU-CLID) propagates uncertainty from multiple sources (e.g. coreference resolution or verb interpretation) until it can be confidently resolved. Experiments show the first-ever results (43% recall and 91% precision) on SAT algebra word problems. We also apply EUCLID to the public Dolphin algebra question set, and improve the state-of-the-art F 1-score from 73.9% to 77.0%.\n",
      "predicted task:  [{'words': ['math sat'], 'value': 0.5857397318, 'top_word': 'math sat'}]\n",
      "predicted method:  [{'words': ['sentential semantic parsing'], 'value': 0, 'top_word': 'sentential semantic parsing'}, {'words': ['cascade of tree transducers'], 'value': 0, 'top_word': 'cascade of tree transducers'}, {'words': ['tree transducer cascade'], 'value': 0, 'top_word': 'tree transducer cascade'}, {'words': ['eu - clid)'], 'value': 0, 'top_word': 'eu - clid)'}, {'words': ['euclid'], 'value': 0, 'top_word': 'euclid'}]\n",
      "actual task:  ['semantic parsing']\n",
      "actual method:  ['tree transducer cascade']\n",
      "comparing  semantic parsing  :with:  math sat  ::result:: 50\n",
      "comparing  tree transducer cascade  :with:  sentential semantic parsing  ::result:: 39\n",
      "comparing  tree transducer cascade  :with:  cascade of tree transducers  ::result:: 82\n",
      "comparing  tree transducer cascade  :with:  tree transducer cascade  ::result:: 100\n",
      "comparing  tree transducer cascade  :with:  eu - clid)  ::result:: 40\n",
      "comparing  tree transducer cascade  :with:  euclid  ::result:: 33\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "Topic-Based Measures of Conversation for Detecting Mild CognitiveImpairment. Conversation is a complex cognitive task that engages multiple aspects of cognitive functions to remember the discussed topics, monitor the semantic and linguistic elements, and recognize others' emotions. In this paper, we propose a computational method based on the lexical coherence of consecutive utterances to quantify topical variations in semistructured conversations of older adults with cognitive impairments. Extracting the lexical knowledge of conversational utterances, our method generates a set of novel conversational measures that indicate underlying cognitive deficits among subjects with mild cognitive impairment (MCI). Our preliminary results verify the utility of the proposed conversation-based measures in distinguishing MCI from healthy controls.\n",
      "predicted task:  [{'words': ['topic - based measures of conversation'], 'value': 0, 'top_word': 'topic - based measures of conversation'}, {'words': ['detecting mild cognitiveimpairment conversation'], 'value': 0, 'top_word': 'detecting mild cognitiveimpairment conversation'}, {'words': ['cognitive task'], 'value': 0, 'top_word': 'cognitive task'}, {'words': ['mci'], 'value': 0, 'top_word': 'mci'}]\n",
      "predicted method:  [{'words': ['computational method'], 'value': 0, 'top_word': 'computational method'}, {'words': ['conversation - based measures'], 'value': 0, 'top_word': 'conversation - based measures'}]\n",
      "actual task:  ['detecting mild cognitiveimpairment']\n",
      "actual method:  ['lexical coherence of consecutive utterances']\n",
      "comparing  detecting mild cognitiveimpairment  :with:  topic - based measures of conversation  ::result:: 40\n",
      "comparing  detecting mild cognitiveimpairment  :with:  detecting mild cognitiveimpairment conversation  ::result:: 100\n",
      "comparing  detecting mild cognitiveimpairment  :with:  cognitive task  ::result:: 71\n",
      "comparing  detecting mild cognitiveimpairment  :with:  mci  ::result:: 67\n",
      "comparing  lexical coherence of consecutive utterances  :with:  computational method  ::result:: 35\n",
      "comparing  lexical coherence of consecutive utterances  :with:  conversation - based measures  ::result:: 41\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "MathAlign: Linking Formula Identifiers to their Contextual Natural Language Descriptions. Extending machine reading approaches to extract mathematical concepts and their descriptions is useful for a variety of tasks, ranging from mathematical information retrieval to increasing accessibility of scientific documents for the visually impaired. This entails segmenting mathematical formulae into identifiers and linking them to their natural language descriptions. We propose a rule-based approach for this task, which extracts L A T E X representations of formula identifiers and links them to their in-text descriptions, given only the original PDF and the location of the formula of interest. We also present a novel evaluation dataset for this task, as well as the tool used to create it.\n",
      "predicted task:  [{'words': ['linking formula identifiers'], 'value': 0, 'top_word': 'linking formula identifiers'}, {'words': ['mathematical information retrieval'], 'value': 0, 'top_word': 'mathematical information retrieval'}, {'words': ['accessibility of scientific documents'], 'value': 0, 'top_word': 'accessibility of scientific documents'}]\n",
      "predicted method:  [{'words': ['mathalign'], 'value': 0, 'top_word': 'mathalign'}, {'words': ['machine reading approaches'], 'value': 0, 'top_word': 'machine reading approaches'}, {'words': ['rule - based approach'], 'value': 0, 'top_word': 'rule - based approach'}]\n",
      "actual task:  ['machine reading']\n",
      "actual method:  ['rule-based approach']\n",
      "comparing  machine reading  :with:  linking formula identifiers  ::result:: 40\n",
      "comparing  machine reading  :with:  mathematical information retrieval  ::result:: 53\n",
      "comparing  machine reading  :with:  accessibility of scientific documents  ::result:: 33\n",
      "comparing  rule-based approach  :with:  mathalign  ::result:: 22\n",
      "comparing  rule-based approach  :with:  machine reading approaches  ::result:: 68\n",
      "comparing  rule-based approach  :with:  rule - based approach  ::result:: 89\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "ReEscreve: a Translator-friendly Multi-purpose Paraphrasing Software Tool. \n",
      "predicted task:  [{'words': ['text generation'], 'value': 0, 'top_word': 'text generation'}, {'words': ['text summarization'], 'value': 0, 'top_word': 'text summarization'}, {'words': ['text simplification'], 'value': 0, 'top_word': 'text simplification'}, {'words': ['text translation'], 'value': 0, 'top_word': 'text translation'}]\n",
      "predicted method:  [{'words': ['translator friendly multi purpose paraphrasing software'], 'value': 0.3734092712, 'top_word': 'translator friendly multi purpose paraphrasing software'}]\n",
      "actual task:  ['paraphrasing']\n",
      "actual method:  ['multi-purpose paraphrasing software tool']\n",
      "comparing  paraphrasing  :with:  text generation  ::result:: 33\n",
      "comparing  paraphrasing  :with:  text summarization  ::result:: 42\n",
      "comparing  paraphrasing  :with:  text simplification  ::result:: 33\n",
      "comparing  paraphrasing  :with:  text translation  ::result:: 42\n",
      "comparing  multi-purpose paraphrasing software tool  :with:  translator friendly multi purpose paraphrasing software  ::result:: 91\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "CommandTalk: A Spoken-Language Interface for Battlefield Simulations. CommandTalk is a spoken-language interface to battlefield simulations that allows the use of ordinary spoken English to create forces and control measures, assign missions to forces, modify missions during execution, and control simulation system functions. CommandTalk combines a number of separate components integrated through the use of the Open Agent Architecture, including the Nuance speech recognition system, the Gemini naturallanguage parsing and interpretation system, a contextual-interpretation modhle, a \"push-to-talk\" agent, the ModSAF battlefield simulator, and \"Start-It\" (a graphical processing-spawning agent). Com-mandTalk is installed at a number of Government and contractor sites, including NRaD and the Marine Corps Air Ground Combat Center. It is currently being extended to provide exercise-time control of all simulated U.S. forces in DARPA's STOW 97 demonstration. Put Checkpoint 1 at 937 965. Create a point called Checkpoint 2 at 930 960. Objective Alpha is 92 96. Charlie 4 5, at my command, advance in a column to Checkpoint 1. Next, proceed to Checkpoint 2. Then assault Objective Alpha. Charlie 4 5, move out. With the simulation under way, the user can exercise direct control over the simulated forces by giving commands such as the following for immediate execution: Charlie 4 5, speed up. Change formation to echelon right. Get in a line. Withdraw to Checkpoint 2. Examples of voice commands for controlling Mod-SAF system functions include the following: Show contour lines. Center on M1 platoon.\n",
      "predicted task:  [{'words': ['battlefield simulations'], 'value': 0, 'top_word': 'battlefield simulations'}, {'words': ['battlefield simulations'], 'value': 0, 'top_word': 'battlefield simulations'}, {'words': ['control simulation system functions'], 'value': 0, 'top_word': 'control simulation system functions'}, {'words': ['exercise - time control'], 'value': 0, 'top_word': 'exercise - time control'}, {'words': ['immediate execution'], 'value': 0, 'top_word': 'immediate execution'}, {'words': ['mod - saf system functions'], 'value': 0, 'top_word': 'mod - saf system functions'}]\n",
      "predicted method:  [{'words': ['commandtalk', 'commandtalk', 'commandtalk'], 'value': 0.4743520518, 'top_word': 'commandtalk'}]\n",
      "actual task:  ['battlefield simulations']\n",
      "actual method:  ['nuance speech recognition system', 'gemini natural language parsing', 'contextual-interpretation module', 'spoken-language interface']\n",
      "comparing  battlefield simulations  :with:  battlefield simulations  ::result:: 100\n",
      "comparing  battlefield simulations  :with:  battlefield simulations  ::result:: 100\n",
      "comparing  battlefield simulations  :with:  control simulation system functions  ::result:: 61\n",
      "comparing  battlefield simulations  :with:  exercise - time control  ::result:: 36\n",
      "comparing  battlefield simulations  :with:  immediate execution  ::result:: 47\n",
      "comparing  battlefield simulations  :with:  mod - saf system functions  ::result:: 48\n",
      "comparing  nuance speech recognition system  :with:  commandtalk  ::result:: 36\n",
      "comparing  nuance speech recognition system  :with:  commandtalk  ::result:: 36\n",
      "comparing  nuance speech recognition system  :with:  commandtalk  ::result:: 36\n",
      "comparing  gemini natural language parsing  :with:  commandtalk  ::result:: 36\n",
      "comparing  gemini natural language parsing  :with:  commandtalk  ::result:: 36\n",
      "comparing  gemini natural language parsing  :with:  commandtalk  ::result:: 36\n",
      "comparing  contextual-interpretation module  :with:  commandtalk  ::result:: 55\n",
      "comparing  contextual-interpretation module  :with:  commandtalk  ::result:: 55\n",
      "comparing  contextual-interpretation module  :with:  commandtalk  ::result:: 55\n",
      "comparing  spoken-language interface  :with:  commandtalk  ::result:: 27\n",
      "comparing  spoken-language interface  :with:  commandtalk  ::result:: 27\n",
      "comparing  spoken-language interface  :with:  commandtalk  ::result:: 27\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Parallels between Linguistics and Biology. In this paper we take a fresh look at parallels between linguistics and biology. We expect that this new line of thinking will propel cross fertilization of two disciplines and open up new research avenues.\n",
      "predicted task:  [{'words': ['cross-disciplinary research'], 'value': 0, 'top_word': 'cross-disciplinary research'}, {'words': ['new research avenues'], 'value': 0, 'top_word': 'new research avenues'}]\n",
      "predicted method:  [{'words': ['method1'], 'value': 0, 'top_word': 'method1'}, {'words': ['method2'], 'value': 0, 'top_word': 'method2'}, {'words': ['method3'], 'value': 0, 'top_word': 'method3'}]\n",
      "actual task:  ['parallels between linguistics and biology']\n",
      "actual method:  ['parallel construction', 'analogies']\n",
      "comparing  parallels between linguistics and biology  :with:  cross-disciplinary research  ::result:: 26\n",
      "comparing  parallels between linguistics and biology  :with:  new research avenues  ::result:: 40\n",
      "comparing  parallel construction  :with:  method1  ::result:: 29\n",
      "comparing  parallel construction  :with:  method2  ::result:: 29\n",
      "comparing  parallel construction  :with:  method3  ::result:: 29\n",
      "comparing  analogies  :with:  method1  ::result:: 14\n",
      "comparing  analogies  :with:  method2  ::result:: 14\n",
      "comparing  analogies  :with:  method3  ::result:: 14\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Sentiment Analysis on the People's Daily. We propose a semi-supervised bootstrapping algorithm for analyzing China's foreign relations from the People's Daily. Our approach addresses sentiment target clustering, subjective lexicons extraction and sentiment prediction in a unified framework. Different from existing algorithms in the literature, time information is considered in our algorithm through a hierarchical bayesian model to guide the bootstrapping approach. We are hopeful that our approach can facilitate quantitative political analysis conducted by social scientists and politicians.\n",
      "predicted task:  [{'words': ['sentiment analysis', 'sentiment target clustering', 'sentiment prediction'], 'value': 0.1564198186, 'top_word': 'sentiment analysis'}]\n",
      "predicted method:  [{'words': ['semi - supervised bootstrapping algorithm'], 'value': 0, 'top_word': 'semi - supervised bootstrapping algorithm'}, {'words': ['hierarchical bayesian model'], 'value': 0, 'top_word': 'hierarchical bayesian model'}, {'words': ['bootstrapping approach'], 'value': 0, 'top_word': 'bootstrapping approach'}]\n",
      "actual task:  ['sentiment analysis']\n",
      "actual method:  ['semi-supervised bootstrapping algorithm']\n",
      "comparing  sentiment analysis  :with:  sentiment analysis  ::result:: 100\n",
      "comparing  sentiment analysis  :with:  sentiment target clustering  ::result:: 61\n",
      "comparing  sentiment analysis  :with:  sentiment prediction  ::result:: 61\n",
      "comparing  semi-supervised bootstrapping algorithm  :with:  semi - supervised bootstrapping algorithm  ::result:: 95\n",
      "comparing  semi-supervised bootstrapping algorithm  :with:  hierarchical bayesian model  ::result:: 37\n",
      "comparing  semi-supervised bootstrapping algorithm  :with:  bootstrapping approach  ::result:: 77\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "BIGODM System in the Social Media Mining for Health Applications Shared Task 2019. In this study, we describe our methods to automatically classify Twitter posts conveying events of adverse drug reaction (ADR). Based on our previous experience in tackling the ADR classification task, we empirically applied the vote-based undersampling ensemble approach along with linear support vector machine (SVM) to develop our classifiers as part of our participation in ACL 2019 Social Media Mining for Health Applications (SMM4H) shared task 1. The best-performed model on the test sets were trained on a merged corpus consisting of the datasets released by SMM4H 2017 and 2019. By using VUE, the corpus was randomly under-sampled with 2:1 ratio between the negative and positive classes to create an ensemble using the linear kernel trained with features including bag-of-word, domain knowledge, negation and word embedding. The best performing model achieved an F-measure of 0.551 which is about 5% higher than the average F-scores of 16 teams.\n",
      "predicted task:  [{'words': ['bigodm system', 'adr classification task', 'classifiers'], 'value': 0.2017435934, 'top_word': 'adr classification task'}]\n",
      "predicted method:  [{'words': ['vue'], 'value': 0.2828738689, 'top_word': 'vue'}]\n",
      "actual task:  ['social media mining']\n",
      "actual method:  ['support vector machines', 'word embedding', 'linear kernel', 'bag-of-word', 'domain-knowledge', 'negation']\n",
      "comparing  social media mining  :with:  bigodm system  ::result:: 31\n",
      "comparing  social media mining  :with:  adr classification task  ::result:: 32\n",
      "comparing  social media mining  :with:  classifiers  ::result:: 27\n",
      "comparing  support vector machines  :with:  vue  ::result:: 67\n",
      "comparing  word embedding  :with:  vue  ::result:: 33\n",
      "comparing  linear kernel  :with:  vue  ::result:: 33\n",
      "comparing  bag-of-word  :with:  vue  ::result:: 0\n",
      "comparing  domain-knowledge  :with:  vue  ::result:: 33\n",
      "comparing  negation  :with:  vue  ::result:: 0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Analyzing Stereotypes in Generative Text Inference Tasks. Stereotypes are inferences drawn about people based on their demographic attributes, which may result in harms to users when a system is deployed. In generative language-inference tasks, given a premise, a model produces plausible hypotheses that follow either logically (natural language inference) or commonsensically (commonsense inference). Such tasks are therefore a fruitful setting in which to explore the degree to which NLP systems encode stereotypes. In our work, we study how stereotypes manifest when the potential targets of stereotypes are situated in real-life, neutral contexts. We collect human judgments on the presence of stereotypes in generated inferences, and compare how perceptions of stereotypes vary due to annotator positionality. Domain Target Categories Gender man, woman, non-binary person, trans man, trans woman, cis man, cis woman\n",
      "predicted task:  [{'words': ['analyzing stereotypes'], 'value': 0, 'top_word': 'analyzing stereotypes'}, {'words': ['generative text inference tasks'], 'value': 0, 'top_word': 'generative text inference tasks'}, {'words': ['generative language - inference tasks'], 'value': 0, 'top_word': 'generative language - inference tasks'}, {'words': ['language inference)'], 'value': 0, 'top_word': 'language inference)'}, {'words': ['nlp'], 'value': 0, 'top_word': 'nlp'}, {'words': ['generated inferences'], 'value': 0, 'top_word': 'generated inferences'}]\n",
      "predicted method:  [{'words': ['inference)'], 'value': 0, 'top_word': 'inference)'}]\n",
      "actual task:  ['analyzing stereotypes']\n",
      "actual method:  ['annotation', 'human judgement']\n",
      "comparing  analyzing stereotypes  :with:  analyzing stereotypes  ::result:: 100\n",
      "comparing  analyzing stereotypes  :with:  generative text inference tasks  ::result:: 38\n",
      "comparing  analyzing stereotypes  :with:  generative language - inference tasks  ::result:: 43\n",
      "comparing  analyzing stereotypes  :with:  language inference)  ::result:: 42\n",
      "comparing  analyzing stereotypes  :with:  nlp  ::result:: 67\n",
      "comparing  analyzing stereotypes  :with:  generated inferences  ::result:: 45\n",
      "comparing  annotation  :with:  inference)  ::result:: 20\n",
      "comparing  human judgement  :with:  inference)  ::result:: 30\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "A Checkpoint on Multilingual Misogyny Identification. We address the problem of identifying misogyny in tweets in mono and multilingual settings in three languages: English, Italian and Spanish. We explore model variations considering single and multiple languages both in the pre-training of the transformer and in the training of the downstream task to explore the feasibility of detecting misogyny through a transfer learning approach across multiple languages. That is, we train monolingual transformers with monolingual data and multilingual transformers with both monolingual and multilingual data. Our models reach state-of-the-art performance on all three languages. The single-language BERT models perform the best, closely followed by different configurations of multilingual BERT models. The performance drops in zero-shot classification across languages. Our error analysis shows that multilingual and monolingual models tend to make the same mistakes.\n",
      "predicted task:  [{'words': ['identifying misogyny in tweets', 'detecting misogyny'], 'value': 0.4181928635, 'top_word': 'identifying misogyny in tweets'}]\n",
      "predicted method:  [{'words': ['transfer learning approach'], 'value': 0, 'top_word': 'transfer learning approach'}, {'words': ['monolingual transformers'], 'value': 0, 'top_word': 'monolingual transformers'}, {'words': ['multilingual transformers'], 'value': 0, 'top_word': 'multilingual transformers'}, {'words': ['single - language bert models'], 'value': 0, 'top_word': 'single - language bert models'}, {'words': ['multilingual bert models'], 'value': 0, 'top_word': 'multilingual bert models'}, {'words': ['error analysis'], 'value': 0, 'top_word': 'error analysis'}, {'words': ['multilingual and monolingual models'], 'value': 0, 'top_word': 'multilingual and monolingual models'}]\n",
      "actual task:  ['misogyny identification']\n",
      "actual method:  ['transformers', 'bert']\n",
      "comparing  misogyny identification  :with:  identifying misogyny in tweets  ::result:: 63\n",
      "comparing  misogyny identification  :with:  detecting misogyny  ::result:: 44\n",
      "comparing  transformers  :with:  transfer learning approach  ::result:: 67\n",
      "comparing  transformers  :with:  monolingual transformers  ::result:: 100\n",
      "comparing  transformers  :with:  multilingual transformers  ::result:: 100\n",
      "comparing  transformers  :with:  single - language bert models  ::result:: 33\n",
      "comparing  transformers  :with:  multilingual bert models  ::result:: 33\n",
      "comparing  transformers  :with:  error analysis  ::result:: 42\n",
      "comparing  transformers  :with:  multilingual and monolingual models  ::result:: 33\n",
      "comparing  bert  :with:  transfer learning approach  ::result:: 50\n",
      "comparing  bert  :with:  multilingual transformers  ::result:: 50\n",
      "comparing  bert  :with:  single - language bert models  ::result:: 100\n",
      "comparing  bert  :with:  multilingual bert models  ::result:: 100\n",
      "comparing  bert  :with:  error analysis  ::result:: 50\n",
      "comparing  bert  :with:  multilingual and monolingual models  ::result:: 25\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "Collaborative Data Relabeling for Robust and Diverse Voice Apps Recommendation in Intelligent Personal Assistants. Intelligent personal assistants (IPAs) such as Amazon Alexa, Google Assistant and Apple Siri extend their built-in capabilities by supporting voice apps developed by third-party developers. Sometimes the smart assistant is not able to successfully respond to user voice commands (aka utterances). There are many reasons including automatic speech recognition (ASR) error, natural language understanding (NLU) error, routing utterances to an irrelevant voice app or simply that the user is asking for a capability that is not supported yet. The failure to handle a voice command leads to customer frustration. In this paper, we introduce a fallback skill recommendation system to suggest a voice app to a customer for an unhandled voice command. One of the prominent challenges of developing a skill recommender system for IPAs is partial observation. To solve the partial observation problem, we propose collaborative data relabeling (CDR) method. In addition, CDR also improves the diversity of the recommended skills. We evaluate the proposed method both offline and online. The offline evaluation results show that the proposed system outperforms the baselines. The online A/B testing results show significant gain of customer experience metrics.\n",
      "predicted task:  [{'words': ['collaborative data relabeling'], 'value': 0, 'top_word': 'collaborative data relabeling'}, {'words': ['robust and diverse voice apps recommendation'], 'value': 0, 'top_word': 'robust and diverse voice apps recommendation'}, {'words': ['intelligent personal assistants'], 'value': 0, 'top_word': 'intelligent personal assistants'}, {'words': ['intelligent personal assistants'], 'value': 0, 'top_word': 'intelligent personal assistants'}, {'words': ['automatic speech recognition (asr) error'], 'value': 0, 'top_word': 'automatic speech recognition (asr) error'}, {'words': ['natural language understanding'], 'value': 0, 'top_word': 'natural language understanding'}, {'words': ['partial observation'], 'value': 0, 'top_word': 'partial observation'}, {'words': ['partial observation problem'], 'value': 0, 'top_word': 'partial observation problem'}]\n",
      "predicted method:  [{'words': ['cdr'], 'value': 0.268807888, 'top_word': 'cdr'}]\n",
      "actual task:  ['recommendation system']\n",
      "actual method:  ['collaborative data relabeling']\n",
      "comparing  recommendation system  :with:  collaborative data relabeling  ::result:: 33\n",
      "comparing  recommendation system  :with:  robust and diverse voice apps recommendation  ::result:: 67\n",
      "comparing  recommendation system  :with:  intelligent personal assistants  ::result:: 43\n",
      "comparing  recommendation system  :with:  intelligent personal assistants  ::result:: 43\n",
      "comparing  recommendation system  :with:  automatic speech recognition (asr) error  ::result:: 57\n",
      "comparing  recommendation system  :with:  natural language understanding  ::result:: 29\n",
      "comparing  recommendation system  :with:  partial observation  ::result:: 42\n",
      "comparing  recommendation system  :with:  partial observation problem  ::result:: 48\n",
      "comparing  collaborative data relabeling  :with:  cdr  ::result:: 33\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Statistical Machine Translation Models for Personalized Search. Web search personalization has been well studied in the recent few years. Relevance feedback has been used in various ways to improve relevance of search results. In this paper, we propose a novel usage of relevance feedback to effectively model the process of query formulation and better characterize how a user relates his query to the document that he intends to retrieve using a noisy channel model. We model a user profile as the probabilities of translation of query to document in this noisy channel using the relevance feedback obtained from the user. The user profile thus learnt is applied in a re-ranking phase to rescore the search results retrieved using an underlying search engine. We evaluate our approach by conducting experiments using relevance feedback data collected from users using a popular search engine. The results have shown improvement over baseline, proving that our approach can be applied to personalization of web search. The experiments have also resulted in some valuable observations that learning these user profiles using snippets surrounding the results for a query gives better performance than learning from entire document collection.\n",
      "predicted task:  [{'words': ['personalized search'], 'value': 0, 'top_word': 'personalized search'}, {'words': ['web search personalization'], 'value': 0, 'top_word': 'web search personalization'}, {'words': ['query formulation'], 'value': 0, 'top_word': 'query formulation'}, {'words': ['re - ranking phase'], 'value': 0, 'top_word': 're - ranking phase'}, {'words': ['personalization of web search'], 'value': 0, 'top_word': 'personalization of web search'}]\n",
      "predicted method:  [{'words': ['statistical machine translation models'], 'value': 0, 'top_word': 'statistical machine translation models'}, {'words': ['relevance feedback'], 'value': 0, 'top_word': 'relevance feedback'}, {'words': ['noisy channel model'], 'value': 0, 'top_word': 'noisy channel model'}, {'words': ['search engine'], 'value': 0, 'top_word': 'search engine'}, {'words': ['search engine'], 'value': 0, 'top_word': 'search engine'}]\n",
      "actual task:  ['personalized search web']\n",
      "actual method:  ['statistical machine translation models', 'relevance feedback']\n",
      "comparing  personalized search web  :with:  personalized search  ::result:: 100\n",
      "comparing  personalized search web  :with:  web search personalization  ::result:: 48\n",
      "comparing  personalized search web  :with:  query formulation  ::result:: 29\n",
      "comparing  personalized search web  :with:  re - ranking phase  ::result:: 39\n",
      "comparing  personalized search web  :with:  personalization of web search  ::result:: 65\n",
      "comparing  statistical machine translation models  :with:  statistical machine translation models  ::result:: 100\n",
      "comparing  statistical machine translation models  :with:  relevance feedback  ::result:: 33\n",
      "comparing  statistical machine translation models  :with:  noisy channel model  ::result:: 53\n",
      "comparing  statistical machine translation models  :with:  search engine  ::result:: 46\n",
      "comparing  statistical machine translation models  :with:  search engine  ::result:: 46\n",
      "comparing  relevance feedback  :with:  relevance feedback  ::result:: 100\n",
      "comparing  relevance feedback  :with:  noisy channel model  ::result:: 29\n",
      "comparing  relevance feedback  :with:  search engine  ::result:: 46\n",
      "comparing  relevance feedback  :with:  search engine  ::result:: 46\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "LTL-UDE at SemEval-2019 Task 6: BERT and Two-Vote Classification for Categorizing Offensiveness. This paper describes LTL-UDE's systems for the SemEval 2019 Shared Task 6. We present results for Subtask A and C. In Subtask A, we experiment with an embedding representation of postings and use a Multi-Layer Perceptron and BERT to categorize postings. Our best result reaches the 10th place (out of 103) using BERT. In Subtask C, we applied a two-vote classification approach with minority fallback, which is placed on the 19th rank (out of 65).\n",
      "predicted task:  [{'words': ['categorizing offensiveness'], 'value': 0, 'top_word': 'categorizing offensiveness'}]\n",
      "predicted method:  [{'words': ['ltl ude', 'ltl udes systems'], 'value': 0.42122802140000004, 'top_word': 'ltl udes systems'}]\n",
      "actual task:  ['categorizing offensiveness']\n",
      "actual method:  ['embedding representation', 'multi-layer perceptron', 'bert']\n",
      "comparing  categorizing offensiveness  :with:  categorizing offensiveness  ::result:: 100\n",
      "comparing  embedding representation  :with:  ltl ude  ::result:: 29\n",
      "comparing  embedding representation  :with:  ltl udes systems  ::result:: 25\n",
      "comparing  multi-layer perceptron  :with:  ltl ude  ::result:: 43\n",
      "comparing  multi-layer perceptron  :with:  ltl udes systems  ::result:: 38\n",
      "comparing  bert  :with:  ltl ude  ::result:: 25\n",
      "comparing  bert  :with:  ltl udes systems  ::result:: 25\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Developing and Orchestrating a Portfolio of Natural Legal Language Processing and Document Curation Services. We present a portfolio of natural legal language processing and document curation services currently under development in a collaborative European project. First, we give an overview of the project and the different use cases, while, in the main part of the article, we focus upon the 13 different processing services that are being deployed in different prototype applications using a flexible and scalable microservices architecture. Their orchestration is operationalised using a content and document curation workflow manager.\n",
      "predicted task:  [{'words': ['natural legal language processing'], 'value': 0, 'top_word': 'natural legal language processing'}, {'words': ['document curation services'], 'value': 0, 'top_word': 'document curation services'}, {'words': ['natural legal language processing'], 'value': 0, 'top_word': 'natural legal language processing'}, {'words': ['document curation services'], 'value': 0, 'top_word': 'document curation services'}]\n",
      "predicted method:  [{'words': ['processing services'], 'value': 0, 'top_word': 'processing services'}, {'words': ['microservices architecture'], 'value': 0, 'top_word': 'microservices architecture'}, {'words': ['content and document curation workflow manager'], 'value': 0, 'top_word': 'content and document curation workflow manager'}]\n",
      "actual task:  ['natural legal language processing and document curation']\n",
      "actual method:  ['content and document curation workflow manager']\n",
      "comparing  natural legal language processing and document curation  :with:  natural legal language processing  ::result:: 100\n",
      "comparing  natural legal language processing and document curation  :with:  document curation services  ::result:: 65\n",
      "comparing  natural legal language processing and document curation  :with:  natural legal language processing  ::result:: 100\n",
      "comparing  natural legal language processing and document curation  :with:  document curation services  ::result:: 65\n",
      "comparing  content and document curation workflow manager  :with:  processing services  ::result:: 37\n",
      "comparing  content and document curation workflow manager  :with:  microservices architecture  ::result:: 31\n",
      "comparing  content and document curation workflow manager  :with:  content and document curation workflow manager  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Neural Networks for Joint Sentence Classification in Medical Paper Abstracts. Existing models based on artificial neural networks (ANNs) for sentence classification often do not incorporate the context in which sentences appear, and classify sentences individually. However, traditional sentence classification approaches have been shown to greatly benefit from jointly classifying subsequent sentences, such as with conditional random fields. In this work, we present an ANN architecture that combines the effectiveness of typical ANN models to classify sentences in isolation, with the strength of structured prediction. Our model outperforms the state-ofthe-art results on two different datasets for sequential sentence classification in medical abstracts.\n",
      "predicted task:  [{'words': ['joint sentence classification', 'sentence classification', 'sequential sentence classification'], 'value': 0.6521787643, 'top_word': 'sequential sentence classification'}]\n",
      "predicted method:  [{'words': ['neural networks'], 'value': 0, 'top_word': 'neural networks'}, {'words': ['artificial neural networks'], 'value': 0, 'top_word': 'artificial neural networks'}, {'words': ['sentence classification approaches'], 'value': 0, 'top_word': 'sentence classification approaches'}, {'words': ['conditional random fields'], 'value': 0, 'top_word': 'conditional random fields'}, {'words': ['ann architecture'], 'value': 0, 'top_word': 'ann architecture'}, {'words': ['ann models'], 'value': 0, 'top_word': 'ann models'}]\n",
      "actual task:  ['sentence classification']\n",
      "actual method:  ['artificial neural networks']\n",
      "comparing  sentence classification  :with:  joint sentence classification  ::result:: 100\n",
      "comparing  sentence classification  :with:  sentence classification  ::result:: 100\n",
      "comparing  sentence classification  :with:  sequential sentence classification  ::result:: 100\n",
      "comparing  artificial neural networks  :with:  neural networks  ::result:: 100\n",
      "comparing  artificial neural networks  :with:  artificial neural networks  ::result:: 100\n",
      "comparing  artificial neural networks  :with:  sentence classification approaches  ::result:: 42\n",
      "comparing  artificial neural networks  :with:  conditional random fields  ::result:: 41\n",
      "comparing  artificial neural networks  :with:  ann architecture  ::result:: 44\n",
      "comparing  artificial neural networks  :with:  ann models  ::result:: 30\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "NoPropaganda at SemEval-2020 Task 11: A Borrowed Approach to Sequence Tagging and Text Classification. This paper describes our contribution to SemEval-2020 Task 11: Detection Of Propaganda Techniques In News Articles. We start with simple LSTM baselines and move to an autoregressive transformer decoder to predict long continuous propaganda spans for the first subtask. We also adopt an approach from relation extraction by enveloping spans mentioned above with special tokens for the second subtask of propaganda technique classification. Our models report an F-score of 44.6% and a micro-averaged F-score of 58.2% for those tasks accordingly.\n",
      "predicted task:  [{'words': ['sequence tagging'], 'value': 0, 'top_word': 'sequence tagging'}, {'words': ['text classification'], 'value': 0, 'top_word': 'text classification'}, {'words': ['semeval - 2020 task'], 'value': 0, 'top_word': 'semeval - 2020 task'}, {'words': ['detection of propaganda techniques'], 'value': 0, 'top_word': 'detection of propaganda techniques'}, {'words': ['relation extraction'], 'value': 0, 'top_word': 'relation extraction'}, {'words': ['propaganda technique classification'], 'value': 0, 'top_word': 'propaganda technique classification'}]\n",
      "predicted method:  [{'words': ['lstm baselines'], 'value': 0, 'top_word': 'lstm baselines'}, {'words': ['autoregressive transformer decoder'], 'value': 0, 'top_word': 'autoregressive transformer decoder'}]\n",
      "actual task:  ['detection of propaganda techniques', 'propaganda technique classification']\n",
      "actual method:  ['lstm', 'autoregressive transformer decoder']\n",
      "comparing  detection of propaganda techniques  :with:  sequence tagging  ::result:: 38\n",
      "comparing  detection of propaganda techniques  :with:  text classification  ::result:: 37\n",
      "comparing  detection of propaganda techniques  :with:  semeval - 2020 task  ::result:: 26\n",
      "comparing  detection of propaganda techniques  :with:  detection of propaganda techniques  ::result:: 100\n",
      "comparing  detection of propaganda techniques  :with:  relation extraction  ::result:: 47\n",
      "comparing  detection of propaganda techniques  :with:  propaganda technique classification  ::result:: 62\n",
      "comparing  propaganda technique classification  :with:  sequence tagging  ::result:: 44\n",
      "comparing  propaganda technique classification  :with:  text classification  ::result:: 84\n",
      "comparing  propaganda technique classification  :with:  semeval - 2020 task  ::result:: 26\n",
      "comparing  propaganda technique classification  :with:  relation extraction  ::result:: 47\n",
      "comparing  propaganda technique classification  :with:  propaganda technique classification  ::result:: 100\n",
      "comparing  lstm  :with:  lstm baselines  ::result:: 100\n",
      "comparing  lstm  :with:  autoregressive transformer decoder  ::result:: 25\n",
      "comparing  autoregressive transformer decoder  :with:  autoregressive transformer decoder  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Interpretable Propaganda Detection in News Articles. Online users today are exposed to misleading and propagandistic news articles and media posts on a daily basis. To counter thus, a number of approaches have been designed aiming to achieve a healthier and safer online news and media consumption. Automatic systems are able to support humans in detecting such content; yet, a major impediment to their broad adoption is that besides being accurate, the decisions of such systems need also to be interpretable in order to be trusted and widely adopted by users. Since misleading and propagandistic content influences readers through the use of a number of deception techniques, we propose to detect and to show the use of such techniques as a way to offer interpretability. In particular, we define qualitatively descriptive features and we analyze their suitability for detecting deception techniques. We further show that our interpretable features can be easily combined with pre-trained language models, yielding state-of-the-art results.\n",
      "predicted task:  [{'words': ['interpretable propaganda detection', 'online news and media consumption', 'automatic systems'], 'value': 0.1094129928, 'top_word': 'interpretable propaganda detection'}]\n",
      "predicted method:  [{'words': ['automatic systems'], 'value': 0, 'top_word': 'automatic systems'}, {'words': ['deception techniques'], 'value': 0, 'top_word': 'deception techniques'}, {'words': ['deception techniques'], 'value': 0, 'top_word': 'deception techniques'}, {'words': ['language models'], 'value': 0, 'top_word': 'language models'}]\n",
      "actual task:  ['propaganda detection']\n",
      "actual method:  ['qualitatively descriptive features', 'pre-trained language models']\n",
      "comparing  propaganda detection  :with:  interpretable propaganda detection  ::result:: 100\n",
      "comparing  propaganda detection  :with:  online news and media consumption  ::result:: 45\n",
      "comparing  propaganda detection  :with:  automatic systems  ::result:: 29\n",
      "comparing  qualitatively descriptive features  :with:  automatic systems  ::result:: 47\n",
      "comparing  qualitatively descriptive features  :with:  deception techniques  ::result:: 55\n",
      "comparing  qualitatively descriptive features  :with:  deception techniques  ::result:: 55\n",
      "comparing  qualitatively descriptive features  :with:  language models  ::result:: 47\n",
      "comparing  pre-trained language models  :with:  automatic systems  ::result:: 35\n",
      "comparing  pre-trained language models  :with:  deception techniques  ::result:: 40\n",
      "comparing  pre-trained language models  :with:  deception techniques  ::result:: 40\n",
      "comparing  pre-trained language models  :with:  language models  ::result:: 100\n",
      "1.0\n",
      "0.5\n",
      "\n",
      "On Unifying Misinformation Detection. In this paper, we introduce UNIFIEDM2, a general-purpose misinformation model that jointly models multiple domains of misinformation with a single, unified setup. The model is trained to handle four tasks: detecting news bias, clickbait, fake news and verifying rumors. By grouping these tasks together, UNIFIEDM2 learns a richer representation of misinformation, which leads to stateof-the-art or comparable performance across all tasks. Furthermore, we demonstrate that UNIFIEDM2's learned representation is helpful for few-shot learning of unseen misinformation tasks/datasets and model's generalizability to unseen events. * Work partially done while interning at Facebook AI. † Work partially done while working at Facebook AI.\n",
      "predicted task:  [{'words': ['unifying misinformation detection'], 'value': 0.5123311877, 'top_word': 'unifying misinformation detection'}]\n",
      "predicted method:  [{'words': ['unifiedm2', 'unifiedm2', 'unifiedm2s learned representation'], 'value': 0.5888508459, 'top_word': 'unifiedm2'}]\n",
      "actual task:  ['misinformation detection', 'detecting news bias', 'verifying rumors']\n",
      "actual method:  ['few-shot learning', 'unifiedm2']\n",
      "comparing  misinformation detection  :with:  unifying misinformation detection  ::result:: 100\n",
      "comparing  few-shot learning  :with:  unifiedm2  ::result:: 22\n",
      "comparing  few-shot learning  :with:  unifiedm2  ::result:: 22\n",
      "comparing  few-shot learning  :with:  unifiedm2s learned representation  ::result:: 53\n",
      "comparing  unifiedm2  :with:  unifiedm2  ::result:: 100\n",
      "comparing  unifiedm2  :with:  unifiedm2  ::result:: 100\n",
      "comparing  unifiedm2  :with:  unifiedm2s learned representation  ::result:: 100\n",
      "0.3333333333333333\n",
      "0.5\n",
      "\n",
      "Lexically-Triggered Hidden Markov Models for Clinical Document Coding. The automatic coding of clinical documents is an important task for today's healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.\n",
      "predicted task:  [{'words': ['clinical document coding'], 'value': 0, 'top_word': 'clinical document coding'}, {'words': ['automatic coding of clinical documents'], 'value': 0, 'top_word': 'automatic coding of clinical documents'}, {'words': ['multi - label document classification'], 'value': 0, 'top_word': 'multi - label document classification'}, {'words': ['coding problem'], 'value': 0, 'top_word': 'coding problem'}]\n",
      "predicted method:  [{'words': ['lexically triggered hidden markov models', 'lexically triggered hidden markov model'], 'value': 0.2184042633, 'top_word': 'lexically triggered hidden markov models'}, {'words': ['lt hmm', 'lt hmm'], 'value': 0.24816216530000001, 'top_word': 'lt hmm'}]\n",
      "actual task:  ['clinical document coding', 'document classification']\n",
      "actual method:  [' lexically-triggered hidden markov model']\n",
      "comparing  clinical document coding  :with:  clinical document coding  ::result:: 100\n",
      "comparing  clinical document coding  :with:  automatic coding of clinical documents  ::result:: 81\n",
      "comparing  clinical document coding  :with:  multi - label document classification  ::result:: 62\n",
      "comparing  clinical document coding  :with:  coding problem  ::result:: 43\n",
      "comparing  document classification  :with:  automatic coding of clinical documents  ::result:: 43\n",
      "comparing  document classification  :with:  multi - label document classification  ::result:: 100\n",
      "comparing  document classification  :with:  coding problem  ::result:: 29\n",
      "comparing   lexically-triggered hidden markov model  :with:  lexically triggered hidden markov models  ::result:: 95\n",
      "comparing   lexically-triggered hidden markov model  :with:  lexically triggered hidden markov model  ::result:: 97\n",
      "comparing   lexically-triggered hidden markov model  :with:  lt hmm  ::result:: 33\n",
      "comparing   lexically-triggered hidden markov model  :with:  lt hmm  ::result:: 33\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Faceted Hierarchy: A New Graph Type to Organize Scientific Concepts and a Construction Method. On a scientific concept hierarchy, a parent concept may have a few attributes, each of which has multiple values being a group of child concepts. We call these attributes facets: classification has a few facets such as application (e.g., face recognition), model (e.g., svm, knn), and metric (e.g., precision). In this work, we aim at building faceted concept hierarchies from scientific literature. Hierarchy construction methods heavily rely on hypernym detection, however, the faceted relations are parent-to-child links but the hypernym relation is a multi-hop, i.e., ancestor-todescendent link with a specific facet \"type-of\". We use information extraction techniques to find synonyms, sibling concepts, and ancestordescendent relations from a data science corpus. And we propose a hierarchy growth algorithm to infer the parent-child links from the three types of relationships. It resolves conflicts by maintaining the acyclic structure of a hierarchy.\n",
      "predicted task:  [{'words': ['graph type', 'construction method', 'classification', 'face recognition', 'svm'], 'value': 0.0896247971, 'top_word': 'classification'}]\n",
      "predicted method:  [{'words': ['faceted hierarchy'], 'value': 0, 'top_word': 'faceted hierarchy'}, {'words': ['graph type'], 'value': 0, 'top_word': 'graph type'}, {'words': ['construction method'], 'value': 0, 'top_word': 'construction method'}, {'words': ['svm'], 'value': 0, 'top_word': 'svm'}, {'words': ['knn)'], 'value': 0, 'top_word': 'knn)'}, {'words': ['hierarchy construction methods'], 'value': 0, 'top_word': 'hierarchy construction methods'}, {'words': ['hypernym detection'], 'value': 0, 'top_word': 'hypernym detection'}, {'words': ['information extraction techniques'], 'value': 0, 'top_word': 'information extraction techniques'}, {'words': ['hierarchy growth algorithm'], 'value': 0, 'top_word': 'hierarchy growth algorithm'}]\n",
      "actual task:  ['organize scientific concepts']\n",
      "actual method:  ['information extraction techniques']\n",
      "comparing  organize scientific concepts  :with:  graph type  ::result:: 30\n",
      "comparing  organize scientific concepts  :with:  construction method  ::result:: 42\n",
      "comparing  organize scientific concepts  :with:  classification  ::result:: 50\n",
      "comparing  organize scientific concepts  :with:  face recognition  ::result:: 50\n",
      "comparing  organize scientific concepts  :with:  svm  ::result:: 33\n",
      "comparing  information extraction techniques  :with:  faceted hierarchy  ::result:: 47\n",
      "comparing  information extraction techniques  :with:  graph type  ::result:: 50\n",
      "comparing  information extraction techniques  :with:  construction method  ::result:: 63\n",
      "comparing  information extraction techniques  :with:  svm  ::result:: 33\n",
      "comparing  information extraction techniques  :with:  knn)  ::result:: 25\n",
      "comparing  information extraction techniques  :with:  hierarchy construction methods  ::result:: 50\n",
      "comparing  information extraction techniques  :with:  hypernym detection  ::result:: 56\n",
      "comparing  information extraction techniques  :with:  information extraction techniques  ::result:: 100\n",
      "comparing  information extraction techniques  :with:  hierarchy growth algorithm  ::result:: 35\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "Multilingual Generation and Summarization of Job Adverts: the TREE Project. A multilingual Internet-based employment advertisement system is described. Job ads are submitted as e-mail texts, analysed by an example-based pattern matcher and stored in language-independent schemas in an object-oriented database. Users can search the database in their own language and get customized summaries of the job ads. The query engine uses symbolic case-based reasoning techniques, while the generation module integrates canned text, templates, and grammar rules to produce texts and hypertexts in a simple way.\n",
      "predicted task:  [{'words': ['multilingual generation and summarization of job adverts'], 'value': 0, 'top_word': 'multilingual generation and summarization of job adverts'}]\n",
      "predicted method:  [{'words': ['multilingual internet - based employment advertisement system'], 'value': 0, 'top_word': 'multilingual internet - based employment advertisement system'}, {'words': ['example - based pattern matcher'], 'value': 0, 'top_word': 'example - based pattern matcher'}, {'words': ['query engine'], 'value': 0, 'top_word': 'query engine'}, {'words': ['symbolic case - based reasoning techniques'], 'value': 0, 'top_word': 'symbolic case - based reasoning techniques'}, {'words': ['generation module'], 'value': 0, 'top_word': 'generation module'}, {'words': ['grammar rules'], 'value': 0, 'top_word': 'grammar rules'}]\n",
      "actual task:  ['multilingual generation', 'summarization']\n",
      "actual method:  ['query engine']\n",
      "comparing  multilingual generation  :with:  multilingual generation and summarization of job adverts  ::result:: 100\n",
      "comparing  query engine  :with:  multilingual internet - based employment advertisement system  ::result:: 33\n",
      "comparing  query engine  :with:  example - based pattern matcher  ::result:: 33\n",
      "comparing  query engine  :with:  query engine  ::result:: 100\n",
      "comparing  query engine  :with:  symbolic case - based reasoning techniques  ::result:: 50\n",
      "comparing  query engine  :with:  generation module  ::result:: 33\n",
      "comparing  query engine  :with:  grammar rules  ::result:: 25\n",
      "0.5\n",
      "1.0\n",
      "\n",
      "Applications of Natural Language Processing in Bilingual Language Teaching: An Indonesian-English Case Study. Multilingual corpora are difficult to compile and a classroom setting adds pedagogy to the mix of factors which make this data so rich and problematic to classify. In this paper, we set out methodological considerations of using automated speech recognition to build a corpus of teacher speech in an Indonesian language classroom. Our preliminary results (64% word error rate) suggest these tools have the potential to speed data collection in this context. We provide practical examples of our data structure, details of our piloted computer-assisted processes, and fine-grained error analysis. Our study is informed and directed by genuine research questions and discussion in both the education and computational linguistics fields. We highlight some of the benefits and risks of using these emerging technologies to analyze the complex work of language teachers and in education more generally.\n",
      "predicted task:  [{'words': ['natural language processing', 'automated speech recognition', 'data collection', 'computer assisted processes', 'fine grained error analysis'], 'value': 0.257721817, 'top_word': 'natural language processing'}, {'words': ['bilingual language teaching', 'language teachers'], 'value': 0.16599020920000002, 'top_word': 'bilingual language teaching'}]\n",
      "predicted method:  [{'words': ['computer - assisted processes'], 'value': 0, 'top_word': 'computer - assisted processes'}, {'words': ['fine - grained error analysis'], 'value': 0, 'top_word': 'fine - grained error analysis'}]\n",
      "actual task:  ['bilingual language teaching']\n",
      "actual method:  ['speech recognition', 'corpus']\n",
      "comparing  bilingual language teaching  :with:  natural language processing  ::result:: 67\n",
      "comparing  bilingual language teaching  :with:  automated speech recognition  ::result:: 33\n",
      "comparing  bilingual language teaching  :with:  data collection  ::result:: 40\n",
      "comparing  bilingual language teaching  :with:  computer assisted processes  ::result:: 22\n",
      "comparing  bilingual language teaching  :with:  fine grained error analysis  ::result:: 37\n",
      "comparing  bilingual language teaching  :with:  bilingual language teaching  ::result:: 100\n",
      "comparing  bilingual language teaching  :with:  language teachers  ::result:: 82\n",
      "comparing  speech recognition  :with:  computer - assisted processes  ::result:: 28\n",
      "comparing  speech recognition  :with:  fine - grained error analysis  ::result:: 33\n",
      "comparing  corpus  :with:  computer - assisted processes  ::result:: 67\n",
      "comparing  corpus  :with:  fine - grained error analysis  ::result:: 33\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "MedAI at SemEval-2021 Task 10: Negation-aware Pre-training for Source-free Negation Detection Domain Adaptation. Due to the increasing concerns for data privacy, source-free unsupervised domain adaptation attracts more and more research attention, where only a trained source model is assumed to be available, while the labeled source data remains private. To get promising adaptation results, we need to find effective ways to transfer knowledge learned in source domain and leverage useful domain specific information from target domain at the same time. This paper describes our winning contribution to SemEval 2021 Task 10: Source-Free Domain Adaptation for Semantic Processing. Our key idea is to leverage the model trained on source domain data to generate pseudo labels for target domain samples. Besides, we propose Negationaware Pre-training (NAP) to incorporate negation knowledge into model. Our method wins the 1st place with F1-score of 0.822 on the official blind test set of Negation Detection Track.\n",
      "predicted task:  [{'words': ['source free negation detection', 'negation detection track'], 'value': 0.4352698922, 'top_word': 'source free negation detection'}, {'words': ['semeval 2021'], 'value': 0.8103166819000001, 'top_word': 'semeval 2021'}]\n",
      "predicted method:  [{'words': ['negation aware pre training', 'negationaware pre training'], 'value': 0.272423476, 'top_word': 'negation aware pre training'}]\n",
      "actual task:  ['source-free negation detection']\n",
      "actual method:  ['negationaware pre-training']\n",
      "comparing  source-free negation detection  :with:  source free negation detection  ::result:: 97\n",
      "comparing  source-free negation detection  :with:  negation detection track  ::result:: 86\n",
      "comparing  source-free negation detection  :with:  semeval 2021  ::result:: 33\n",
      "comparing  negationaware pre-training  :with:  negation aware pre training  ::result:: 92\n",
      "comparing  negationaware pre-training  :with:  negationaware pre training  ::result:: 96\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "An Unsupervised Vector Approach to Biomedical Term Disambiguation: Integrating UMLS and Medline. This paper introduces an unsupervised vector approach to disambiguate words in biomedical text that can be applied to all-word disambiguation. We explore using contextual information from the Unified Medical Language System (UMLS) to describe the possible senses of a word. We experiment with automatically creating individualized stoplists to help reduce the noise in our dataset. We compare our results to SenseClusters and Humphrey et al. (2006) using the NLM-WSD dataset and with SenseClusters using conflated data from the 2005 Medline Baseline.\n",
      "predicted task:  [{'words': ['biomedical term disambiguation', 'all word disambiguation'], 'value': 0.4234089404, 'top_word': 'biomedical term disambiguation'}]\n",
      "predicted method:  [{'words': ['unsupervised vector approach'], 'value': 0, 'top_word': 'unsupervised vector approach'}, {'words': ['umls'], 'value': 0, 'top_word': 'umls'}, {'words': ['unsupervised vector approach'], 'value': 0, 'top_word': 'unsupervised vector approach'}, {'words': ['unified medical language system'], 'value': 0, 'top_word': 'unified medical language system'}, {'words': ['senseclusters'], 'value': 0, 'top_word': 'senseclusters'}]\n",
      "actual task:  ['biomedical term disambiguation']\n",
      "actual method:  ['contextual information']\n",
      "comparing  biomedical term disambiguation  :with:  biomedical term disambiguation  ::result:: 100\n",
      "comparing  biomedical term disambiguation  :with:  all word disambiguation  ::result:: 83\n",
      "comparing  contextual information  :with:  unsupervised vector approach  ::result:: 27\n",
      "comparing  contextual information  :with:  umls  ::result:: 50\n",
      "comparing  contextual information  :with:  unsupervised vector approach  ::result:: 27\n",
      "comparing  contextual information  :with:  unified medical language system  ::result:: 32\n",
      "comparing  contextual information  :with:  senseclusters  ::result:: 23\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Extracting Fine-Grained Economic Events from Business News. Based on a recently developed fine-grained event extraction dataset for the economic domain, we present in a pilot study for supervised economic event extraction. We investigate how a stateof-the-art model for event extraction performs on the trigger and argument identification and classification. While F 1-scores of above 50% are obtained on the task of trigger identification, we observe a large gap in performance compared to results on the benchmark ACE05 dataset. We show that single-token triggers do not provide sufficient discriminative information for a finegrained event detection setup in a closed domain such as economics, since many classes have a large degree of lexico-semantic and contextual overlap.\n",
      "predicted task:  [{'words': ['extracting fine grained economic events', 'supervised economic event extraction', 'event extraction'], 'value': 0.2921973616, 'top_word': 'extracting fine grained economic events'}, {'words': ['classification'], 'value': 0.3153921366, 'top_word': 'classification'}, {'words': ['finegrained event detection setup'], 'value': 0.4459644854, 'top_word': 'finegrained event detection setup'}]\n",
      "predicted method:  [{'words': ['supervised learning'], 'value': 0, 'top_word': 'supervised learning'}, {'words': ['event extraction'], 'value': 0, 'top_word': 'event extraction'}, {'words': ['trigger identification'], 'value': 0, 'top_word': 'trigger identification'}, {'words': ['argument identification'], 'value': 0, 'top_word': 'argument identification'}, {'words': ['classification'], 'value': 0, 'top_word': 'classification'}]\n",
      "actual task:  ['supervised economic event extraction']\n",
      "actual method:  ['pilot study']\n",
      "comparing  supervised economic event extraction  :with:  extracting fine grained economic events  ::result:: 65\n",
      "comparing  supervised economic event extraction  :with:  supervised economic event extraction  ::result:: 100\n",
      "comparing  supervised economic event extraction  :with:  event extraction  ::result:: 100\n",
      "comparing  supervised economic event extraction  :with:  classification  ::result:: 43\n",
      "comparing  supervised economic event extraction  :with:  finegrained event detection setup  ::result:: 58\n",
      "comparing  pilot study  :with:  supervised learning  ::result:: 36\n",
      "comparing  pilot study  :with:  event extraction  ::result:: 27\n",
      "comparing  pilot study  :with:  trigger identification  ::result:: 27\n",
      "comparing  pilot study  :with:  argument identification  ::result:: 27\n",
      "comparing  pilot study  :with:  classification  ::result:: 18\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Architectures of ``toy'' systems for teaching machine translation. This paper addresses the advantages of practical academic teaching of machine translation by implementations of \"toy\" systems. This is the result of experience from several semesters with different types of courses and different categories of students. In addition to describing two possible architectures for such educational toy systems, we will also discuss how to overcome misconceptions about MT and the evaluation both of the achieved systems and the learning success.\n",
      "predicted task:  [{'words': ['teaching machine translation', 'machine translation', 'mt'], 'value': 0.5982012053, 'top_word': 'teaching machine translation'}]\n",
      "predicted method:  [{'words': [\"``toy'' systems\"], 'value': 0, 'top_word': \"``toy'' systems\"}, {'words': ['\"toy\" systems'], 'value': 0, 'top_word': '\"toy\" systems'}]\n",
      "actual task:  ['academic teaching']\n",
      "actual method:  ['describing two possible architectures']\n",
      "comparing  academic teaching  :with:  teaching machine translation  ::result:: 53\n",
      "comparing  academic teaching  :with:  machine translation  ::result:: 41\n",
      "comparing  academic teaching  :with:  mt  ::result:: 50\n",
      "comparing  describing two possible architectures  :with:  ``toy'' systems  ::result:: 40\n",
      "comparing  describing two possible architectures  :with:  \"toy\" systems  ::result:: 46\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Dependency-Based Relation Mining for Biomedical Literature. We describe techniques for the automatic detection of relationships among domain entities (e.g. genes, proteins, diseases) mentioned in the biomedical literature. Our approach is based on the adaptive selection of candidate interactions sentences, which are then parsed using our own dependency parser. Specific syntax-based filters are used to limit the number of possible candidate interacting pairs. The approach has been implemented as a demonstrator over a corpus of 2000 richly annotated MedLine abstracts, and later tested by participation to a text mining competition. In both cases, the results obtained have proved the adequacy of the proposed approach to the task of interaction detection.\n",
      "predicted task:  [{'words': ['dependency based relation mining', 'automatic detection of relationships among domain entities'], 'value': 0.1735263467, 'top_word': 'dependency based relation mining'}]\n",
      "predicted method:  [{'words': ['dependency parser'], 'value': 0, 'top_word': 'dependency parser'}, {'words': ['syntax - based filters'], 'value': 0, 'top_word': 'syntax - based filters'}]\n",
      "actual task:  ['dependency-based relation mining', 'text mining']\n",
      "actual method:  ['dependency parser']\n",
      "comparing  dependency-based relation mining  :with:  dependency based relation mining  ::result:: 97\n",
      "comparing  dependency-based relation mining  :with:  automatic detection of relationships among domain entities  ::result:: 50\n",
      "comparing  dependency parser  :with:  dependency parser  ::result:: 100\n",
      "comparing  dependency parser  :with:  syntax - based filters  ::result:: 29\n",
      "0.5\n",
      "1.0\n",
      "\n",
      "Automatic Labeling of Problem-Solving Dialogues for Computational Microgenetic Learning Analytics. This paper presents a recurrent neural network model to automate the analysis of students' computational thinking in problem-solving dialogue. We have collected and annotated dialogue transcripts from middle school students solving a robotics challenge, and each dialogue turn is assigned a code. We use sentence embeddings and speaker identities as features, and experiment with linear chain CRFs and RNNs with a CRF layer (LSTM-CRF). Both the linear chain CRF model and the LSTM-CRF model outperform the naïve baselines by a large margin, and LSTM-CRF has an edge between the two. To our knowledge, this is the first study on dialogue segment annotation using neural network models. This study is also a stepping-stone to automating the microgenetic analysis of cognitive interactions between students.\n",
      "predicted task:  [{'words': ['automatic labeling of problem - solving dialogues'], 'value': 0, 'top_word': 'automatic labeling of problem - solving dialogues'}, {'words': ['computational microgenetic learning analytics'], 'value': 0, 'top_word': 'computational microgenetic learning analytics'}, {'words': [\"analysis of students' computational thinking\"], 'value': 0, 'top_word': \"analysis of students' computational thinking\"}, {'words': ['problem - solving dialogue'], 'value': 0, 'top_word': 'problem - solving dialogue'}, {'words': ['robotics challenge'], 'value': 0, 'top_word': 'robotics challenge'}, {'words': ['dialogue segment annotation'], 'value': 0, 'top_word': 'dialogue segment annotation'}, {'words': ['microgenetic analysis of cognitive interactions between students'], 'value': 0, 'top_word': 'microgenetic analysis of cognitive interactions between students'}]\n",
      "predicted method:  [{'words': ['recurrent neural network model'], 'value': 0, 'top_word': 'recurrent neural network model'}, {'words': ['linear chain crfs'], 'value': 0, 'top_word': 'linear chain crfs'}, {'words': ['rnns'], 'value': 0, 'top_word': 'rnns'}, {'words': ['crf layer'], 'value': 0, 'top_word': 'crf layer'}, {'words': ['crf)'], 'value': 0, 'top_word': 'crf)'}, {'words': ['linear chain crf model'], 'value': 0, 'top_word': 'linear chain crf model'}, {'words': ['lstm - crf model'], 'value': 0, 'top_word': 'lstm - crf model'}, {'words': ['lstm - crf'], 'value': 0, 'top_word': 'lstm - crf'}, {'words': ['neural network models'], 'value': 0, 'top_word': 'neural network models'}]\n",
      "actual task:  ['automatic labeling']\n",
      "actual method:  ['sentence embeddings', 'linear chain crf model', 'rnns', 'lstm-crf', 'microgenetic learning analytics']\n",
      "comparing  automatic labeling  :with:  automatic labeling of problem - solving dialogues  ::result:: 100\n",
      "comparing  automatic labeling  :with:  computational microgenetic learning analytics  ::result:: 56\n",
      "comparing  automatic labeling  :with:  analysis of students' computational thinking  ::result:: 56\n",
      "comparing  automatic labeling  :with:  problem - solving dialogue  ::result:: 39\n",
      "comparing  automatic labeling  :with:  robotics challenge  ::result:: 50\n",
      "comparing  automatic labeling  :with:  dialogue segment annotation  ::result:: 39\n",
      "comparing  automatic labeling  :with:  microgenetic analysis of cognitive interactions between students  ::result:: 44\n",
      "comparing  sentence embeddings  :with:  recurrent neural network model  ::result:: 37\n",
      "comparing  sentence embeddings  :with:  linear chain crfs  ::result:: 35\n",
      "comparing  sentence embeddings  :with:  rnns  ::result:: 50\n",
      "comparing  sentence embeddings  :with:  crf layer  ::result:: 33\n",
      "comparing  sentence embeddings  :with:  crf)  ::result:: 25\n",
      "comparing  sentence embeddings  :with:  linear chain crf model  ::result:: 37\n",
      "comparing  sentence embeddings  :with:  lstm - crf model  ::result:: 38\n",
      "comparing  sentence embeddings  :with:  lstm - crf  ::result:: 20\n",
      "comparing  sentence embeddings  :with:  neural network models  ::result:: 37\n",
      "comparing  linear chain crf model  :with:  recurrent neural network model  ::result:: 55\n",
      "comparing  linear chain crf model  :with:  linear chain crfs  ::result:: 94\n",
      "comparing  linear chain crf model  :with:  rnns  ::result:: 25\n",
      "comparing  linear chain crf model  :with:  crf layer  ::result:: 56\n",
      "comparing  linear chain crf model  :with:  crf)  ::result:: 75\n",
      "comparing  linear chain crf model  :with:  linear chain crf model  ::result:: 100\n",
      "comparing  linear chain crf model  :with:  lstm - crf model  ::result:: 69\n",
      "comparing  linear chain crf model  :with:  lstm - crf  ::result:: 50\n",
      "comparing  linear chain crf model  :with:  neural network models  ::result:: 59\n",
      "comparing  rnns  :with:  recurrent neural network model  ::result:: 25\n",
      "comparing  rnns  :with:  linear chain crfs  ::result:: 50\n",
      "comparing  rnns  :with:  rnns  ::result:: 100\n",
      "comparing  rnns  :with:  crf layer  ::result:: 25\n",
      "comparing  rnns  :with:  crf)  ::result:: 25\n",
      "comparing  rnns  :with:  lstm - crf model  ::result:: 25\n",
      "comparing  rnns  :with:  lstm - crf  ::result:: 25\n",
      "comparing  rnns  :with:  neural network models  ::result:: 25\n",
      "comparing  lstm-crf  :with:  recurrent neural network model  ::result:: 38\n",
      "comparing  lstm-crf  :with:  linear chain crfs  ::result:: 38\n",
      "comparing  lstm-crf  :with:  crf layer  ::result:: 25\n",
      "comparing  lstm-crf  :with:  crf)  ::result:: 86\n",
      "comparing  lstm-crf  :with:  lstm - crf model  ::result:: 75\n",
      "comparing  lstm-crf  :with:  lstm - crf  ::result:: 75\n",
      "comparing  lstm-crf  :with:  neural network models  ::result:: 38\n",
      "comparing  microgenetic learning analytics  :with:  recurrent neural network model  ::result:: 37\n",
      "comparing  microgenetic learning analytics  :with:  linear chain crfs  ::result:: 47\n",
      "comparing  microgenetic learning analytics  :with:  crf layer  ::result:: 56\n",
      "comparing  microgenetic learning analytics  :with:  lstm - crf model  ::result:: 25\n",
      "comparing  microgenetic learning analytics  :with:  lstm - crf  ::result:: 30\n",
      "comparing  microgenetic learning analytics  :with:  neural network models  ::result:: 33\n",
      "1.0\n",
      "0.6\n",
      "\n",
      "Linguistic and Acoustic Features for Automatic Identification of Autism Spectrum Disorders in Children's Narrative. Autism spectrum disorders are developmental disorders characterised as deficits in social and communication skills, and they affect both verbal and non-verbal communication. Previous works measured differences in children with and without autism spectrum disorders in terms of linguistic and acoustic features, although they do not mention automatic identification using integration of these features. In this paper, we perform an exploratory study of several language and speech features of both single utterances and full narratives. We find that there are characteristic differences between children with autism spectrum disorders and typical development with respect to word categories, prosody, and voice quality, and that these differences can be used in automatic classifiers. We also examine the differences between American and Japanese children and find significant differences with regards to pauses before new turns and linguistic cues.\n",
      "predicted task:  [{'words': ['automatic identification of autism spectrum disorders'], 'value': 0, 'top_word': 'automatic identification of autism spectrum disorders'}, {'words': ['verbal and non - verbal communication'], 'value': 0, 'top_word': 'verbal and non - verbal communication'}, {'words': ['automatic identification'], 'value': 0, 'top_word': 'automatic identification'}, {'words': ['automatic classifiers'], 'value': 0, 'top_word': 'automatic classifiers'}]\n",
      "predicted method:  [{'words': ['automatic classification'], 'value': 0, 'top_word': 'automatic classification'}, {'words': ['word categories'], 'value': 0, 'top_word': 'word categories'}, {'words': ['prosody'], 'value': 0, 'top_word': 'prosody'}, {'words': ['voice quality'], 'value': 0, 'top_word': 'voice quality'}]\n",
      "actual task:  ['automatic identification of autism spectrum disorders']\n",
      "actual method:  ['linguistic and acoustic features']\n",
      "comparing  automatic identification of autism spectrum disorders  :with:  automatic identification of autism spectrum disorders  ::result:: 100\n",
      "comparing  automatic identification of autism spectrum disorders  :with:  verbal and non - verbal communication  ::result:: 35\n",
      "comparing  automatic identification of autism spectrum disorders  :with:  automatic identification  ::result:: 100\n",
      "comparing  automatic identification of autism spectrum disorders  :with:  automatic classifiers  ::result:: 62\n",
      "comparing  linguistic and acoustic features  :with:  automatic classification  ::result:: 42\n",
      "comparing  linguistic and acoustic features  :with:  word categories  ::result:: 47\n",
      "comparing  linguistic and acoustic features  :with:  prosody  ::result:: 29\n",
      "comparing  linguistic and acoustic features  :with:  voice quality  ::result:: 46\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "WTMED at MEDIQA 2019: A Hybrid Approach to Biomedical Natural Language Inference. Natural language inference (NLI) is challenging, especially when it is applied to technical domains such as biomedical settings. In this paper, we propose a hybrid approach to biomedical NLI where different types of information are exploited for this task. Our base model includes a pre-trained text encoder as the core component, and a syntax encoder and a feature encoder to capture syntactic and domain-specific information. Then we combine the output of different base models to form more powerful ensemble models. Finally, we design two conflict resolution strategies when the test data contain multiple (premise, hypothesis) pairs with the same premise. We train our models on the MedNLI dataset, yielding the best performance on the test set of the MEDIQA 2019 Task 1.\n",
      "predicted task:  [{'words': ['biomedical natural language inference', 'natural language inference', 'biomedical nli'], 'value': 0.7655127645, 'top_word': 'natural language inference'}]\n",
      "predicted method:  [{'words': ['hybrid approach', 'hybrid approach'], 'value': 0.24208025630000002, 'top_word': 'hybrid approach'}]\n",
      "actual task:  ['natural language inference']\n",
      "actual method:  ['pre-trained text encoder', 'syntax encoder', 'ensemble models']\n",
      "comparing  natural language inference  :with:  biomedical natural language inference  ::result:: 100\n",
      "comparing  natural language inference  :with:  natural language inference  ::result:: 100\n",
      "comparing  natural language inference  :with:  biomedical nli  ::result:: 21\n",
      "comparing  pre-trained text encoder  :with:  hybrid approach  ::result:: 33\n",
      "comparing  pre-trained text encoder  :with:  hybrid approach  ::result:: 33\n",
      "comparing  syntax encoder  :with:  hybrid approach  ::result:: 21\n",
      "comparing  syntax encoder  :with:  hybrid approach  ::result:: 21\n",
      "comparing  ensemble models  :with:  hybrid approach  ::result:: 20\n",
      "comparing  ensemble models  :with:  hybrid approach  ::result:: 20\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Tintin at SemEval-2019 Task 4: Detecting Hyperpartisan News Article with only Simple Tokens. Tintin, the system proposed by the CECL for the Hyperpartisan News Detection task of Se-mEval 2019, is exclusively based on the tokens that make up the documents and a standard supervised learning procedure. It obtained very contrasting results: poor on the main task, but much more effective at distinguishing documents published by hyperpartisan media outlets from unbiased ones, as it ranked first. An analysis of the most important features highlighted the positive aspects, but also some potential limitations of the approach.\n",
      "predicted task:  [{'words': ['detecting hyperpartisan news article', 'hyperpartisan news detection task'], 'value': 0.31213906410000003, 'top_word': 'detecting hyperpartisan news article'}]\n",
      "predicted method:  [{'words': ['tintin', 'cecl'], 'value': 0.21371699500000002, 'top_word': 'tintin'}]\n",
      "actual task:  ['hyperpartisan news detection']\n",
      "actual method:  ['simple tokens']\n",
      "comparing  hyperpartisan news detection  :with:  detecting hyperpartisan news article  ::result:: 78\n",
      "comparing  hyperpartisan news detection  :with:  hyperpartisan news detection task  ::result:: 100\n",
      "comparing  simple tokens  :with:  tintin  ::result:: 33\n",
      "comparing  simple tokens  :with:  cecl  ::result:: 25\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Debiasing Embeddings for Reduced Gender Bias in Text Classification. Bolukbasi et al., 2016) demonstrated that pretrained word embeddings can inherit gender bias from the data they were trained on. We investigate how this bias affects downstream classification tasks, using the case study of occupation classification (De-Arteaga et al., 2019). We show that traditional techniques for debiasing embeddings can actually worsen the bias of the downstream classifier by providing a less noisy channel for communicating gender information. With a relatively minor adjustment, however, we show how these same techniques can be used to simultaneously reduce bias and maintain high classification accuracy.\n",
      "predicted task:  [{'words': ['text classification', 'downstream classification tasks', 'occupation classification'], 'value': 0.3735835652, 'top_word': 'text classification'}]\n",
      "predicted method:  [{'words': ['debiasing embeddings'], 'value': 0, 'top_word': 'debiasing embeddings'}, {'words': ['downstream classifier'], 'value': 0, 'top_word': 'downstream classifier'}]\n",
      "actual task:  ['text classification']\n",
      "actual method:  ['classifier', 'embeddings']\n",
      "comparing  text classification  :with:  text classification  ::result:: 100\n",
      "comparing  text classification  :with:  downstream classification tasks  ::result:: 84\n",
      "comparing  text classification  :with:  occupation classification  ::result:: 84\n",
      "comparing  classifier  :with:  debiasing embeddings  ::result:: 40\n",
      "comparing  classifier  :with:  downstream classifier  ::result:: 100\n",
      "comparing  embeddings  :with:  debiasing embeddings  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "A Multimodal Dataset for Deception Detection. This paper presents the construction of a multimodal dataset for deception detection, including physiological, thermal, and visual responses of human subjects under three deceptive scenarios. We present the experimental protocol, as well as the data acquisition process. To evaluate the usefulness of the dataset for the task of deception detection, we present a statistical analysis of the physiological and thermal modalities associated with the deceptive and truthful conditions. Initial results show that physiological and thermal responses can differentiate between deceptive and truthful states.\n",
      "predicted task:  [{'words': ['deception detection', 'deception detection', 'deception detection'], 'value': 0.7061952154000001, 'top_word': 'deception detection'}]\n",
      "predicted method:  [{'words': ['statistical analysis'], 'value': 0, 'top_word': 'statistical analysis'}]\n",
      "actual task:  ['deception detection']\n",
      "actual method:  ['multimodal dataset', 'statistical analysis']\n",
      "comparing  deception detection  :with:  deception detection  ::result:: 100\n",
      "comparing  deception detection  :with:  deception detection  ::result:: 100\n",
      "comparing  deception detection  :with:  deception detection  ::result:: 100\n",
      "comparing  multimodal dataset  :with:  statistical analysis  ::result:: 44\n",
      "comparing  statistical analysis  :with:  statistical analysis  ::result:: 100\n",
      "1.0\n",
      "0.5\n",
      "\n",
      "A Research Platform for Multi-Robot Dialogue with Humans. This paper presents a research platform that supports spoken dialogue interaction with multiple robots. The demonstration showcases our crafted MultiBot testing scenario in which users can verbally issue search, navigate, and follow instructions to two robotic teammates: a simulated ground robot and an aerial robot. This flexible language and robotic platform takes advantage of existing tools for speech recognition and dialogue management that are compatible with new domains, and implements an inter-agent communication protocol (tactical behavior specification), where verbal instructions are encoded for tasks assigned to the appropriate robot.\n",
      "predicted task:  [{'words': ['multi robot dialogue', 'multibot testing scenario'], 'value': 0.1881504059, 'top_word': 'multi robot dialogue'}]\n",
      "predicted method:  [{'words': ['robotic platform'], 'value': 0, 'top_word': 'robotic platform'}, {'words': ['inter - agent communication protocol'], 'value': 0, 'top_word': 'inter - agent communication protocol'}]\n",
      "actual task:  ['multi-robot dialogue with humans']\n",
      "actual method:  ['research platform']\n",
      "comparing  multi-robot dialogue with humans  :with:  multi robot dialogue  ::result:: 95\n",
      "comparing  multi-robot dialogue with humans  :with:  multibot testing scenario  ::result:: 52\n",
      "comparing  research platform  :with:  robotic platform  ::result:: 69\n",
      "comparing  research platform  :with:  inter - agent communication protocol  ::result:: 35\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Evaluating productivity gains of hybrid ASR-MT systems for translation dictation.. This paper is about Translation Dictation with ASR, that is, the use of Automatic Speech Recognition (ASR) by human translators, in order to dictate translations. We are particularly interested in the productivity gains that this could provide over conventional keyboard input, and ways in which such gains might be increased through a combination of ASR and Statistical Machine Translation (SMT). In this hybrid technology, the source language text is presented to both the human translator and a SMT system. The latter produces Nbest translations hypotheses, which are then used to fine tune the ASR language model and vocabulary towards utterances which are probable translations of source text sentences. We conducted an ergonomic experiment with eight professional translators dictating into French, using a top of the line offthe-shelf ASR system (Dragon NatuallySpeaking 8). We found that the ASR system had an average Word Error Rate (WER) of 11.7%, and that translation using this system did not provide statistically significant productivity increases over keyboard input, when following the manufacturer recommended procedure for error correction. However, we found indications that, even in its current imperfect state, French ASR might be beneficial to translators who are already used to dictation (either with ASR or a dictaphone), but more focused experiments are needed to confirm this. We also found that dictation using an ASR with WER of 4% or less would have resulted in statistically significant (p < 0.6) productivity gains in the order of 25.1% to 44.9% Translated Words Per Minute. We also evaluated the extent to which the limited manufacturer provided Domain Adaptation features could be used to positively bias the ASR using SMT hypotheses. We found that the relative gains in WER were much lower than has been reported in the literature for tighter integration of SMT with ASR, pointing the advantages of tight integration approaches and the need for more research in that area.\n",
      "predicted task:  [{'words': ['translation dictation', 'translation dictation'], 'value': 0.5527668893000001, 'top_word': 'translation dictation'}, {'words': ['asr', 'asr'], 'value': 0.29110737140000004, 'top_word': 'asr'}, {'words': ['automatic speech recognition'], 'value': 0.46070253850000004, 'top_word': 'automatic speech recognition'}, {'words': ['translation'], 'value': 0.3971374929, 'top_word': 'translation'}]\n",
      "predicted method:  [{'words': ['statistical machine translation', 'smt system', 'smt hypotheses', 'smt'], 'value': 0.2314211018, 'top_word': 'statistical machine translation'}, {'words': ['asr system', 'asr system', 'asr', 'asr', 'asr', 'asr', 'asr'], 'value': 0.2682202842, 'top_word': 'asr'}, {'words': ['hybrid asr mt systems'], 'value': 0.38688144090000004, 'top_word': 'hybrid asr mt systems'}]\n",
      "actual task:  ['translation dictation', 'automatic speech recognition']\n",
      "actual method:  ['evaluation']\n",
      "comparing  translation dictation  :with:  translation dictation  ::result:: 100\n",
      "comparing  translation dictation  :with:  translation dictation  ::result:: 100\n",
      "comparing  translation dictation  :with:  asr  ::result:: 67\n",
      "comparing  translation dictation  :with:  asr  ::result:: 67\n",
      "comparing  translation dictation  :with:  automatic speech recognition  ::result:: 38\n",
      "comparing  translation dictation  :with:  translation  ::result:: 100\n",
      "comparing  automatic speech recognition  :with:  asr  ::result:: 33\n",
      "comparing  automatic speech recognition  :with:  asr  ::result:: 33\n",
      "comparing  automatic speech recognition  :with:  automatic speech recognition  ::result:: 100\n",
      "comparing  automatic speech recognition  :with:  translation  ::result:: 55\n",
      "comparing  evaluation  :with:  statistical machine translation  ::result:: 70\n",
      "comparing  evaluation  :with:  smt system  ::result:: 10\n",
      "comparing  evaluation  :with:  smt hypotheses  ::result:: 20\n",
      "comparing  evaluation  :with:  smt  ::result:: 33\n",
      "comparing  evaluation  :with:  asr system  ::result:: 20\n",
      "comparing  evaluation  :with:  asr system  ::result:: 20\n",
      "comparing  evaluation  :with:  asr  ::result:: 33\n",
      "comparing  evaluation  :with:  asr  ::result:: 33\n",
      "comparing  evaluation  :with:  asr  ::result:: 33\n",
      "comparing  evaluation  :with:  asr  ::result:: 33\n",
      "comparing  evaluation  :with:  asr  ::result:: 33\n",
      "comparing  evaluation  :with:  hybrid asr mt systems  ::result:: 20\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Social Bias in Elicited Natural Language Inferences. We analyze the Stanford Natural Language Inference (SNLI) corpus in an investigation of bias and stereotyping in NLP data. The human-elicitation protocol employed in the construction of the SNLI makes it prone to amplifying bias and stereotypical associations, which we demonstrate statistically (using pointwise mutual information) and with qualitative examples.\n",
      "predicted task:  [{'words': ['social bias'], 'value': 0, 'top_word': 'social bias'}, {'words': ['bias and stereotyping'], 'value': 0, 'top_word': 'bias and stereotyping'}]\n",
      "predicted method:  [{'words': ['human - elicitation protocol'], 'value': 0, 'top_word': 'human - elicitation protocol'}]\n",
      "actual task:  ['natural language inference']\n",
      "actual method:  ['statistical analysis']\n",
      "comparing  natural language inference  :with:  social bias  ::result:: 36\n",
      "comparing  natural language inference  :with:  bias and stereotyping  ::result:: 43\n",
      "comparing  statistical analysis  :with:  human - elicitation protocol  ::result:: 35\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "From ADHD to SAD: Analyzing the Language of Mental Health on Twitter through Self-Reported Diagnoses. Many significant challenges exist for the mental health field, but one in particular is a lack of data available to guide research. Language provides a natural lens for studying mental health-much existing work and therapy have strong linguistic components, so the creation of a large, varied, language-centric dataset could provide significant grist for the field of mental health research. We examine a broad range of mental health conditions in Twitter data by identifying self-reported statements of diagnosis. We systematically explore language differences between ten conditions with respect to the general population, and to each other. Our aim is to provide guidance and a roadmap for where deeper exploration is likely to be fruitful.\n",
      "predicted task:  [{'words': ['mental health field', 'mental health'], 'value': 0.2078470476, 'top_word': 'mental health'}]\n",
      "predicted method:  [{'words': ['linguistic components'], 'value': 0, 'top_word': 'linguistic components'}]\n",
      "actual task:  ['mental health']\n",
      "actual method:  ['language analysis']\n",
      "comparing  mental health  :with:  mental health field  ::result:: 100\n",
      "comparing  mental health  :with:  mental health  ::result:: 100\n",
      "comparing  language analysis  :with:  linguistic components  ::result:: 35\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Extracting Patient Clinical Profiles from Case Reports. This research aims to extract detailed clinical profiles, such as signs and symptoms, and important laboratory test results of the patient from descriptions of the diagnostic and treatment procedures in journal articles. This paper proposes a novel markup tag set to cover a wide variety of semantics in the description of clinical case studies in the clinical literature. A manually annotated corpus which consists of 75 clinical reports with 5,117 sentences has been created and a sentence classification system is reported as the preliminary attempt to exploit the fast growing online repositories of clinical case reports.\n",
      "predicted task:  [{'words': ['extracting patient clinical profiles'], 'value': 0, 'top_word': 'extracting patient clinical profiles'}, {'words': ['diagnostic and treatment procedures'], 'value': 0, 'top_word': 'diagnostic and treatment procedures'}, {'words': ['description of clinical case studies'], 'value': 0, 'top_word': 'description of clinical case studies'}]\n",
      "predicted method:  [{'words': ['markup tag set'], 'value': 0, 'top_word': 'markup tag set'}, {'words': ['sentence classification system'], 'value': 0, 'top_word': 'sentence classification system'}]\n",
      "actual task:  ['extracting patient clinical profiles']\n",
      "actual method:  ['sentence classification system']\n",
      "comparing  extracting patient clinical profiles  :with:  extracting patient clinical profiles  ::result:: 100\n",
      "comparing  extracting patient clinical profiles  :with:  diagnostic and treatment procedures  ::result:: 47\n",
      "comparing  extracting patient clinical profiles  :with:  description of clinical case studies  ::result:: 56\n",
      "comparing  sentence classification system  :with:  markup tag set  ::result:: 36\n",
      "comparing  sentence classification system  :with:  sentence classification system  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "HumorHunter at SemEval-2021 Task 7: Humor and Offense Recognition with Disentangled Attention. In this paper, we describe our system submitted to SemEval 2021 Task 7: HaHackathon: Detecting and Rating Humor and Offense. The task aims at predicting whether the given text is humorous, the average humor rating given by the annotators, and whether the humor rating is controversial. In addition, the task also involves predicting how offensive the text is. Our approach adopts the DeBERTa architecture with disentangled attention mechanism, where the attention scores between words are calculated based on their content vectors and relative position vectors. We also took advantage of the pre-trained language models and fine-tuned the DeBERTa model on all the four subtasks. We experimented with several BERT-like structures and found that the large DeBERTa model generally performs better. During the evaluation phase, our system achieved an F-score of 0.9480 on subtask 1a, an RMSE of 0.5510 on subtask 1b, an F-score of 0.4764 on subtask 1c, and an RMSE of 0.4230 on subtask 2a (rank 3 on the leaderboard).\n",
      "predicted task:  [{'words': ['semeval 2021 task'], 'value': 0.29884070160000004, 'top_word': 'semeval 2021 task'}]\n",
      "predicted method:  [{'words': ['deberta architecture', 'deberta model', 'deberta model'], 'value': 0.28205959999999997, 'top_word': 'deberta model'}]\n",
      "actual task:  ['humor and offense recognition']\n",
      "actual method:  ['deberta', 'disentangled attention']\n",
      "comparing  humor and offense recognition  :with:  semeval 2021 task  ::result:: 24\n",
      "comparing  deberta  :with:  deberta architecture  ::result:: 100\n",
      "comparing  deberta  :with:  deberta model  ::result:: 100\n",
      "comparing  deberta  :with:  deberta model  ::result:: 100\n",
      "0.0\n",
      "0.5\n",
      "\n",
      "LEXIPLOIGISSI: An Educational Platform for the Teaching of Terminology in Greece. This paper introduces a project, LEXIPLOIGISSI * , which involves use of language resources for educational purposes. More particularly, the aim of the project is to develop written corpora, electronic dictionaries and exercises to enhance students' reading and writing abilities in six different school subjects. It is the product of a small-scale pilot program that will be part of the school curriculum in the three grades of Upper Secondary Education in Greece. The application seeks to create exploratory learning environments in which digital sound, image, text and video are fully integrated through the educational platform and placed under the direct control of users who are able to follow individual pathways through data stores. * The Institute for Language and Speech Processing has undertaken this project as the leading contractor and Kastaniotis Publications as a subcontractor. The first partner was responsible for the design, development and implementation of the educational platform, as well as for the provision of pedagogic scenarios of use; the second partner provided the resources (texts and multimedia material). The starting date of the project was June 1999, the development of the software and the collection of material lasted nine months.\n",
      "predicted task:  [{'words': ['teaching of terminology'], 'value': 0, 'top_word': 'teaching of terminology'}, {'words': ['educational purposes'], 'value': 0, 'top_word': 'educational purposes'}, {'words': ['reading and writing abilities'], 'value': 0, 'top_word': 'reading and writing abilities'}, {'words': ['pilot program'], 'value': 0, 'top_word': 'pilot program'}, {'words': ['school curriculum'], 'value': 0, 'top_word': 'school curriculum'}, {'words': ['upper secondary education'], 'value': 0, 'top_word': 'upper secondary education'}, {'words': ['exploratory learning environments'], 'value': 0, 'top_word': 'exploratory learning environments'}, {'words': ['language and speech processing'], 'value': 0, 'top_word': 'language and speech processing'}, {'words': ['educational platform'], 'value': 0, 'top_word': 'educational platform'}]\n",
      "predicted method:  [{'words': ['lexiploigissi'], 'value': 0, 'top_word': 'lexiploigissi'}, {'words': ['educational platform'], 'value': 0, 'top_word': 'educational platform'}, {'words': ['lexiploigissi *'], 'value': 0, 'top_word': 'lexiploigissi *'}, {'words': ['educational platform'], 'value': 0, 'top_word': 'educational platform'}]\n",
      "actual task:  ['teaching of terminology']\n",
      "actual method:  ['educational platform']\n",
      "comparing  teaching of terminology  :with:  teaching of terminology  ::result:: 100\n",
      "comparing  teaching of terminology  :with:  educational purposes  ::result:: 35\n",
      "comparing  teaching of terminology  :with:  reading and writing abilities  ::result:: 48\n",
      "comparing  teaching of terminology  :with:  pilot program  ::result:: 38\n",
      "comparing  teaching of terminology  :with:  school curriculum  ::result:: 35\n",
      "comparing  teaching of terminology  :with:  upper secondary education  ::result:: 32\n",
      "comparing  teaching of terminology  :with:  exploratory learning environments  ::result:: 45\n",
      "comparing  teaching of terminology  :with:  language and speech processing  ::result:: 43\n",
      "comparing  teaching of terminology  :with:  educational platform  ::result:: 40\n",
      "comparing  educational platform  :with:  lexiploigissi  ::result:: 31\n",
      "comparing  educational platform  :with:  educational platform  ::result:: 100\n",
      "comparing  educational platform  :with:  lexiploigissi *  ::result:: 27\n",
      "comparing  educational platform  :with:  educational platform  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Enriching An Academic knowledge base using Linked Open Data. In this paper we present work done towards populating a domain ontology using a public knowledge base like DBpedia. Using an academic ontology as our target we identify mappings between a subset of its predicates and those in DBpedia and other linked datasets. In the semantic web context, ontology mapping allows linking of independently developed ontologies and inter-operation of heterogeneous resources. Linked open data is an initiative in this direction. We populate our ontology by querying the linked open datasets for extracting instances from these resources. We show how these along with semantic web standards and tools enable us to populate the academic ontology. Resulting instances could then be used as seeds in spirit of the typical bootstrapping paradigm.\n",
      "predicted task:  [{'words': ['semantic web context'], 'value': 0, 'top_word': 'semantic web context'}, {'words': ['ontology mapping'], 'value': 0, 'top_word': 'ontology mapping'}, {'words': ['inter - operation of heterogeneous resources'], 'value': 0, 'top_word': 'inter - operation of heterogeneous resources'}]\n",
      "predicted method:  [{'words': ['academic knowledge base'], 'value': 0, 'top_word': 'academic knowledge base'}, {'words': ['bootstrapping paradigm'], 'value': 0, 'top_word': 'bootstrapping paradigm'}]\n",
      "actual task:  ['domain ontology']\n",
      "actual method:  ['querying', 'extracting']\n",
      "comparing  domain ontology  :with:  semantic web context  ::result:: 47\n",
      "comparing  domain ontology  :with:  ontology mapping  ::result:: 47\n",
      "comparing  domain ontology  :with:  inter - operation of heterogeneous resources  ::result:: 47\n",
      "comparing  querying  :with:  academic knowledge base  ::result:: 38\n",
      "comparing  querying  :with:  bootstrapping paradigm  ::result:: 50\n",
      "comparing  extracting  :with:  academic knowledge base  ::result:: 30\n",
      "comparing  extracting  :with:  bootstrapping paradigm  ::result:: 60\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Deep Reinforcement Learning-based Text Anonymization against Private-Attribute Inference. User-generated textual data is rich in content and has been used in many user behavioral modeling tasks. However, it could also leak user private-attribute information that they may not want to disclose such as age and location. User's privacy concerns mandate data publishers to protect privacy. One effective way is to anonymize the textual data. In this paper, we study the problem of textual data anonymization and propose a novel Reinforcement Learning-based Text Anonymizor, RLTA, which addresses the problem of private-attribute leakage while preserving the utility of textual data. Our approach first extracts a latent representation of the original text w.r.t. a given task, then leverages deep reinforcement learning to automatically learn an optimal strategy for manipulating text representations w.r.t. the received privacy and utility feedback. Experiments show the effectiveness of this approach in terms of preserving both privacy and utility.\n",
      "predicted task:  [{'words': ['user behavioral modeling tasks'], 'value': 0, 'top_word': 'user behavioral modeling tasks'}, {'words': ['textual data anonymization'], 'value': 0, 'top_word': 'textual data anonymization'}, {'words': ['private - attribute leakage'], 'value': 0, 'top_word': 'private - attribute leakage'}, {'words': ['text representations'], 'value': 0, 'top_word': 'text representations'}]\n",
      "predicted method:  [{'words': ['deep reinforcement learning based text anonymization', 'reinforcement learning based text anonymizor', 'deep reinforcement learning'], 'value': 0.2485622441, 'top_word': 'deep reinforcement learning based text anonymization'}]\n",
      "actual task:  ['text anonymization']\n",
      "actual method:  ['deep reinforcement learning']\n",
      "comparing  text anonymization  :with:  user behavioral modeling tasks  ::result:: 33\n",
      "comparing  text anonymization  :with:  textual data anonymization  ::result:: 83\n",
      "comparing  text anonymization  :with:  private - attribute leakage  ::result:: 33\n",
      "comparing  text anonymization  :with:  text representations  ::result:: 56\n",
      "comparing  deep reinforcement learning  :with:  deep reinforcement learning based text anonymization  ::result:: 100\n",
      "comparing  deep reinforcement learning  :with:  reinforcement learning based text anonymizor  ::result:: 81\n",
      "comparing  deep reinforcement learning  :with:  deep reinforcement learning  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Data Integration for Toxic Comment Classification: Making More Than 40 Datasets Easily Accessible in One Unified Format. With the rise of research on toxic comment classification, more and more annotated datasets have been released. The wide variety of the task (different languages, different labeling processes and schemes) has led to a large amount of heterogeneous datasets that can be used for training and testing very specific settings. Despite recent efforts to create web pages that provide an overview, most publications still use only a single dataset. They are not stored in one central database, they come in many different data formats and it is difficult to interpret their class labels and how to reuse these labels in other projects.\n",
      "predicted task:  [{'words': ['toxic comment classification', 'toxic comment classification'], 'value': 0.49176511170000003, 'top_word': 'toxic comment classification'}]\n",
      "predicted method:  [{'words': ['labeling processes'], 'value': 0, 'top_word': 'labeling processes'}]\n",
      "actual task:  ['toxic comment classification']\n",
      "actual method:  ['data integration']\n",
      "comparing  toxic comment classification  :with:  toxic comment classification  ::result:: 100\n",
      "comparing  toxic comment classification  :with:  toxic comment classification  ::result:: 100\n",
      "comparing  data integration  :with:  labeling processes  ::result:: 38\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "A Support System for Revising Titles to Stimulate the Lay Reader's Interest in Technical Achievements. When we write a report or an explanation on a newly-developed technology for readers including laypersons, it is very important to compose a title that can stimulate their interest in the technology. However, it is difficult for inexperienced authors to come up with an appealing title. In this research, we developed a support system for revising titles. We call it \"title revision wizard\". The wizard provides a guidance on revising draft title to compose a title meeting three key points, and support tools for coming up with and elaborating on comprehensible or appealing phrases. In order to test the effect of our title revision wizard, we conducted a questionnaire survey on the effect of the titles with or without using the wizard on the interest of lay readers. The survey showed that the wizard is effective and helpful for the authors who cannot compose appealing titles for lay readers by themselves.\n",
      "predicted task:  [{'words': ['revising titles'], 'value': 0, 'top_word': 'revising titles'}, {'words': ['revising titles'], 'value': 0, 'top_word': 'revising titles'}]\n",
      "predicted method:  [{'words': ['support system'], 'value': 0, 'top_word': 'support system'}, {'words': ['support system'], 'value': 0, 'top_word': 'support system'}, {'words': ['revision wizard\"'], 'value': 0, 'top_word': 'revision wizard\"'}, {'words': ['title revision wizard'], 'value': 0, 'top_word': 'title revision wizard'}]\n",
      "actual task:  ['revising titles']\n",
      "actual method:  ['support system', 'questionnaire survey']\n",
      "comparing  revising titles  :with:  revising titles  ::result:: 100\n",
      "comparing  revising titles  :with:  revising titles  ::result:: 100\n",
      "comparing  support system  :with:  support system  ::result:: 100\n",
      "comparing  support system  :with:  support system  ::result:: 100\n",
      "comparing  support system  :with:  revision wizard\"  ::result:: 21\n",
      "comparing  support system  :with:  title revision wizard  ::result:: 21\n",
      "comparing  questionnaire survey  :with:  support system  ::result:: 36\n",
      "comparing  questionnaire survey  :with:  revision wizard\"  ::result:: 44\n",
      "comparing  questionnaire survey  :with:  title revision wizard  ::result:: 35\n",
      "1.0\n",
      "0.5\n",
      "\n",
      "Analyzing Political Bias and Unfairness in News Articles at Different Levels of Granularity. Media organizations bear great reponsibility because of their considerable influence on shaping beliefs and positions of our society. Any form of media can contain overly biased content, e.g., by reporting on political events in a selective or incomplete manner. A relevant question hence is whether and how such form of imbalanced news coverage can be exposed. The research presented in this paper addresses not only the automatic detection of bias but goes one step further in that it explores how political bias and unfairness are manifested linguistically. In this regard we utilize a new corpus of 6964 news articles with labels derived from adfontesmedia.com and develop a neural model for bias assessment. By analyzing this model on article excerpts, we find insightful bias patterns at different levels of text granularity, from single words to the whole article discourse.\n",
      "predicted task:  [{'words': ['analyzing political bias'], 'value': 0, 'top_word': 'analyzing political bias'}, {'words': ['automatic detection of bias'], 'value': 0, 'top_word': 'automatic detection of bias'}, {'words': ['bias assessment'], 'value': 0, 'top_word': 'bias assessment'}]\n",
      "predicted method:  [{'words': ['neural model'], 'value': 0, 'top_word': 'neural model'}]\n",
      "actual task:  ['analyzing political bias']\n",
      "actual method:  ['corpus', 'neural model']\n",
      "comparing  analyzing political bias  :with:  analyzing political bias  ::result:: 100\n",
      "comparing  analyzing political bias  :with:  automatic detection of bias  ::result:: 42\n",
      "comparing  analyzing political bias  :with:  bias assessment  ::result:: 33\n",
      "comparing  corpus  :with:  neural model  ::result:: 17\n",
      "comparing  neural model  :with:  neural model  ::result:: 100\n",
      "1.0\n",
      "0.5\n",
      "\n",
      "Structured prediction models for RNN based sequence labeling in clinical text. Sequence labeling is a widely used method for named entity recognition and information extraction from unstructured natural language data. In the clinical domain one major application of sequence labeling involves extraction of relevant entities such as medication, indication, and side-effects from Electronic Health Record Narratives. Sequence labeling in this domain presents its own set of challenges and objectives. In this work we experiment with Conditional Random Field based structured learning models with Recurrent Neural Networks. We extend the previously studied CRF-LSTM model with explicit modeling of pairwise potentials. We also propose an approximate version of skip-chain CRF inference with RNN potentials. We use these methods 1 for structured prediction in order to improve the exact phrase detection of clinical entities.\n",
      "predicted task:  [{'words': ['named entity recognition'], 'value': 0.47310033440000004, 'top_word': 'named entity recognition'}]\n",
      "predicted method:  [{'words': ['structured prediction models'], 'value': 0, 'top_word': 'structured prediction models'}, {'words': ['conditional random field based structured learning models'], 'value': 0, 'top_word': 'conditional random field based structured learning models'}, {'words': ['recurrent neural networks'], 'value': 0, 'top_word': 'recurrent neural networks'}, {'words': ['crf - lstm model'], 'value': 0, 'top_word': 'crf - lstm model'}, {'words': ['explicit modeling of pairwise potentials'], 'value': 0, 'top_word': 'explicit modeling of pairwise potentials'}, {'words': ['approximate version'], 'value': 0, 'top_word': 'approximate version'}, {'words': ['skip - chain crf inference'], 'value': 0, 'top_word': 'skip - chain crf inference'}, {'words': ['rnn potentials'], 'value': 0, 'top_word': 'rnn potentials'}]\n",
      "actual task:  ['sequence labeling', 'named entity recognition', 'information extraction']\n",
      "actual method:  ['conditional random field', 'recurrent neural networks', 'crf-lstm model']\n",
      "comparing  sequence labeling  :with:  named entity recognition  ::result:: 35\n",
      "comparing  named entity recognition  :with:  named entity recognition  ::result:: 100\n",
      "comparing  conditional random field  :with:  structured prediction models  ::result:: 46\n",
      "comparing  conditional random field  :with:  conditional random field based structured learning models  ::result:: 100\n",
      "comparing  conditional random field  :with:  recurrent neural networks  ::result:: 38\n",
      "comparing  conditional random field  :with:  crf - lstm model  ::result:: 31\n",
      "comparing  conditional random field  :with:  explicit modeling of pairwise potentials  ::result:: 38\n",
      "comparing  conditional random field  :with:  approximate version  ::result:: 32\n",
      "comparing  conditional random field  :with:  skip - chain crf inference  ::result:: 33\n",
      "comparing  conditional random field  :with:  rnn potentials  ::result:: 43\n",
      "comparing  recurrent neural networks  :with:  structured prediction models  ::result:: 40\n",
      "comparing  recurrent neural networks  :with:  recurrent neural networks  ::result:: 100\n",
      "comparing  recurrent neural networks  :with:  crf - lstm model  ::result:: 38\n",
      "comparing  recurrent neural networks  :with:  explicit modeling of pairwise potentials  ::result:: 36\n",
      "comparing  recurrent neural networks  :with:  approximate version  ::result:: 32\n",
      "comparing  recurrent neural networks  :with:  skip - chain crf inference  ::result:: 32\n",
      "comparing  recurrent neural networks  :with:  rnn potentials  ::result:: 36\n",
      "comparing  crf-lstm model  :with:  structured prediction models  ::result:: 57\n",
      "comparing  crf-lstm model  :with:  crf - lstm model  ::result:: 86\n",
      "comparing  crf-lstm model  :with:  explicit modeling of pairwise potentials  ::result:: 57\n",
      "comparing  crf-lstm model  :with:  approximate version  ::result:: 29\n",
      "comparing  crf-lstm model  :with:  skip - chain crf inference  ::result:: 36\n",
      "comparing  crf-lstm model  :with:  rnn potentials  ::result:: 36\n",
      "0.3333333333333333\n",
      "1.0\n",
      "\n",
      "Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph. Symptom diagnosis is a challenging yet profound problem in natural language processing. Most previous research focus on investigating the standard electronic medical records for symptom diagnosis, while the dialogues between doctors and patients that contain more rich information are not well studied. In this paper, we first construct a dialogue symptom diagnosis dataset based on an online medical forum with a large amount of dialogues between patients and doctors. Then, we provide some benchmark models on this dataset to boost the research of dialogue symptom diagnosis. In order to further enhance the performance of symptom diagnosis over dialogues, we propose a global attention mechanism to capture more symptom related information, and build a symptom graph to model the associations between symptoms rather than treating each symptom independently. Experimental results show that both the global attention and symptom graph are effective to boost dialogue symptom diagnosis. In particular, our proposed model achieves the state-of-the-art performance on the constructed dataset.\n",
      "predicted task:  [{'words': ['dialogue symptom diagnosis', 'symptom diagnosis', 'symptom diagnosis', 'dialogue symptom diagnosis', 'symptom diagnosis', 'dialogue symptom diagnosis'], 'value': 0.705699861, 'top_word': 'dialogue symptom diagnosis'}]\n",
      "predicted method:  [{'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}, {'words': ['global attention mechanism'], 'value': 0, 'top_word': 'global attention mechanism'}, {'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}, {'words': ['global attention'], 'value': 0, 'top_word': 'global attention'}, {'words': ['symptom graph'], 'value': 0, 'top_word': 'symptom graph'}]\n",
      "actual task:  ['symptom diagnosis']\n",
      "actual method:  ['global attention mechanism', 'symptom graph']\n",
      "comparing  symptom diagnosis  :with:  dialogue symptom diagnosis  ::result:: 100\n",
      "comparing  symptom diagnosis  :with:  symptom diagnosis  ::result:: 100\n",
      "comparing  symptom diagnosis  :with:  symptom diagnosis  ::result:: 100\n",
      "comparing  symptom diagnosis  :with:  dialogue symptom diagnosis  ::result:: 100\n",
      "comparing  symptom diagnosis  :with:  symptom diagnosis  ::result:: 100\n",
      "comparing  symptom diagnosis  :with:  dialogue symptom diagnosis  ::result:: 100\n",
      "comparing  global attention mechanism  :with:  symptom graph  ::result:: 31\n",
      "comparing  global attention mechanism  :with:  global attention mechanism  ::result:: 100\n",
      "comparing  global attention mechanism  :with:  symptom graph  ::result:: 31\n",
      "comparing  global attention mechanism  :with:  global attention  ::result:: 100\n",
      "comparing  global attention mechanism  :with:  symptom graph  ::result:: 31\n",
      "comparing  symptom graph  :with:  symptom graph  ::result:: 100\n",
      "comparing  symptom graph  :with:  symptom graph  ::result:: 100\n",
      "comparing  symptom graph  :with:  global attention  ::result:: 15\n",
      "comparing  symptom graph  :with:  symptom graph  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Towards Automated Related Work Summarization. We introduce the novel problem of automatic related work summarization. Given multiple articles (e.g., conference/journal papers) as input, a related work summarization system creates a topic-biased summary of related work specific to the target paper. Our prototype Related Work Summarization system, ReWoS, takes in set of keywords arranged in a hierarchical fashion that describes a target paper's topics, to drive the creation of an extractive summary using two different strategies for locating appropriate sentences for general topics as well as detailed ones. Our initial results show an improvement over generic multi-document summarization baselines in a human evaluation.\n",
      "predicted task:  [{'words': ['summarization', 'automatic related work summarization', 'summarization', 'summarization'], 'value': 0.5889991671, 'top_word': 'summarization'}]\n",
      "predicted method:  [{'words': ['rewos'], 'value': 0, 'top_word': 'rewos'}, {'words': ['multi - document summarization baselines'], 'value': 0, 'top_word': 'multi - document summarization baselines'}]\n",
      "actual task:  ['automatic related work summarization']\n",
      "actual method:  ['summarization system']\n",
      "comparing  automatic related work summarization  :with:  summarization  ::result:: 100\n",
      "comparing  automatic related work summarization  :with:  automatic related work summarization  ::result:: 100\n",
      "comparing  automatic related work summarization  :with:  summarization  ::result:: 100\n",
      "comparing  automatic related work summarization  :with:  summarization  ::result:: 100\n",
      "comparing  summarization system  :with:  rewos  ::result:: 40\n",
      "comparing  summarization system  :with:  multi - document summarization baselines  ::result:: 80\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Automatic Extraction of Reasoning Chains from Textual Reports. Many organizations possess large collections of textual reports that document how a problem is solved or analysed, e.g. medical patient records, industrial accident reports, lawsuit records and investigation reports. Effective use of expert knowledge contained in these reports may greatly increase productivity of the organization. In this article, we propose a method for automatic extraction of reasoning chains that contain information used by the author of a report to analyse the problem at hand. For this purpose, we developed a graph-based text representation that makes the relations between textual units explicit. This representation is acquired automatically from a report using natural language processing tools including syntactic and discourse parsers. When applied to aviation investigation reports, our method generates reasoning chains that reveal the connection between initial information about the aircraft incident and its causes.\n",
      "predicted task:  [{'words': ['automatic extraction of reasoning chains'], 'value': 0, 'top_word': 'automatic extraction of reasoning chains'}, {'words': ['automatic extraction of reasoning chains'], 'value': 0, 'top_word': 'automatic extraction of reasoning chains'}, {'words': ['aviation investigation reports'], 'value': 0, 'top_word': 'aviation investigation reports'}]\n",
      "predicted method:  [{'words': ['graph - based text representation'], 'value': 0, 'top_word': 'graph - based text representation'}, {'words': ['natural language processing tools'], 'value': 0, 'top_word': 'natural language processing tools'}, {'words': ['syntactic and discourse parsers'], 'value': 0, 'top_word': 'syntactic and discourse parsers'}, {'words': ['reasoning chains'], 'value': 0, 'top_word': 'reasoning chains'}]\n",
      "actual task:  ['automatic extraction']\n",
      "actual method:  ['graph-based text representation', 'natural language processing tools', 'syntactic and discourse parsers']\n",
      "comparing  automatic extraction  :with:  automatic extraction of reasoning chains  ::result:: 100\n",
      "comparing  automatic extraction  :with:  automatic extraction of reasoning chains  ::result:: 100\n",
      "comparing  automatic extraction  :with:  aviation investigation reports  ::result:: 55\n",
      "comparing  graph-based text representation  :with:  graph - based text representation  ::result:: 94\n",
      "comparing  graph-based text representation  :with:  natural language processing tools  ::result:: 39\n",
      "comparing  graph-based text representation  :with:  syntactic and discourse parsers  ::result:: 33\n",
      "comparing  graph-based text representation  :with:  reasoning chains  ::result:: 44\n",
      "comparing  natural language processing tools  :with:  natural language processing tools  ::result:: 100\n",
      "comparing  natural language processing tools  :with:  syntactic and discourse parsers  ::result:: 42\n",
      "comparing  natural language processing tools  :with:  reasoning chains  ::result:: 50\n",
      "comparing  syntactic and discourse parsers  :with:  syntactic and discourse parsers  ::result:: 100\n",
      "comparing  syntactic and discourse parsers  :with:  reasoning chains  ::result:: 38\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Automatic Term Extraction from Knowledge Bank of Economics. KB-N is a web-accessible searchable Knowledge Bank comprising A) a parallel corpus of quality assured and calibrated English and Norwegian text drawn from economic-administrative knowledge domains, and B) a domain-focused database representing that knowledge universe in terms of defined concepts and their respective bilingual terminological entries. A central mechanism in connecting A and B is an algorithm for the automatic extraction of term candidates from aligned translation pairs on the basis of linguistic, lexical and statistical filtering (first ever for Norwegian). The system is designed and programmed by Paul Meurer at Aksis (UiB). An important pilot application of the term base is subdomain and collocations based word-sense disambiguation for LOGON, a system for Norwegian-to-English MT currently being developed.\n",
      "predicted task:  [{'words': ['norwegian to english mt'], 'value': 0.3539590836, 'top_word': 'norwegian to english mt'}, {'words': ['automatic term extraction', 'automatic extraction of term candidates'], 'value': 0.3088204339, 'top_word': 'automatic term extraction'}]\n",
      "predicted method:  [{'words': ['kb - n'], 'value': 0, 'top_word': 'kb - n'}, {'words': ['web - accessible searchable knowledge bank'], 'value': 0, 'top_word': 'web - accessible searchable knowledge bank'}, {'words': ['lexical and statistical filtering'], 'value': 0, 'top_word': 'lexical and statistical filtering'}, {'words': ['term base'], 'value': 0, 'top_word': 'term base'}]\n",
      "actual task:  ['automatic term extraction']\n",
      "actual method:  ['statistical filtering']\n",
      "comparing  automatic term extraction  :with:  norwegian to english mt  ::result:: 30\n",
      "comparing  automatic term extraction  :with:  automatic term extraction  ::result:: 100\n",
      "comparing  automatic term extraction  :with:  automatic extraction of term candidates  ::result:: 80\n",
      "comparing  statistical filtering  :with:  kb - n  ::result:: 17\n",
      "comparing  statistical filtering  :with:  web - accessible searchable knowledge bank  ::result:: 43\n",
      "comparing  statistical filtering  :with:  lexical and statistical filtering  ::result:: 100\n",
      "comparing  statistical filtering  :with:  term base  ::result:: 33\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Multi-task Peer-Review Score Prediction. Automatic prediction of the peer-review aspect scores of academic papers can be a useful assistant tool for both reviewers and authors. To handle the small size of published datasets on the target aspect of scores, we propose a multi-task approach to leverage additional information from other aspects of scores for improving the performance of the target aspect. Because one of the problems of building multi-task models is how to select the proper resources of auxiliary tasks and how to select the proper shared structures, we thus propose a multi-task shared structure encoding approach that automatically selects good shared network structures as well as good auxiliary resources. The experiments based on peer-review datasets show that our approach is effective and has better performance on the target scores than the single-task method and naïve multi-task methods.\n",
      "predicted task:  [{'words': ['multi task peer review score prediction', 'peer review aspect scores'], 'value': 0.29438569400000003, 'top_word': 'multi task peer review score prediction'}]\n",
      "predicted method:  [{'words': ['multi - task approach'], 'value': 0, 'top_word': 'multi - task approach'}, {'words': ['multi - task models'], 'value': 0, 'top_word': 'multi - task models'}, {'words': ['multi - task shared structure encoding approach'], 'value': 0, 'top_word': 'multi - task shared structure encoding approach'}, {'words': ['single - task method'], 'value': 0, 'top_word': 'single - task method'}, {'words': ['multi - task methods'], 'value': 0, 'top_word': 'multi - task methods'}]\n",
      "actual task:  ['peer-review score prediction']\n",
      "actual method:  ['multi-task shared structure encoding approach', 'peer-review datasets']\n",
      "comparing  peer-review score prediction  :with:  multi task peer review score prediction  ::result:: 96\n",
      "comparing  peer-review score prediction  :with:  peer review aspect scores  ::result:: 64\n",
      "comparing  multi-task shared structure encoding approach  :with:  multi - task approach  ::result:: 62\n",
      "comparing  multi-task shared structure encoding approach  :with:  multi - task models  ::result:: 68\n",
      "comparing  multi-task shared structure encoding approach  :with:  multi - task shared structure encoding approach  ::result:: 96\n",
      "comparing  multi-task shared structure encoding approach  :with:  single - task method  ::result:: 45\n",
      "comparing  multi-task shared structure encoding approach  :with:  multi - task methods  ::result:: 70\n",
      "comparing  peer-review datasets  :with:  multi - task approach  ::result:: 25\n",
      "comparing  peer-review datasets  :with:  multi - task models  ::result:: 37\n",
      "comparing  peer-review datasets  :with:  single - task method  ::result:: 40\n",
      "comparing  peer-review datasets  :with:  multi - task methods  ::result:: 41\n",
      "1.0\n",
      "0.5\n",
      "\n",
      "Development and Use of an Evaluation Collection for Personalisation of Digital Newspapers. This paper presents the process of development and the characteristics of an evaluation collection for a personalisation system for digital newspapers. This system selects, adapts and presents contents according to a user model that define information needs. The collection presented here contains data that are cross-related over four different axes: a set of news items from an electronic newspaper, collected into subsets corresponding to a particular sequence of days, packaged together and cross-indexed with a set of user profiles that represent the particular evolution of interests of a set of real users over the given days, expressed in each case according to four different representation frameworks: newspaper sections, Yahoo categories, keywords, and relevance feedback over the set of news items for the previous day. This information provides a minimum starting material over which one can evaluate for a given system how it addresses the first two observations-adapting to different users and adapting to particular users over time-providing that the particular system implements the representation of information needs according to the four frameworks employed in the collection. This collection has been successfully used to perform some different experiments to determine the effectiveness of the personalization system presented.\n",
      "predicted task:  [{'words': ['personalisation of digital newspapers'], 'value': 0, 'top_word': 'personalisation of digital newspapers'}, {'words': ['representation of information needs'], 'value': 0, 'top_word': 'representation of information needs'}]\n",
      "predicted method:  [{'words': ['personalisation system'], 'value': 0, 'top_word': 'personalisation system'}, {'words': ['user model'], 'value': 0, 'top_word': 'user model'}, {'words': ['representation frameworks'], 'value': 0, 'top_word': 'representation frameworks'}, {'words': ['personalization system'], 'value': 0, 'top_word': 'personalization system'}]\n",
      "actual task:  ['personalisation system']\n",
      "actual method:  ['evaluation collection']\n",
      "comparing  personalisation system  :with:  personalisation of digital newspapers  ::result:: 73\n",
      "comparing  personalisation system  :with:  representation of information needs  ::result:: 50\n",
      "comparing  evaluation collection  :with:  personalisation system  ::result:: 48\n",
      "comparing  evaluation collection  :with:  user model  ::result:: 40\n",
      "comparing  evaluation collection  :with:  representation frameworks  ::result:: 43\n",
      "comparing  evaluation collection  :with:  personalization system  ::result:: 48\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension. In this work, we introduce a novel algorithm for solving the textbook question answering (TQA) task which describes more realistic QA problems compared to other recent tasks. We mainly focus on two related issues with analysis of the TQA dataset. First, solving the TQA problems requires to comprehend multimodal contexts in complicated input data. To tackle this issue of extracting knowledge features from long text lessons and merging them with visual features, we establish a context graph from texts and images, and propose a new module f-GCN based on graph convolutional networks (GCN). Second, scientific terms are not spread over the chapters and subjects are split in the TQA dataset. To overcome this so called 'out-of-domain' issue, before learning QA problems, we introduce a novel self-supervised open-set learning process without any annotations. The experimental results show that our model significantly outperforms prior state-of-the-art methods. Moreover, ablation studies validate that both methods of incorporating f-GCN for extracting knowledge from multi-modal contexts and our newly proposed self-supervised learning process are effective for TQA problems.\n",
      "predicted task:  [{'words': ['textbook question answering', 'textbook question answering', 'qa problems', 'learning qa problems'], 'value': 0.5479186177, 'top_word': 'textbook question answering'}, {'words': ['tqa problems', 'tqa problems'], 'value': 0.3707527369, 'top_word': 'tqa problems'}]\n",
      "predicted method:  [{'words': ['module f gcn', 'f gcn'], 'value': 0.45613715050000003, 'top_word': 'module f gcn'}]\n",
      "actual task:  ['textbook question answering']\n",
      "actual method:  ['multi-modal context graph understanding', 'self-supervised open-set comprehension', 'graph convolutional networks (gcn)']\n",
      "comparing  textbook question answering  :with:  textbook question answering  ::result:: 100\n",
      "comparing  textbook question answering  :with:  textbook question answering  ::result:: 100\n",
      "comparing  textbook question answering  :with:  qa problems  ::result:: 27\n",
      "comparing  textbook question answering  :with:  learning qa problems  ::result:: 30\n",
      "comparing  textbook question answering  :with:  tqa problems  ::result:: 25\n",
      "comparing  textbook question answering  :with:  tqa problems  ::result:: 25\n",
      "comparing  multi-modal context graph understanding  :with:  module f gcn  ::result:: 58\n",
      "comparing  multi-modal context graph understanding  :with:  f gcn  ::result:: 40\n",
      "comparing  self-supervised open-set comprehension  :with:  module f gcn  ::result:: 33\n",
      "comparing  self-supervised open-set comprehension  :with:  f gcn  ::result:: 40\n",
      "comparing  graph convolutional networks (gcn)  :with:  module f gcn  ::result:: 42\n",
      "comparing  graph convolutional networks (gcn)  :with:  f gcn  ::result:: 80\n",
      "1.0\n",
      "0.3333333333333333\n",
      "\n",
      "Modeling Intensification for Sign Language Generation: A Computational Approach. End-to-end sign language generation models do not accurately represent the prosody in sign language. A lack of temporal and spatial variations leads to poor-quality generated presentations that confuse human interpreters. In this paper, we aim to improve the prosody in generated sign languages by modeling intensification in a data-driven manner. We present different strategies grounded in linguistics of sign language that inform how intensity modifiers can be represented in gloss annotations. To employ our strategies, we first annotate a subset of the benchmark PHOENIX-14T, a German Sign Language dataset, with different levels of intensification. We then use a supervised intensity tagger to extend the annotated dataset and obtain labels for the remaining portion of it. This enhanced dataset is then used to train state-of-the-art transformer models for sign language generation. We find that our efforts in intensification modeling yield better results when evaluated with automatic metrics. Human evaluation also indicates a higher preference of the videos generated using our model.\n",
      "predicted task:  [{'words': ['sign language generation', 'sign language generation'], 'value': 0.4236453921, 'top_word': 'sign language generation'}]\n",
      "predicted method:  [{'words': ['computational approach'], 'value': 0, 'top_word': 'computational approach'}, {'words': ['sign language generation models'], 'value': 0, 'top_word': 'sign language generation models'}, {'words': ['data - driven manner'], 'value': 0, 'top_word': 'data - driven manner'}, {'words': ['supervised intensity tagger'], 'value': 0, 'top_word': 'supervised intensity tagger'}, {'words': ['transformer models'], 'value': 0, 'top_word': 'transformer models'}]\n",
      "actual task:  ['sign language generation']\n",
      "actual method:  ['supervised intensity tagger', 'transformer']\n",
      "comparing  sign language generation  :with:  sign language generation  ::result:: 100\n",
      "comparing  sign language generation  :with:  sign language generation  ::result:: 100\n",
      "comparing  supervised intensity tagger  :with:  computational approach  ::result:: 23\n",
      "comparing  supervised intensity tagger  :with:  sign language generation models  ::result:: 33\n",
      "comparing  supervised intensity tagger  :with:  data - driven manner  ::result:: 45\n",
      "comparing  supervised intensity tagger  :with:  supervised intensity tagger  ::result:: 100\n",
      "comparing  supervised intensity tagger  :with:  transformer models  ::result:: 33\n",
      "comparing  transformer  :with:  computational approach  ::result:: 27\n",
      "comparing  transformer  :with:  sign language generation models  ::result:: 36\n",
      "comparing  transformer  :with:  data - driven manner  ::result:: 36\n",
      "comparing  transformer  :with:  transformer models  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "Extraction and Exploration of Correlations in Patient Status Data. The paper discusses an Information Extraction approach, which is applied for the automatic processing of hospital Patient Records (PRs) in Bulgarian language. The main task reported here is retrieval of status descriptions related to anatomical organs. Due to the specific telegraphic PR style, the approach is focused on shallow analysis. Missing text descriptions and default values are another obstacle. To overcome it, we propose an algorithm for exploring the correlations between patient status data and the corresponding diagnosis. Rules for interdependencies of the patient status data are generated by clustering according to chosen metrics. In this way it becomes possible to fill in status templates for each patient when explicit descriptions are unavailable in the text. The article summarises evaluation results which concern the performance of the current IE prototype.\n",
      "predicted task:  [{'words': ['extraction and exploration of correlations'], 'value': 0, 'top_word': 'extraction and exploration of correlations'}, {'words': ['automatic processing of hospital patient records'], 'value': 0, 'top_word': 'automatic processing of hospital patient records'}, {'words': ['retrieval of status descriptions'], 'value': 0, 'top_word': 'retrieval of status descriptions'}, {'words': ['shallow analysis'], 'value': 0, 'top_word': 'shallow analysis'}]\n",
      "predicted method:  [{'words': ['information extraction approach', 'ie'], 'value': 0.1501079081, 'top_word': 'ie'}]\n",
      "actual task:  ['information extraction']\n",
      "actual method:  ['algorithm for exploring the correlations']\n",
      "comparing  information extraction  :with:  extraction and exploration of correlations  ::result:: 64\n",
      "comparing  information extraction  :with:  automatic processing of hospital patient records  ::result:: 45\n",
      "comparing  information extraction  :with:  retrieval of status descriptions  ::result:: 45\n",
      "comparing  information extraction  :with:  shallow analysis  ::result:: 31\n",
      "comparing  algorithm for exploring the correlations  :with:  information extraction approach  ::result:: 42\n",
      "comparing  algorithm for exploring the correlations  :with:  ie  ::result:: 50\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "Assessing Gender Bias in Wikipedia: Inequalities in Article Titles. Potential gender biases existing in Wikipedia's content can contribute to biased behaviors in a variety of downstream NLP systems. Yet, efforts in understanding what inequalities in portraying women and men occur in Wikipedia focused so far only on biographies, leaving open the question of how often such harmful patterns occur in other topics. In this paper, we investigate gender-related asymmetries in Wikipedia titles from all domains. We assess that for only half of gender-related articles, i.e., articles with words such as women or male in their titles, symmetrical counterparts describing the same concept for the other gender (and clearly stating it in their titles) exist. Among the remaining imbalanced cases, the vast majority of articles concern sports-and social-related issues. We provide insights on how such asymmetries can influence other Wikipedia components and propose steps towards reducing the frequency of observed patterns.\n",
      "predicted task:  [{'words': ['assessing gender bias'], 'value': 0, 'top_word': 'assessing gender bias'}, {'words': ['nlp'], 'value': 0, 'top_word': 'nlp'}]\n",
      "predicted method:  [{'words': ['data collection'], 'value': 0, 'top_word': 'data collection'}, {'words': ['data analysis'], 'value': 0, 'top_word': 'data analysis'}, {'words': ['natural language processing'], 'value': 0, 'top_word': 'natural language processing'}]\n",
      "actual task:  ['gender bias detection']\n",
      "actual method:  ['analysis']\n",
      "comparing  gender bias detection  :with:  assessing gender bias  ::result:: 52\n",
      "comparing  gender bias detection  :with:  nlp  ::result:: 33\n",
      "comparing  analysis  :with:  data collection  ::result:: 38\n",
      "comparing  analysis  :with:  data analysis  ::result:: 100\n",
      "comparing  analysis  :with:  natural language processing  ::result:: 38\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "Identifying Nuances in Fake News vs. Satire: Using Semantic and Linguistic Cues. The blurry line between nefarious fake news and protected-speech satire has been a notorious struggle for social media platforms. Further to the efforts of reducing exposure to misinformation on social media, purveyors of fake news have begun to masquerade as satire sites to avoid being demoted. In this work, we address the challenge of automatically classifying fake news versus satire. Previous work have studied whether fake news and satire can be distinguished based on language differences. Contrary to fake news, satire stories are usually humorous and carry some political or social message. We hypothesize that these nuances could be identified using semantic and linguistic cues. Consequently, we train a machine learning method using semantic representation, with a state-of-the-art contextual language model, and with linguistic features based on textual coherence metrics. Empirical evaluation attests to the merits of our approach compared to the language-based baseline and sheds light on the nuances between fake news and satire. As avenues for future work, we consider studying additional linguistic features related to the humor aspect, and enriching the data with current news events, to help identify a political or social message.\n",
      "predicted task:  [{'words': ['identifying nuances'], 'value': 0, 'top_word': 'identifying nuances'}, {'words': ['automatically classifying fake news'], 'value': 0, 'top_word': 'automatically classifying fake news'}, {'words': ['satire'], 'value': 0, 'top_word': 'satire'}]\n",
      "predicted method:  [{'words': ['machine learning method'], 'value': 0, 'top_word': 'machine learning method'}, {'words': ['semantic representation'], 'value': 0, 'top_word': 'semantic representation'}, {'words': ['contextual language model'], 'value': 0, 'top_word': 'contextual language model'}, {'words': ['language - based baseline'], 'value': 0, 'top_word': 'language - based baseline'}]\n",
      "actual task:  ['identifying nuances in fake news']\n",
      "actual method:  ['semantic representation', 'contextual language model', 'linguistic feature']\n",
      "comparing  identifying nuances in fake news  :with:  identifying nuances  ::result:: 100\n",
      "comparing  identifying nuances in fake news  :with:  automatically classifying fake news  ::result:: 56\n",
      "comparing  identifying nuances in fake news  :with:  satire  ::result:: 33\n",
      "comparing  semantic representation  :with:  machine learning method  ::result:: 39\n",
      "comparing  semantic representation  :with:  semantic representation  ::result:: 100\n",
      "comparing  semantic representation  :with:  contextual language model  ::result:: 26\n",
      "comparing  semantic representation  :with:  language - based baseline  ::result:: 30\n",
      "comparing  contextual language model  :with:  machine learning method  ::result:: 52\n",
      "comparing  contextual language model  :with:  contextual language model  ::result:: 100\n",
      "comparing  contextual language model  :with:  language - based baseline  ::result:: 48\n",
      "comparing  linguistic feature  :with:  machine learning method  ::result:: 40\n",
      "comparing  linguistic feature  :with:  language - based baseline  ::result:: 39\n",
      "1.0\n",
      "0.6666666666666666\n",
      "\n",
      "Exploiting multiple resources for Japanese to English patent translation. This paper describes the development of a Japanese to English translation system using multiple resources and NTCIR-10 Patent translation collection. The MT system is based on different training data, the Wiktionary as a bilingual dictionary and Moses decoder. Due to the lack of parallel data on the patent domain, additional training data of the general domain was extracted from Wikipedia. Experiments using NTCIR-10 Patent translation data collection showed an improvement of the BLEU score when using a 5-grams language model and when adding the data extracted from Wikipedia but no improvement when adding the Wiktionary.\n",
      "predicted task:  [{'words': ['japanese to english patent translation', 'japanese to english translation system'], 'value': 0.48515015840000003, 'top_word': 'japanese to english patent translation'}, {'words': ['mt'], 'value': 0.5951254964, 'top_word': 'mt'}]\n",
      "predicted method:  [{'words': ['moses decoder'], 'value': 0, 'top_word': 'moses decoder'}, {'words': ['5 - grams language model'], 'value': 0, 'top_word': '5 - grams language model'}]\n",
      "actual task:  ['patent translation']\n",
      "actual method:  ['mt system', 'data collection']\n",
      "comparing  patent translation  :with:  japanese to english patent translation  ::result:: 100\n",
      "comparing  patent translation  :with:  japanese to english translation system  ::result:: 72\n",
      "comparing  patent translation  :with:  mt  ::result:: 50\n",
      "comparing  mt system  :with:  moses decoder  ::result:: 44\n",
      "comparing  mt system  :with:  5 - grams language model  ::result:: 22\n",
      "comparing  data collection  :with:  moses decoder  ::result:: 31\n",
      "comparing  data collection  :with:  5 - grams language model  ::result:: 33\n",
      "1.0\n",
      "0.0\n",
      "\n",
      "Detecting dementia in Mandarin Chinese using transfer learning from a parallel corpus. Machine learning has shown promise for automatic detection of Alzheimer's disease (AD) through speech; however, efforts are hampered by a scarcity of data, especially in languages other than English. We propose a method to learn a correspondence between independently engineered lexicosyntactic features in two languages, using a large parallel corpus of outof-domain movie dialogue data. We apply it to dementia detection in Mandarin Chinese, and demonstrate that our method outperforms both unilingual and machine translation-based baselines. This appears to be the first study that transfers feature domains in detecting cognitive decline.\n",
      "predicted task:  [{'words': ['detecting dementia', 'automatic detection of alzheimers disease', 'dementia detection'], 'value': 0.29908896490000003, 'top_word': 'detecting dementia'}]\n",
      "predicted method:  [{'words': ['transfer learning'], 'value': 0.27751755710000003, 'top_word': 'transfer learning'}]\n",
      "actual task:  ['dementia detection']\n",
      "actual method:  ['transfer learning']\n",
      "comparing  dementia detection  :with:  detecting dementia  ::result:: 61\n",
      "comparing  dementia detection  :with:  automatic detection of alzheimers disease  ::result:: 72\n",
      "comparing  dementia detection  :with:  dementia detection  ::result:: 100\n",
      "comparing  transfer learning  :with:  transfer learning  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "An Analysis of Verbs in Financial News Articles and their Impact on Stock Price. Article terms can move stock prices. By analyzing verbs in financial news articles and coupling their usage with a discrete machine learning algorithm tied to stock price movement, we can build a model of price movement based upon the verbs used, to not only identify those terms that can move a stock price the most, but also whether they move the predicted price up or down.\n",
      "predicted task:  [{'words': ['stock price movement'], 'value': 0, 'top_word': 'stock price movement'}, {'words': ['price movement'], 'value': 0, 'top_word': 'price movement'}]\n",
      "predicted method:  [{'words': ['discrete machine learning algorithm'], 'value': 0, 'top_word': 'discrete machine learning algorithm'}]\n",
      "actual task:  ['analysis of verbs']\n",
      "actual method:  ['discrete machine learning algorithm']\n",
      "comparing  analysis of verbs  :with:  stock price movement  ::result:: 29\n",
      "comparing  analysis of verbs  :with:  price movement  ::result:: 37\n",
      "comparing  discrete machine learning algorithm  :with:  discrete machine learning algorithm  ::result:: 100\n",
      "0.0\n",
      "1.0\n",
      "\n",
      "The Modulation of Cooperation and Emotion in Dialogue: The REC Corpus. In this paper we describe the Rovereto Emotive Corpus (REC) which we collected to investigate the relationship between emotion and cooperation in dialogue tasks. It is an area where still many unsolved questions are present. One of the main open issues is the annotation of the socalled \"blended\" emotions and their recognition. Usually, there is a low agreement among raters in annotating emotions and, surprisingly, emotion recognition is higher in a condition of modality deprivation (i. e. only acoustic or only visual modality vs. bimodal display of emotion). Because of these previous results, we collected a corpus in which \"emotive\" tokens are pointed out during the recordings by psychophysiological indexes (ElectroCardioGram, and Galvanic Skin Conductance). From the output values of these indexes a general recognition of each emotion arousal is allowed. After this selection we will annotate emotive interactions with our multimodal annotation scheme, performing a kappa statistic on annotation results to validate our coding scheme. In the near future, a logistic regression on annotated data will be performed to find out correlations between cooperation and negative emotions. A final step will be an fMRI experiment on emotion recognition of blended emotions from face displays.\n",
      "predicted task:  [{'words': ['modulation of cooperation and emotion in dialogue', 'cooperation'], 'value': 0.17548814140000002, 'top_word': 'cooperation'}]\n",
      "predicted method:  [{'words': ['multimodal annotation scheme'], 'value': 0, 'top_word': 'multimodal annotation scheme'}, {'words': ['coding scheme'], 'value': 0, 'top_word': 'coding scheme'}, {'words': ['logistic regression'], 'value': 0, 'top_word': 'logistic regression'}]\n",
      "actual task:  ['emotion in dialogue']\n",
      "actual method:  ['emotive corpus', 'kappa statistic', 'coding scheme']\n",
      "comparing  emotion in dialogue  :with:  modulation of cooperation and emotion in dialogue  ::result:: 100\n",
      "comparing  emotion in dialogue  :with:  cooperation  ::result:: 45\n",
      "comparing  emotive corpus  :with:  multimodal annotation scheme  ::result:: 36\n",
      "comparing  emotive corpus  :with:  coding scheme  ::result:: 31\n",
      "comparing  emotive corpus  :with:  logistic regression  ::result:: 43\n",
      "comparing  kappa statistic  :with:  multimodal annotation scheme  ::result:: 47\n",
      "comparing  kappa statistic  :with:  coding scheme  ::result:: 23\n",
      "comparing  kappa statistic  :with:  logistic regression  ::result:: 33\n",
      "comparing  coding scheme  :with:  multimodal annotation scheme  ::result:: 69\n",
      "comparing  coding scheme  :with:  coding scheme  ::result:: 100\n",
      "comparing  coding scheme  :with:  logistic regression  ::result:: 38\n",
      "1.0\n",
      "0.3333333333333333\n",
      "\n",
      "IDIAP\\_TIET@LT-EDI-ACL2022 : Hope Speech Detection in Social Media using Contextualized BERT with Attention Mechanism. With the increase of users on social media platforms, manipulating or provoking masses of people has become a piece of cake. This spread of hatred among people, which has become a loophole for freedom of speech, must be minimized. Hence, it is essential to have a system that automatically classifies the hatred content, especially on social media, to take it down. This paper presents a simple modular pipeline classifier with BERT embeddings and attention mechanism to classify hope speech content in the Hope Speech Detection shared task for Equality, Diversity, and Inclusion-ACL 2022. Our system submission ranks fourth with an F1-score of 0.84. We release our code-base here https: //github.com/Deepanshu-beep/ hope-speech-attention.\n",
      "predicted task:  [{'words': ['hope speech detection', 'hope speech detection shared task'], 'value': 0.5462485552, 'top_word': 'hope speech detection'}]\n",
      "predicted method:  [{'words': ['attention mechanism', 'attention mechanism'], 'value': 0.38918802140000003, 'top_word': 'attention mechanism'}, {'words': ['bert'], 'value': 0.3831139803, 'top_word': 'bert'}]\n",
      "actual task:  ['hope speech detection']\n",
      "actual method:  ['bert embeddings', 'attention mechanism']\n",
      "comparing  hope speech detection  :with:  hope speech detection  ::result:: 100\n",
      "comparing  hope speech detection  :with:  hope speech detection shared task  ::result:: 100\n",
      "comparing  bert embeddings  :with:  attention mechanism  ::result:: 47\n",
      "comparing  bert embeddings  :with:  attention mechanism  ::result:: 47\n",
      "comparing  bert embeddings  :with:  bert  ::result:: 100\n",
      "comparing  attention mechanism  :with:  attention mechanism  ::result:: 100\n",
      "comparing  attention mechanism  :with:  attention mechanism  ::result:: 100\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "A Case Study of Sockpuppet Detection in Wikipedia. This paper presents preliminary results of using authorship attribution methods for the detection of sockpuppeteering in Wikipedia. Sockpuppets are fake accounts created by malicious users to bypass Wikipedia's regulations. Our dataset is composed of the comments made by the editors on the talk pages. To overcome the limitations of the short lengths of these comments, we use an voting scheme to combine predictions made on individual user entries. We show that this approach is promising and that it can be a viable alternative to the current human process that Wikipedia uses to resolve suspected sockpuppet cases.\n",
      "predicted task:  [{'words': ['sockpuppet detection', 'detection of sockpuppeteering', 'sockpuppet cases'], 'value': 0.4393684566, 'top_word': 'sockpuppet detection'}]\n",
      "predicted method:  [{'words': ['authorship attribution methods'], 'value': 0, 'top_word': 'authorship attribution methods'}, {'words': ['sockpuppets'], 'value': 0, 'top_word': 'sockpuppets'}, {'words': ['voting scheme'], 'value': 0, 'top_word': 'voting scheme'}, {'words': ['human process'], 'value': 0, 'top_word': 'human process'}]\n",
      "actual task:  ['detection of sockpuppeteering']\n",
      "actual method:  ['authorship attribution', 'voting scheme']\n",
      "comparing  detection of sockpuppeteering  :with:  sockpuppet detection  ::result:: 78\n",
      "comparing  detection of sockpuppeteering  :with:  detection of sockpuppeteering  ::result:: 100\n",
      "comparing  detection of sockpuppeteering  :with:  sockpuppet cases  ::result:: 69\n",
      "comparing  authorship attribution  :with:  authorship attribution methods  ::result:: 100\n",
      "comparing  authorship attribution  :with:  sockpuppets  ::result:: 27\n",
      "comparing  authorship attribution  :with:  voting scheme  ::result:: 23\n",
      "comparing  authorship attribution  :with:  human process  ::result:: 23\n",
      "comparing  voting scheme  :with:  sockpuppets  ::result:: 27\n",
      "comparing  voting scheme  :with:  voting scheme  ::result:: 100\n",
      "comparing  voting scheme  :with:  human process  ::result:: 31\n",
      "1.0\n",
      "1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,d in test_set.iterrows():\n",
    "    print(d['text'])\n",
    "    predicted_sci=d['task_scirex'][:]\n",
    "    predicted_sci_m=d['method_scirex'][:]\n",
    "    actual=d['task_annotation']\n",
    "    actual = [x for x in actual if str(x) != 'nan']\n",
    "\n",
    "    \n",
    "    actual_m=d['method_annotation']\n",
    "    actual_m = [x for x in actual_m if str(x) != 'nan']\n",
    "    print(\"predicted task: \",predicted_sci)\n",
    "    print(\"predicted method: \",predicted_sci_m)\n",
    "    #print(ratio_m)\n",
    "    \n",
    "    print(\"actual task: \",actual)\n",
    "    print(\"actual method: \",actual_m)\n",
    "       \n",
    "    f1,precision,recall,golden,match_g,match_p,unmatch,match_group=get_metrics_colors(actual, predicted_sci)\n",
    "    test_set.loc[i,'task_sci_f1']=f1\n",
    "    test_set.loc[i,'task_sci_precision']=precision\n",
    "    test_set.loc[i,'task_sci_recall']=recall\n",
    "    test_set.at[i,'task_unmatch_golden']=list(golden)\n",
    "    test_set.at[i,'task_match_golden']=list(match_g)\n",
    "    test_set.at[i,'task_match_predicted']=list(match_p)\n",
    "    test_set.at[i,'task_unmatch_pred']=list(unmatch)\n",
    "    test_set.at[i,'task_match_group']=list(match_group)\n",
    "    test_set.at[i,'task_match_total']=list(set(match_g).union(set(match_p)))\n",
    "\n",
    "    \n",
    "    \n",
    "    f1,precision,recall,golden,match_g,match_p,unmatch,match_group=get_metrics_colors(actual_m, predicted_sci_m)\n",
    "    test_set.loc[i,'method_sci_f1']=f1\n",
    "    test_set.loc[i,'method_sci_precision']=precision\n",
    "    test_set.loc[i,'method_sci_recall']=recall\n",
    "    test_set.at[i,'method_unmatch_golden']=list(golden)\n",
    "    test_set.at[i,'method_match_golden']=list(match_g)\n",
    "    test_set.at[i,'method_match_predicted']=list(match_p)\n",
    "    test_set.at[i,'method_unmatch_pred']=list(unmatch)\n",
    "    test_set.at[i,'method_match_group']=list(match_group)\n",
    "    test_set.at[i,'method_match_total']=list(set(match_g).union(set(match_p)))\n",
    "\n",
    "    #print(predicted_sci)\n",
    "    #print(test_set.loc[i,'task_sci_f1'])\n",
    "    #print(test_set.loc[i,'task_sci_precision'])\n",
    "    print(test_set.loc[i,'task_sci_recall'])\n",
    "    print(test_set.loc[i,'method_sci_recall'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc5de1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>soh-etal-2019-legal</td>\n",
       "      <td>[{'words': ['legal area classification', 'clas...</td>\n",
       "      <td>[{'words': ['text classifiers'], 'value': 0, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                                        task_scirex  \\\n",
       "24  soh-etal-2019-legal  [{'words': ['legal area classification', 'clas...   \n",
       "\n",
       "                                        method_scirex  \n",
       "24  [{'words': ['text classifiers'], 'value': 0, '...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.loc[test_set.ID=='soh-etal-2019-legal']\n",
    "df_labels_scirex.loc[df_labels_scirex.ID=='soh-etal-2019-legal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db1f58f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set.method_sci_recall.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57f8f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "just100=test_set.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0189f02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.21"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(just100.task_annotation.apply(lambda x:len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34489f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.69"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(just100.method_annotation.apply(lambda x:len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7151d0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.91"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(just100.task_scirex.apply(lambda x:len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7216139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.82"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(just100.method_scirex.apply(lambda x:len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "574702e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(just100.task_annotation.explode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fd0f64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(just100.method_annotation.explode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d54bb1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.21*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce78db8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.69*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f88dfd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_sci_ratio</th>\n",
       "      <th>method_sci_ratio</th>\n",
       "      <th>correct_ratio_sci_task</th>\n",
       "      <th>correct_ratio_sci_method</th>\n",
       "      <th>task_sci_f1</th>\n",
       "      <th>task_sci_precision</th>\n",
       "      <th>task_sci_recall</th>\n",
       "      <th>method_sci_f1</th>\n",
       "      <th>method_sci_precision</th>\n",
       "      <th>method_sci_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8806.80</td>\n",
       "      <td>7953.40</td>\n",
       "      <td>76.70</td>\n",
       "      <td>66.02</td>\n",
       "      <td>53.08</td>\n",
       "      <td>50.26</td>\n",
       "      <td>71.84</td>\n",
       "      <td>38.50</td>\n",
       "      <td>34.60</td>\n",
       "      <td>55.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2141.53</td>\n",
       "      <td>2749.61</td>\n",
       "      <td>42.48</td>\n",
       "      <td>47.60</td>\n",
       "      <td>38.08</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.84</td>\n",
       "      <td>33.14</td>\n",
       "      <td>34.74</td>\n",
       "      <td>44.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2400.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8750.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.50</td>\n",
       "      <td>12.70</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_sci_ratio  method_sci_ratio  correct_ratio_sci_task  \\\n",
       "count        10300.00          10300.00                10300.00   \n",
       "mean          8806.80           7953.40                   76.70   \n",
       "std           2141.53           2749.61                   42.48   \n",
       "min           2400.00              0.00                    0.00   \n",
       "25%           8750.00           5000.00                  100.00   \n",
       "50%          10000.00          10000.00                  100.00   \n",
       "75%          10000.00          10000.00                  100.00   \n",
       "max          10000.00          10000.00                  100.00   \n",
       "\n",
       "       correct_ratio_sci_method  task_sci_f1  task_sci_precision  \\\n",
       "count                  10300.00     10300.00            10300.00   \n",
       "mean                      66.02        53.08               50.26   \n",
       "std                       47.60        38.08               41.33   \n",
       "min                        0.00         0.00                0.00   \n",
       "25%                        0.00        22.50               12.70   \n",
       "50%                      100.00        50.00               50.00   \n",
       "75%                      100.00       100.00              100.00   \n",
       "max                      100.00       100.00              100.00   \n",
       "\n",
       "       task_sci_recall  method_sci_f1  method_sci_precision  method_sci_recall  \n",
       "count         10300.00       10300.00              10300.00           10300.00  \n",
       "mean             71.84          38.50                 34.60              55.44  \n",
       "std              42.84          33.14                 34.74              44.42  \n",
       "min               0.00           0.00                  0.00               0.00  \n",
       "25%              33.33           0.00                  0.00               0.00  \n",
       "50%             100.00          40.00                 33.33              50.00  \n",
       "75%             100.00          66.67                 50.00             100.00  \n",
       "max             100.00         100.00                100.00             100.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corefsalient  gpt3\n",
    "(test_set.describe()*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f46ec05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_sci_ratio</th>\n",
       "      <th>method_sci_ratio</th>\n",
       "      <th>correct_ratio_sci_task</th>\n",
       "      <th>correct_ratio_sci_method</th>\n",
       "      <th>task_sci_f1</th>\n",
       "      <th>task_sci_precision</th>\n",
       "      <th>task_sci_recall</th>\n",
       "      <th>method_sci_f1</th>\n",
       "      <th>method_sci_precision</th>\n",
       "      <th>method_sci_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8806.80</td>\n",
       "      <td>7953.40</td>\n",
       "      <td>76.70</td>\n",
       "      <td>66.02</td>\n",
       "      <td>53.08</td>\n",
       "      <td>50.26</td>\n",
       "      <td>71.84</td>\n",
       "      <td>38.22</td>\n",
       "      <td>34.36</td>\n",
       "      <td>55.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2141.53</td>\n",
       "      <td>2749.61</td>\n",
       "      <td>42.48</td>\n",
       "      <td>47.60</td>\n",
       "      <td>38.08</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.84</td>\n",
       "      <td>33.10</td>\n",
       "      <td>34.72</td>\n",
       "      <td>44.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2400.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8750.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.50</td>\n",
       "      <td>12.70</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_sci_ratio  method_sci_ratio  correct_ratio_sci_task  \\\n",
       "count        10300.00          10300.00                10300.00   \n",
       "mean          8806.80           7953.40                   76.70   \n",
       "std           2141.53           2749.61                   42.48   \n",
       "min           2400.00              0.00                    0.00   \n",
       "25%           8750.00           5000.00                  100.00   \n",
       "50%          10000.00          10000.00                  100.00   \n",
       "75%          10000.00          10000.00                  100.00   \n",
       "max          10000.00          10000.00                  100.00   \n",
       "\n",
       "       correct_ratio_sci_method  task_sci_f1  task_sci_precision  \\\n",
       "count                  10300.00     10300.00            10300.00   \n",
       "mean                      66.02        53.08               50.26   \n",
       "std                       47.60        38.08               41.33   \n",
       "min                        0.00         0.00                0.00   \n",
       "25%                        0.00        22.50               12.70   \n",
       "50%                      100.00        50.00               50.00   \n",
       "75%                      100.00       100.00              100.00   \n",
       "max                      100.00       100.00              100.00   \n",
       "\n",
       "       task_sci_recall  method_sci_f1  method_sci_precision  method_sci_recall  \n",
       "count         10300.00       10300.00              10300.00           10300.00  \n",
       "mean             71.84          38.22                 34.36              55.11  \n",
       "std              42.84          33.10                 34.72              44.45  \n",
       "min               0.00           0.00                  0.00               0.00  \n",
       "25%              33.33           0.00                  0.00               0.00  \n",
       "50%             100.00          40.00                 33.33              50.00  \n",
       "75%             100.00          66.67                 50.00             100.00  \n",
       "max             100.00         100.00                100.00             100.00  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corefsalient  gpt3\n",
    "(test_set.describe()*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1143e9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_sci_ratio</th>\n",
       "      <th>method_sci_ratio</th>\n",
       "      <th>correct_ratio_sci_task</th>\n",
       "      <th>correct_ratio_sci_method</th>\n",
       "      <th>task_sci_f1</th>\n",
       "      <th>task_sci_precision</th>\n",
       "      <th>task_sci_recall</th>\n",
       "      <th>method_sci_f1</th>\n",
       "      <th>method_sci_precision</th>\n",
       "      <th>method_sci_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8727.18</td>\n",
       "      <td>7395.15</td>\n",
       "      <td>76.70</td>\n",
       "      <td>62.14</td>\n",
       "      <td>53.08</td>\n",
       "      <td>50.26</td>\n",
       "      <td>71.84</td>\n",
       "      <td>36.56</td>\n",
       "      <td>33.30</td>\n",
       "      <td>51.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2380.32</td>\n",
       "      <td>3443.36</td>\n",
       "      <td>42.48</td>\n",
       "      <td>48.74</td>\n",
       "      <td>38.08</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.84</td>\n",
       "      <td>33.87</td>\n",
       "      <td>35.39</td>\n",
       "      <td>44.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8750.00</td>\n",
       "      <td>4400.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.50</td>\n",
       "      <td>12.70</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>9700.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_sci_ratio  method_sci_ratio  correct_ratio_sci_task  \\\n",
       "count        10300.00          10300.00                10300.00   \n",
       "mean          8727.18           7395.15                   76.70   \n",
       "std           2380.32           3443.36                   42.48   \n",
       "min              0.00              0.00                    0.00   \n",
       "25%           8750.00           4400.00                  100.00   \n",
       "50%          10000.00           9700.00                  100.00   \n",
       "75%          10000.00          10000.00                  100.00   \n",
       "max          10000.00          10000.00                  100.00   \n",
       "\n",
       "       correct_ratio_sci_method  task_sci_f1  task_sci_precision  \\\n",
       "count                  10300.00     10300.00            10300.00   \n",
       "mean                      62.14        53.08               50.26   \n",
       "std                       48.74        38.08               41.33   \n",
       "min                        0.00         0.00                0.00   \n",
       "25%                        0.00        22.50               12.70   \n",
       "50%                      100.00        50.00               50.00   \n",
       "75%                      100.00       100.00              100.00   \n",
       "max                      100.00       100.00              100.00   \n",
       "\n",
       "       task_sci_recall  method_sci_f1  method_sci_precision  method_sci_recall  \n",
       "count         10300.00       10300.00              10300.00           10300.00  \n",
       "mean             71.84          36.56                 33.30              51.55  \n",
       "std              42.84          33.87                 35.39              44.72  \n",
       "min               0.00           0.00                  0.00               0.00  \n",
       "25%              33.33           0.00                  0.00               0.00  \n",
       "50%             100.00          40.00                 25.00              50.00  \n",
       "75%             100.00          66.67                 50.00             100.00  \n",
       "max             100.00         100.00                100.00             100.00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coref salient\n",
    "(test_set.describe()*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76bdadb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_sci_ratio</th>\n",
       "      <th>method_sci_ratio</th>\n",
       "      <th>correct_ratio_sci_task</th>\n",
       "      <th>correct_ratio_sci_method</th>\n",
       "      <th>task_sci_f1</th>\n",
       "      <th>task_sci_precision</th>\n",
       "      <th>task_sci_recall</th>\n",
       "      <th>method_sci_f1</th>\n",
       "      <th>method_sci_precision</th>\n",
       "      <th>method_sci_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9177.67</td>\n",
       "      <td>8331.07</td>\n",
       "      <td>84.47</td>\n",
       "      <td>71.84</td>\n",
       "      <td>52.88</td>\n",
       "      <td>44.19</td>\n",
       "      <td>81.23</td>\n",
       "      <td>44.08</td>\n",
       "      <td>40.71</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1837.78</td>\n",
       "      <td>2548.09</td>\n",
       "      <td>36.40</td>\n",
       "      <td>45.20</td>\n",
       "      <td>31.69</td>\n",
       "      <td>33.13</td>\n",
       "      <td>37.17</td>\n",
       "      <td>31.76</td>\n",
       "      <td>33.90</td>\n",
       "      <td>42.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3300.00</td>\n",
       "      <td>2900.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>6450.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>58.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_sci_ratio  method_sci_ratio  correct_ratio_sci_task  \\\n",
       "count        10300.00          10300.00                10300.00   \n",
       "mean          9177.67           8331.07                   84.47   \n",
       "std           1837.78           2548.09                   36.40   \n",
       "min           3300.00           2900.00                    0.00   \n",
       "25%          10000.00           6450.00                  100.00   \n",
       "50%          10000.00          10000.00                  100.00   \n",
       "75%          10000.00          10000.00                  100.00   \n",
       "max          10000.00          10000.00                  100.00   \n",
       "\n",
       "       correct_ratio_sci_method  task_sci_f1  task_sci_precision  \\\n",
       "count                  10300.00     10300.00            10300.00   \n",
       "mean                      71.84        52.88               44.19   \n",
       "std                       45.20        31.69               33.13   \n",
       "min                        0.00         0.00                0.00   \n",
       "25%                        0.00        33.33               20.00   \n",
       "50%                      100.00        50.00               40.00   \n",
       "75%                      100.00        66.67               58.33   \n",
       "max                      100.00       100.00              100.00   \n",
       "\n",
       "       task_sci_recall  method_sci_f1  method_sci_precision  method_sci_recall  \n",
       "count         10300.00       10300.00              10300.00           10300.00  \n",
       "mean             81.23          44.08                 40.71              59.00  \n",
       "std              37.17          31.76                 33.90              42.76  \n",
       "min               0.00           0.00                  0.00               0.00  \n",
       "25%             100.00           0.00                  0.00               0.00  \n",
       "50%             100.00          50.00                 40.00              60.00  \n",
       "75%             100.00          66.67                 50.00             100.00  \n",
       "max             100.00         100.00                100.00             100.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coref gpt3\n",
    "(test_set.describe()*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2b72981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_sci_ratio</th>\n",
       "      <th>method_sci_ratio</th>\n",
       "      <th>correct_ratio_sci_task</th>\n",
       "      <th>correct_ratio_sci_method</th>\n",
       "      <th>task_sci_f1</th>\n",
       "      <th>task_sci_precision</th>\n",
       "      <th>task_sci_recall</th>\n",
       "      <th>method_sci_f1</th>\n",
       "      <th>method_sci_precision</th>\n",
       "      <th>method_sci_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "      <td>10300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9098.06</td>\n",
       "      <td>7772.82</td>\n",
       "      <td>84.47</td>\n",
       "      <td>67.96</td>\n",
       "      <td>52.88</td>\n",
       "      <td>44.19</td>\n",
       "      <td>81.23</td>\n",
       "      <td>42.13</td>\n",
       "      <td>39.42</td>\n",
       "      <td>55.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2125.29</td>\n",
       "      <td>3348.87</td>\n",
       "      <td>36.40</td>\n",
       "      <td>46.89</td>\n",
       "      <td>31.69</td>\n",
       "      <td>33.13</td>\n",
       "      <td>37.17</td>\n",
       "      <td>32.86</td>\n",
       "      <td>34.79</td>\n",
       "      <td>43.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>4900.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>20.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>58.33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>66.67</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_sci_ratio  method_sci_ratio  correct_ratio_sci_task  \\\n",
       "count        10300.00          10300.00                10300.00   \n",
       "mean          9098.06           7772.82                   84.47   \n",
       "std           2125.29           3348.87                   36.40   \n",
       "min              0.00              0.00                    0.00   \n",
       "25%          10000.00           4900.00                  100.00   \n",
       "50%          10000.00          10000.00                  100.00   \n",
       "75%          10000.00          10000.00                  100.00   \n",
       "max          10000.00          10000.00                  100.00   \n",
       "\n",
       "       correct_ratio_sci_method  task_sci_f1  task_sci_precision  \\\n",
       "count                  10300.00     10300.00            10300.00   \n",
       "mean                      67.96        52.88               44.19   \n",
       "std                       46.89        31.69               33.13   \n",
       "min                        0.00         0.00                0.00   \n",
       "25%                        0.00        33.33               20.00   \n",
       "50%                      100.00        50.00               40.00   \n",
       "75%                      100.00        66.67               58.33   \n",
       "max                      100.00       100.00              100.00   \n",
       "\n",
       "       task_sci_recall  method_sci_f1  method_sci_precision  method_sci_recall  \n",
       "count         10300.00       10300.00              10300.00           10300.00  \n",
       "mean             81.23          42.13                 39.42              55.11  \n",
       "std              37.17          32.86                 34.79              43.40  \n",
       "min               0.00           0.00                  0.00               0.00  \n",
       "25%             100.00           0.00                  0.00               0.00  \n",
       "50%             100.00          50.00                 40.00              50.00  \n",
       "75%             100.00          66.67                 50.00             100.00  \n",
       "max             100.00         100.00                100.00             100.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## coref\n",
    "(test_set.describe()*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60b24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
