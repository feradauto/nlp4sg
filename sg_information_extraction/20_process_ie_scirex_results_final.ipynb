{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec3436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe74101",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../data/\"\n",
    "output_path=\"../outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c940bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpredicted = [json.loads(line) for line in open('../../../test_outputs/sg_papers_scirex_predictions_test_final_2.jsonl')]\n",
    "tdf_predicted = pd.DataFrame(tpredicted)\n",
    "salient_test = [json.loads(line) for line in open('../../../test_outputs/salient_mentions_predictions_sg_papers_scirex_test_final_2.jsonl')]\n",
    "df_salient_test = pd.DataFrame(salient_test)\n",
    "sclusters = [json.loads(line) for line in open('../../../test_outputs/sg_papers_scirex_cluster_predictions_test_final_2.jsonl')]\n",
    "tdf_sclusters = pd.DataFrame(sclusters)\n",
    "\n",
    "df_salient_test=tdf_predicted.merge(df_salient_test,on='doc_id',how='left')\n",
    "df_salient_test=df_salient_test.merge(tdf_sclusters,on='doc_id',how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6476070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5088, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salient_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f5fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salient=df_salient_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004b4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salient['Method']=[list() for _ in range(df_salient.shape[0])]\n",
    "df_salient['Task']=[list() for _ in range(df_salient.shape[0])]\n",
    "df_salient['Metric']=[list() for _ in range(df_salient.shape[0])]\n",
    "df_salient['Dataset']=[list() for _ in range(df_salient.shape[0])]\n",
    "df_salient['Material']=[list() for _ in range(df_salient.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ce448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salient=df_salient.assign(clusters=np.where(df_salient.clusters.isna(),None,df_salient.clusters))\n",
    "df_salient=df_salient.assign(saliency=np.where(df_salient.saliency.isna(),None,df_salient.saliency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e048ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>sections</th>\n",
       "      <th>sentences</th>\n",
       "      <th>ner</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>saliency</th>\n",
       "      <th>spans</th>\n",
       "      <th>clusters</th>\n",
       "      <th>Method</th>\n",
       "      <th>Task</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[Assigning, Verbs, to, Semantic, Classes, via]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>korhonen-2002-assigning</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>[Predicative, multi, -, word, expressions, in,...</td>\n",
       "      <td>[[0, 84]]</td>\n",
       "      <td>[[0, 24], [24, 43], [43, 64], [64, 84], [84, 84]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>fleischhauer-2020-predicative</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>[Resolving, Event, Noun, Phrases, to, Their, V...</td>\n",
       "      <td>[[0, 7]]</td>\n",
       "      <td>[[0, 7]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>chen-etal-2010-resolving</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>[Parallels, between, Linguistics, and, Biology...</td>\n",
       "      <td>[[0, 41]]</td>\n",
       "      <td>[[0, 19], [19, 41], [41, 41]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>chakraborti-tendulkar-2013-parallels</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>[Semantically, Analyzing, an, English, Subset,...</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>simmons-bennett-novak-1975-semantically</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>[On, the, Means, for, Clarification, in]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>purver-etal-2001-means</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>[Parsing, English, Conjunctions, And, Comparat...</td>\n",
       "      <td>[[0, 12]]</td>\n",
       "      <td>[[0, 12]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>liu-soo-1989-parsing</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>[Using, prepositions, to, extend, a, verb]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>kipper-etal-2004-using</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>[Doing, Dutch, Pronouns, Automatically, in, Op...</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>bouma-2003-dutch</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>[Resolving, Pronouns, Robustly, :, Plumbing, t...</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>siddharthan-2003-resolving</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>[Wycliffes, Bibeltekster, p\\aa, RA2, (Wycliffe...</td>\n",
       "      <td>[[0, 124]]</td>\n",
       "      <td>[[0, 16], [16, 39], [39, 51], [51, 61], [61, 6...</td>\n",
       "      <td>[]</td>\n",
       "      <td>ro-lien-1981-wycliffes</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>[Speech, input, and, output]</td>\n",
       "      <td>[[0, 4]]</td>\n",
       "      <td>[[0, 4]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>gunawardana-1984-speech</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>[The, FINITE, STRING, ,, Volume, 14, ,, Number]</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>nn-1977-finite-string-volume-14-number-7</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>[Text, on, Tap, :, the, ACL/DCI, s, 200, ,, 00...</td>\n",
       "      <td>[[0, 63]]</td>\n",
       "      <td>[[0, 34], [34, 63]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>liberman-1989-text</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>[Processing, Unknown, Words, in, a, Dialogue]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>purver-2002-processing</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>[Outcomes, of, coming, out, :, Analyzing, stor...</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>ramesh-anand-2020-outcomes</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>[Learning, to, Classify, Utterances, in, a, Ta...</td>\n",
       "      <td>[[0, 9]]</td>\n",
       "      <td>[[0, 9]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>black-etal-2003-learning</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>[Syntaxe, Et]</td>\n",
       "      <td>[[0, 2]]</td>\n",
       "      <td>[[0, 2]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>vauquois-etal-1965-syntaxe</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>[Thinking, of, Going, Neural?, Factors, Honda,...</td>\n",
       "      <td>[[0, 59]]</td>\n",
       "      <td>[[0, 20], [20, 43], [43, 59]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>soldini-2018-thinking</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>[Porting, to, an, Italian, Surface, Realizer, ...</td>\n",
       "      <td>[[0, 9]]</td>\n",
       "      <td>[[0, 9]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>novello-callaway-2003-porting</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>[COLING, 90, :, Contents, in, Volumes, 1, -, 3...</td>\n",
       "      <td>[[0, 118]]</td>\n",
       "      <td>[[0, 25], [25, 34], [34, 52], [52, 72], [72, 9...</td>\n",
       "      <td>[]</td>\n",
       "      <td>nn-1990-coling</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>[Compound, Event, Nouns, of, the, `Modifier, -...</td>\n",
       "      <td>[[0, 145]]</td>\n",
       "      <td>[[0, 19], [19, 28], [28, 54], [54, 61], [61, 7...</td>\n",
       "      <td>[]</td>\n",
       "      <td>wang-huang-2011-compound</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>[Shedding, (a, Thousand, Points, of), Light, o...</td>\n",
       "      <td>[[0, 98]]</td>\n",
       "      <td>[[0, 20], [20, 57], [57, 68], [68, 98], [98, 98]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>yano-etal-2010-shedding</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>[Remarks, on, epistemically, biased, questions...</td>\n",
       "      <td>[[0, 156]]</td>\n",
       "      <td>[[0, 22], [22, 70], [70, 156], [156, 156]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>oshima-2017-remarks</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>[The, FINITE, STRING, ,, Volume, 15, ,, Number...</td>\n",
       "      <td>[[0, 44]]</td>\n",
       "      <td>[[0, 16], [16, 25], [25, 44], [44, 44]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>nn-1978-finite-string-volume</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>[The, behavior, of, English]</td>\n",
       "      <td>[[0, 4]]</td>\n",
       "      <td>[[0, 4]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>edmundson-1963-behavior</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>[Alignment, of, Sound, Track, with, Text, in, ...</td>\n",
       "      <td>[[0, 94]]</td>\n",
       "      <td>[[0, 94]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>tanimura-nakagawa-2000-alignment</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>[A, Corpus, of, Non, -, Native, Written, Engli...</td>\n",
       "      <td>[[0, 66]]</td>\n",
       "      <td>[[0, 30], [30, 37], [37, 66], [66, 66]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>beigman-klebanov-etal-2018-corpus</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>[Bias, and, Fairness, in, Natural, Language]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>chang-etal-2019-bias</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>[Preferred, Clause, Structure, in, Mandarin, S...</td>\n",
       "      <td>[[0, 32]]</td>\n",
       "      <td>[[0, 18], [18, 32]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>liu-1995-preferred</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>[The, Yerkish, Language, for, Non, -, Human]</td>\n",
       "      <td>[[0, 7]]</td>\n",
       "      <td>[[0, 7]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>von-glasersfeld-1974-yerkish</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>[Slavic, languages, -, -, -, comparative, morp...</td>\n",
       "      <td>[[0, 7]]</td>\n",
       "      <td>[[0, 7]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>pacak-1963-slavic</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>[Argument/Valency, Structure, in, PropBank, ,,...</td>\n",
       "      <td>[[0, 15]]</td>\n",
       "      <td>[[0, 15]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hajicova-kucerova-2002-argument</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4333</th>\n",
       "      <td>[Undestanding, Stories, in, Different, Languag...</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[[0, 8]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>bianchi-etal-1993-undestanding</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>[Coling, 2008, :, Companion, volume, :]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>coling-2008-coling-2008</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>[The, Omega]</td>\n",
       "      <td>[[0, 2]]</td>\n",
       "      <td>[[0, 2]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>philpot-etal-2005-omega</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  words    sections  \\\n",
       "94       [Assigning, Verbs, to, Semantic, Classes, via]    [[0, 6]]   \n",
       "229   [Predicative, multi, -, word, expressions, in,...   [[0, 84]]   \n",
       "291   [Resolving, Event, Noun, Phrases, to, Their, V...    [[0, 7]]   \n",
       "302   [Parallels, between, Linguistics, and, Biology...   [[0, 41]]   \n",
       "311   [Semantically, Analyzing, an, English, Subset,...    [[0, 8]]   \n",
       "352            [On, the, Means, for, Clarification, in]    [[0, 6]]   \n",
       "471   [Parsing, English, Conjunctions, And, Comparat...   [[0, 12]]   \n",
       "646          [Using, prepositions, to, extend, a, verb]    [[0, 6]]   \n",
       "719   [Doing, Dutch, Pronouns, Automatically, in, Op...    [[0, 6]]   \n",
       "1155  [Resolving, Pronouns, Robustly, :, Plumbing, t...    [[0, 8]]   \n",
       "1350  [Wycliffes, Bibeltekster, p\\aa, RA2, (Wycliffe...  [[0, 124]]   \n",
       "1428                       [Speech, input, and, output]    [[0, 4]]   \n",
       "1489    [The, FINITE, STRING, ,, Volume, 14, ,, Number]    [[0, 8]]   \n",
       "1532  [Text, on, Tap, :, the, ACL/DCI, s, 200, ,, 00...   [[0, 63]]   \n",
       "1641      [Processing, Unknown, Words, in, a, Dialogue]    [[0, 6]]   \n",
       "1710  [Outcomes, of, coming, out, :, Analyzing, stor...    [[0, 8]]   \n",
       "1758  [Learning, to, Classify, Utterances, in, a, Ta...    [[0, 9]]   \n",
       "1872                                      [Syntaxe, Et]    [[0, 2]]   \n",
       "1968  [Thinking, of, Going, Neural?, Factors, Honda,...   [[0, 59]]   \n",
       "2148  [Porting, to, an, Italian, Surface, Realizer, ...    [[0, 9]]   \n",
       "2232  [COLING, 90, :, Contents, in, Volumes, 1, -, 3...  [[0, 118]]   \n",
       "2336  [Compound, Event, Nouns, of, the, `Modifier, -...  [[0, 145]]   \n",
       "2534  [Shedding, (a, Thousand, Points, of), Light, o...   [[0, 98]]   \n",
       "2574  [Remarks, on, epistemically, biased, questions...  [[0, 156]]   \n",
       "2609  [The, FINITE, STRING, ,, Volume, 15, ,, Number...   [[0, 44]]   \n",
       "2801                       [The, behavior, of, English]    [[0, 4]]   \n",
       "2816  [Alignment, of, Sound, Track, with, Text, in, ...   [[0, 94]]   \n",
       "2868  [A, Corpus, of, Non, -, Native, Written, Engli...   [[0, 66]]   \n",
       "3010       [Bias, and, Fairness, in, Natural, Language]    [[0, 6]]   \n",
       "3191  [Preferred, Clause, Structure, in, Mandarin, S...   [[0, 32]]   \n",
       "3530       [The, Yerkish, Language, for, Non, -, Human]    [[0, 7]]   \n",
       "3677  [Slavic, languages, -, -, -, comparative, morp...    [[0, 7]]   \n",
       "3868  [Argument/Valency, Structure, in, PropBank, ,,...   [[0, 15]]   \n",
       "4333  [Undestanding, Stories, in, Different, Languag...    [[0, 8]]   \n",
       "4726            [Coling, 2008, :, Companion, volume, :]    [[0, 6]]   \n",
       "4864                                       [The, Omega]    [[0, 2]]   \n",
       "\n",
       "                                              sentences ner  \\\n",
       "94                                             [[0, 6]]  []   \n",
       "229   [[0, 24], [24, 43], [43, 64], [64, 84], [84, 84]]  []   \n",
       "291                                            [[0, 7]]  []   \n",
       "302                       [[0, 19], [19, 41], [41, 41]]  []   \n",
       "311                                            [[0, 8]]  []   \n",
       "352                                            [[0, 6]]  []   \n",
       "471                                           [[0, 12]]  []   \n",
       "646                                            [[0, 6]]  []   \n",
       "719                                            [[0, 6]]  []   \n",
       "1155                                           [[0, 8]]  []   \n",
       "1350  [[0, 16], [16, 39], [39, 51], [51, 61], [61, 6...  []   \n",
       "1428                                           [[0, 4]]  []   \n",
       "1489                                           [[0, 8]]  []   \n",
       "1532                                [[0, 34], [34, 63]]  []   \n",
       "1641                                           [[0, 6]]  []   \n",
       "1710                                           [[0, 8]]  []   \n",
       "1758                                           [[0, 9]]  []   \n",
       "1872                                           [[0, 2]]  []   \n",
       "1968                      [[0, 20], [20, 43], [43, 59]]  []   \n",
       "2148                                           [[0, 9]]  []   \n",
       "2232  [[0, 25], [25, 34], [34, 52], [52, 72], [72, 9...  []   \n",
       "2336  [[0, 19], [19, 28], [28, 54], [54, 61], [61, 7...  []   \n",
       "2534  [[0, 20], [20, 57], [57, 68], [68, 98], [98, 98]]  []   \n",
       "2574         [[0, 22], [22, 70], [70, 156], [156, 156]]  []   \n",
       "2609            [[0, 16], [16, 25], [25, 44], [44, 44]]  []   \n",
       "2801                                           [[0, 4]]  []   \n",
       "2816                                          [[0, 94]]  []   \n",
       "2868            [[0, 30], [30, 37], [37, 66], [66, 66]]  []   \n",
       "3010                                           [[0, 6]]  []   \n",
       "3191                                [[0, 18], [18, 32]]  []   \n",
       "3530                                           [[0, 7]]  []   \n",
       "3677                                           [[0, 7]]  []   \n",
       "3868                                          [[0, 15]]  []   \n",
       "4333                                           [[0, 8]]  []   \n",
       "4726                                           [[0, 6]]  []   \n",
       "4864                                           [[0, 2]]  []   \n",
       "\n",
       "                                        doc_id saliency spans clusters Method  \\\n",
       "94                     korhonen-2002-assigning     None   NaN     None     []   \n",
       "229              fleischhauer-2020-predicative     None   NaN     None     []   \n",
       "291                   chen-etal-2010-resolving     None   NaN     None     []   \n",
       "302       chakraborti-tendulkar-2013-parallels     None   NaN     None     []   \n",
       "311    simmons-bennett-novak-1975-semantically     None   NaN     None     []   \n",
       "352                     purver-etal-2001-means     None   NaN     None     []   \n",
       "471                       liu-soo-1989-parsing     None   NaN     None     []   \n",
       "646                     kipper-etal-2004-using     None   NaN     None     []   \n",
       "719                           bouma-2003-dutch     None   NaN     None     []   \n",
       "1155                siddharthan-2003-resolving     None   NaN     None     []   \n",
       "1350                    ro-lien-1981-wycliffes     None   NaN     None     []   \n",
       "1428                   gunawardana-1984-speech     None   NaN     None     []   \n",
       "1489  nn-1977-finite-string-volume-14-number-7     None   NaN     None     []   \n",
       "1532                        liberman-1989-text     None   NaN     None     []   \n",
       "1641                    purver-2002-processing     None   NaN     None     []   \n",
       "1710                ramesh-anand-2020-outcomes     None   NaN     None     []   \n",
       "1758                  black-etal-2003-learning     None   NaN     None     []   \n",
       "1872                vauquois-etal-1965-syntaxe     None   NaN     None     []   \n",
       "1968                     soldini-2018-thinking     None   NaN     None     []   \n",
       "2148             novello-callaway-2003-porting     None   NaN     None     []   \n",
       "2232                            nn-1990-coling     None   NaN     None     []   \n",
       "2336                  wang-huang-2011-compound     None   NaN     None     []   \n",
       "2534                   yano-etal-2010-shedding     None   NaN     None     []   \n",
       "2574                       oshima-2017-remarks     None   NaN     None     []   \n",
       "2609              nn-1978-finite-string-volume     None   NaN     None     []   \n",
       "2801                   edmundson-1963-behavior     None   NaN     None     []   \n",
       "2816          tanimura-nakagawa-2000-alignment     None   NaN     None     []   \n",
       "2868         beigman-klebanov-etal-2018-corpus     None   NaN     None     []   \n",
       "3010                      chang-etal-2019-bias     None   NaN     None     []   \n",
       "3191                        liu-1995-preferred     None   NaN     None     []   \n",
       "3530              von-glasersfeld-1974-yerkish     None   NaN     None     []   \n",
       "3677                         pacak-1963-slavic     None   NaN     None     []   \n",
       "3868           hajicova-kucerova-2002-argument     None   NaN     None     []   \n",
       "4333            bianchi-etal-1993-undestanding     None   NaN     None     []   \n",
       "4726                   coling-2008-coling-2008     None   NaN     None     []   \n",
       "4864                   philpot-etal-2005-omega     None   NaN     None     []   \n",
       "\n",
       "     Task Metric Dataset Material  \n",
       "94     []     []      []       []  \n",
       "229    []     []      []       []  \n",
       "291    []     []      []       []  \n",
       "302    []     []      []       []  \n",
       "311    []     []      []       []  \n",
       "352    []     []      []       []  \n",
       "471    []     []      []       []  \n",
       "646    []     []      []       []  \n",
       "719    []     []      []       []  \n",
       "1155   []     []      []       []  \n",
       "1350   []     []      []       []  \n",
       "1428   []     []      []       []  \n",
       "1489   []     []      []       []  \n",
       "1532   []     []      []       []  \n",
       "1641   []     []      []       []  \n",
       "1710   []     []      []       []  \n",
       "1758   []     []      []       []  \n",
       "1872   []     []      []       []  \n",
       "1968   []     []      []       []  \n",
       "2148   []     []      []       []  \n",
       "2232   []     []      []       []  \n",
       "2336   []     []      []       []  \n",
       "2534   []     []      []       []  \n",
       "2574   []     []      []       []  \n",
       "2609   []     []      []       []  \n",
       "2801   []     []      []       []  \n",
       "2816   []     []      []       []  \n",
       "2868   []     []      []       []  \n",
       "3010   []     []      []       []  \n",
       "3191   []     []      []       []  \n",
       "3530   []     []      []       []  \n",
       "3677   []     []      []       []  \n",
       "3868   []     []      []       []  \n",
       "4333   []     []      []       []  \n",
       "4726   []     []      []       []  \n",
       "4864   []     []      []       []  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salient.loc[(df_salient.saliency.isna()) & (df_salient.clusters.isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a4755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsaliency=[]\n",
    "for i,row in df_salient.iterrows():\n",
    "    #print(row['ner'])\n",
    "    ner={}\n",
    "    score={}\n",
    "    saliency={}\n",
    "    doc_dict={}\n",
    "    ner_list=[]\n",
    "    \n",
    "    doc_ner={}\n",
    "    for n in row['ner']:\n",
    "        word=str.lower(' '.join(row['words'][n[0]:n[1]]))\n",
    "        if n[2] in doc_ner:\n",
    "            doc_ner[n[2]].append({'words':[word],'value':0,'top_word':word})\n",
    "        else:\n",
    "            doc_ner[n[2]]=list([{'words':[word],'value':0,'top_word':word}])\n",
    "    if (row['clusters']!=None):\n",
    "        for s,n in zip(row['saliency'],row['ner']):\n",
    "            ner[str(n[0])+\"_\"+str(n[1])]=n[2]\n",
    "            score[str(n[0])+\"_\"+str(n[1])]=s[3]\n",
    "            saliency[str(n[0])+\"_\"+str(n[1])]=s[2]\n",
    "        for k in row['clusters'].keys():\n",
    "            scores=[]\n",
    "            saliency_flag=0\n",
    "            ner_list=[]\n",
    "            word_list=[]\n",
    "            for entity in row['clusters'][k]:\n",
    "                #print((' '.join(row['words'][entity[0]:entity[1]])).lower())\n",
    "                #print(ner[str(entity[0])+\"_\"+str(entity[1])])\n",
    "                #print(score[str(entity[0])+\"_\"+str(entity[1])])\n",
    "                ner_list.append(ner[str(entity[0])+\"_\"+str(entity[1])])\n",
    "                scores.append(score[str(entity[0])+\"_\"+str(entity[1])])\n",
    "                word=(' '.join(row['words'][entity[0]:entity[1]])).lower()\n",
    "                word=re.sub('[^0-9a-zA-Z ]+', '', word)\n",
    "                word=re.sub(' +', ' ',word)\n",
    "                word_list.append(word)\n",
    "                if saliency[str(entity[0])+\"_\"+str(entity[1])]==1:\n",
    "                    saliency_flag=1\n",
    "            #print(word_list)\n",
    "            type_ent=set(ner_list).pop()\n",
    "            if (type_ent in doc_dict) and (type_ent in ['Method','Task','Metric','Dataset']):\n",
    "                doc_dict[type_ent].append({'words':word_list,'value':np.mean(scores),'top_word':word_list[scores.index(max(scores))]})\n",
    "            else:\n",
    "                doc_dict[type_ent]=list([{'words':word_list,'value':np.mean(scores),'top_word':word_list[scores.index(max(scores))]}])\n",
    "    #print(doc_ner)\n",
    "    #print()\n",
    "    #print(doc_dict)\n",
    "    #print(\"#########\")\n",
    "    \n",
    "    for key in doc_ner.keys():\n",
    "        if key not in doc_dict.keys():\n",
    "            doc_dict[key]=doc_ner[key]\n",
    "    for key in doc_dict.keys():\n",
    "        df_salient.at[i,key]=doc_dict[key]\n",
    "        \n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97adad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_task=df_salient.loc[:,['doc_id','Task','Method']].rename(columns={'doc_id':'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3637b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_task=df_labels_task.rename(columns={'Task':'task_scirex','Method':'method_scirex'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c43990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4647, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.loc[(df_labels_task.method_scirex.apply(lambda x:len(x)!=0))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90376edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ohno-etal-2006-syntactically</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>korhonen-2002-assigning</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>fleischhauer-2020-predicative</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>chen-etal-2010-resolving</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>chakraborti-tendulkar-2013-parallels</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>simmons-bennett-novak-1975-semantically</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>purver-etal-2001-means</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>liu-soo-1989-parsing</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>sloos-etal-2018-boarnsterhim</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>grice-savino-1997-pitch</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>kipper-etal-2004-using</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>bouma-2003-dutch</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>siddharthan-2003-resolving</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>lyu-etal-2004-toward</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>coughlin-2003-correlating</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>barnes-etal-2021-nordial</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>ro-lien-1981-wycliffes</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>kucera-stluka-2014-corpus</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>gunawardana-1984-speech</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>nn-1977-finite-string-volume-14-number-7</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>jaffe-1963-simultaneous</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>liberman-1989-text</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>purver-2002-processing</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>ramesh-anand-2020-outcomes</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>black-etal-2003-learning</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>vauquois-etal-1965-syntaxe</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>soldini-2018-thinking</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>novello-callaway-2003-porting</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>nn-1990-coling</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>wang-huang-2011-compound</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>yano-etal-2010-shedding</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>oshima-2017-remarks</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>nn-1978-finite-string-volume</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>cettolo-etal-2015-iwslt</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>edmundson-1963-behavior</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>tanimura-nakagawa-2000-alignment</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>beigman-klebanov-etal-2018-corpus</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>chang-etal-2019-bias</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>liu-1995-preferred</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>dunn-adams-2020-geographically</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>von-glasersfeld-1974-yerkish</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>pacak-1963-slavic</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>tiedemann-nygaard-2004-opus</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>nielsen-2019-danish</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>hajicova-kucerova-2002-argument</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4333</th>\n",
       "      <td>bianchi-etal-1993-undestanding</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>simoes-etal-2016-enriching</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>tanaka-1995-edr</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>coling-2008-coling-2008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>philpot-etal-2005-omega</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ID task_scirex method_scirex\n",
       "33                ohno-etal-2006-syntactically          []            []\n",
       "94                     korhonen-2002-assigning          []            []\n",
       "229              fleischhauer-2020-predicative          []            []\n",
       "291                   chen-etal-2010-resolving          []            []\n",
       "302       chakraborti-tendulkar-2013-parallels          []            []\n",
       "311    simmons-bennett-novak-1975-semantically          []            []\n",
       "352                     purver-etal-2001-means          []            []\n",
       "471                       liu-soo-1989-parsing          []            []\n",
       "605               sloos-etal-2018-boarnsterhim          []            []\n",
       "612                    grice-savino-1997-pitch          []            []\n",
       "646                     kipper-etal-2004-using          []            []\n",
       "719                           bouma-2003-dutch          []            []\n",
       "1155                siddharthan-2003-resolving          []            []\n",
       "1164                      lyu-etal-2004-toward          []            []\n",
       "1186                 coughlin-2003-correlating          []            []\n",
       "1272                  barnes-etal-2021-nordial          []            []\n",
       "1350                    ro-lien-1981-wycliffes          []            []\n",
       "1354                 kucera-stluka-2014-corpus          []            []\n",
       "1428                   gunawardana-1984-speech          []            []\n",
       "1489  nn-1977-finite-string-volume-14-number-7          []            []\n",
       "1521                   jaffe-1963-simultaneous          []            []\n",
       "1532                        liberman-1989-text          []            []\n",
       "1641                    purver-2002-processing          []            []\n",
       "1710                ramesh-anand-2020-outcomes          []            []\n",
       "1758                  black-etal-2003-learning          []            []\n",
       "1872                vauquois-etal-1965-syntaxe          []            []\n",
       "1968                     soldini-2018-thinking          []            []\n",
       "2148             novello-callaway-2003-porting          []            []\n",
       "2232                            nn-1990-coling          []            []\n",
       "2336                  wang-huang-2011-compound          []            []\n",
       "2534                   yano-etal-2010-shedding          []            []\n",
       "2574                       oshima-2017-remarks          []            []\n",
       "2609              nn-1978-finite-string-volume          []            []\n",
       "2764                   cettolo-etal-2015-iwslt          []            []\n",
       "2801                   edmundson-1963-behavior          []            []\n",
       "2816          tanimura-nakagawa-2000-alignment          []            []\n",
       "2868         beigman-klebanov-etal-2018-corpus          []            []\n",
       "3010                      chang-etal-2019-bias          []            []\n",
       "3191                        liu-1995-preferred          []            []\n",
       "3498            dunn-adams-2020-geographically          []            []\n",
       "3530              von-glasersfeld-1974-yerkish          []            []\n",
       "3677                         pacak-1963-slavic          []            []\n",
       "3744               tiedemann-nygaard-2004-opus          []            []\n",
       "3796                       nielsen-2019-danish          []            []\n",
       "3868           hajicova-kucerova-2002-argument          []            []\n",
       "4333            bianchi-etal-1993-undestanding          []            []\n",
       "4599                simoes-etal-2016-enriching          []            []\n",
       "4701                           tanaka-1995-edr          []            []\n",
       "4726                   coling-2008-coling-2008          []            []\n",
       "4864                   philpot-etal-2005-omega          []            []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.loc[(df_labels_task.method_scirex.apply(lambda x:len(x)==0)) & (df_labels_task.task_scirex.apply(lambda x:len(x)==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcfdfc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miller-etal-2012-using</td>\n",
       "      <td>[{'words': ['disambiguation', 'disambiguation'...</td>\n",
       "      <td>[{'words': ['knowledge based methods'], 'value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kim-etal-2019-unsupervised</td>\n",
       "      <td>[{'words': ['parsing', 'constituency grammar i...</td>\n",
       "      <td>[{'words': ['unsupervised recurrent neural net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iyer-etal-2021-veealign</td>\n",
       "      <td>[{'words': ['ontology alignment', 'ontology al...</td>\n",
       "      <td>[{'words': ['multifaceted context representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patra-etal-2013-automatic</td>\n",
       "      <td>[{'words': ['automatic music mood classificati...</td>\n",
       "      <td>[{'words': ['automatic methods'], 'value': 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kazi-etal-2014-mitll</td>\n",
       "      <td>[{'words': ['mt', 'mt', 'translating'], 'value...</td>\n",
       "      <td>[{'words': ['deep neural networks'], 'value': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5083</th>\n",
       "      <td>owoputi-etal-2013-improved</td>\n",
       "      <td>[{'words': ['part of speech tagging', 'part of...</td>\n",
       "      <td>[{'words': ['pos', 'tagging software'], 'value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>kang-etal-2020-neural</td>\n",
       "      <td>[{'words': ['question answering', 'question an...</td>\n",
       "      <td>[{'words': ['reinforcement learning based fram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>ligozat-2013-question</td>\n",
       "      <td>[{'words': ['question classification', 'questi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>hozumi-etal-1993-integration</td>\n",
       "      <td>[{'words': ['morphological and syntactic analy...</td>\n",
       "      <td>[{'words': ['lr', 'lr', 'lr'], 'value': 0.1034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>maruf-etal-2021-explaining</td>\n",
       "      <td>[{'words': ['explaining decision tree predicti...</td>\n",
       "      <td>[{'words': ['explanatory schemas', '1 explanat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5038 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ID  \\\n",
       "0           miller-etal-2012-using   \n",
       "1       kim-etal-2019-unsupervised   \n",
       "2          iyer-etal-2021-veealign   \n",
       "3        patra-etal-2013-automatic   \n",
       "4             kazi-etal-2014-mitll   \n",
       "...                            ...   \n",
       "5083    owoputi-etal-2013-improved   \n",
       "5084         kang-etal-2020-neural   \n",
       "5085         ligozat-2013-question   \n",
       "5086  hozumi-etal-1993-integration   \n",
       "5087    maruf-etal-2021-explaining   \n",
       "\n",
       "                                            task_scirex  \\\n",
       "0     [{'words': ['disambiguation', 'disambiguation'...   \n",
       "1     [{'words': ['parsing', 'constituency grammar i...   \n",
       "2     [{'words': ['ontology alignment', 'ontology al...   \n",
       "3     [{'words': ['automatic music mood classificati...   \n",
       "4     [{'words': ['mt', 'mt', 'translating'], 'value...   \n",
       "...                                                 ...   \n",
       "5083  [{'words': ['part of speech tagging', 'part of...   \n",
       "5084  [{'words': ['question answering', 'question an...   \n",
       "5085  [{'words': ['question classification', 'questi...   \n",
       "5086  [{'words': ['morphological and syntactic analy...   \n",
       "5087  [{'words': ['explaining decision tree predicti...   \n",
       "\n",
       "                                          method_scirex  \n",
       "0     [{'words': ['knowledge based methods'], 'value...  \n",
       "1     [{'words': ['unsupervised recurrent neural net...  \n",
       "2     [{'words': ['multifaceted context representati...  \n",
       "3     [{'words': ['automatic methods'], 'value': 0, ...  \n",
       "4     [{'words': ['deep neural networks'], 'value': ...  \n",
       "...                                                 ...  \n",
       "5083  [{'words': ['pos', 'tagging software'], 'value...  \n",
       "5084  [{'words': ['reinforcement learning based fram...  \n",
       "5085                                                 []  \n",
       "5086  [{'words': ['lr', 'lr', 'lr'], 'value': 0.1034...  \n",
       "5087  [{'words': ['explanatory schemas', '1 explanat...  \n",
       "\n",
       "[5038 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.loc[(df_labels_task.method_scirex.apply(lambda x:len(x)!=0)) | (df_labels_task.task_scirex.apply(lambda x:len(x)!=0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4130783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>task_scirex</th>\n",
       "      <th>method_scirex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miller-etal-2012-using</td>\n",
       "      <td>[{'words': ['disambiguation', 'disambiguation'...</td>\n",
       "      <td>[{'words': ['knowledge based methods'], 'value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kim-etal-2019-unsupervised</td>\n",
       "      <td>[{'words': ['parsing', 'constituency grammar i...</td>\n",
       "      <td>[{'words': ['unsupervised recurrent neural net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iyer-etal-2021-veealign</td>\n",
       "      <td>[{'words': ['ontology alignment', 'ontology al...</td>\n",
       "      <td>[{'words': ['multifaceted context representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patra-etal-2013-automatic</td>\n",
       "      <td>[{'words': ['automatic music mood classificati...</td>\n",
       "      <td>[{'words': ['automatic methods'], 'value': 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kazi-etal-2014-mitll</td>\n",
       "      <td>[{'words': ['mt', 'mt', 'translating'], 'value...</td>\n",
       "      <td>[{'words': ['deep neural networks'], 'value': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>narsale-2010-jhu</td>\n",
       "      <td>[{'words': ['wmt 2010', 'wmt 2010 submission']...</td>\n",
       "      <td>[{'words': ['jhu system combination scheme', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5083</th>\n",
       "      <td>owoputi-etal-2013-improved</td>\n",
       "      <td>[{'words': ['part of speech tagging', 'part of...</td>\n",
       "      <td>[{'words': ['pos', 'tagging software'], 'value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>kang-etal-2020-neural</td>\n",
       "      <td>[{'words': ['question answering', 'question an...</td>\n",
       "      <td>[{'words': ['reinforcement learning based fram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>hozumi-etal-1993-integration</td>\n",
       "      <td>[{'words': ['morphological and syntactic analy...</td>\n",
       "      <td>[{'words': ['lr', 'lr', 'lr'], 'value': 0.1034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>maruf-etal-2021-explaining</td>\n",
       "      <td>[{'words': ['explaining decision tree predicti...</td>\n",
       "      <td>[{'words': ['explanatory schemas', '1 explanat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4473 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ID  \\\n",
       "0           miller-etal-2012-using   \n",
       "1       kim-etal-2019-unsupervised   \n",
       "2          iyer-etal-2021-veealign   \n",
       "3        patra-etal-2013-automatic   \n",
       "4             kazi-etal-2014-mitll   \n",
       "...                            ...   \n",
       "5082              narsale-2010-jhu   \n",
       "5083    owoputi-etal-2013-improved   \n",
       "5084         kang-etal-2020-neural   \n",
       "5086  hozumi-etal-1993-integration   \n",
       "5087    maruf-etal-2021-explaining   \n",
       "\n",
       "                                            task_scirex  \\\n",
       "0     [{'words': ['disambiguation', 'disambiguation'...   \n",
       "1     [{'words': ['parsing', 'constituency grammar i...   \n",
       "2     [{'words': ['ontology alignment', 'ontology al...   \n",
       "3     [{'words': ['automatic music mood classificati...   \n",
       "4     [{'words': ['mt', 'mt', 'translating'], 'value...   \n",
       "...                                                 ...   \n",
       "5082  [{'words': ['wmt 2010', 'wmt 2010 submission']...   \n",
       "5083  [{'words': ['part of speech tagging', 'part of...   \n",
       "5084  [{'words': ['question answering', 'question an...   \n",
       "5086  [{'words': ['morphological and syntactic analy...   \n",
       "5087  [{'words': ['explaining decision tree predicti...   \n",
       "\n",
       "                                          method_scirex  \n",
       "0     [{'words': ['knowledge based methods'], 'value...  \n",
       "1     [{'words': ['unsupervised recurrent neural net...  \n",
       "2     [{'words': ['multifaceted context representati...  \n",
       "3     [{'words': ['automatic methods'], 'value': 0, ...  \n",
       "4     [{'words': ['deep neural networks'], 'value': ...  \n",
       "...                                                 ...  \n",
       "5082  [{'words': ['jhu system combination scheme', '...  \n",
       "5083  [{'words': ['pos', 'tagging software'], 'value...  \n",
       "5084  [{'words': ['reinforcement learning based fram...  \n",
       "5086  [{'words': ['lr', 'lr', 'lr'], 'value': 0.1034...  \n",
       "5087  [{'words': ['explanatory schemas', '1 explanat...  \n",
       "\n",
       "[4473 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.loc[(df_labels_task.method_scirex.apply(lambda x:len(x)!=0)) & (df_labels_task.task_scirex.apply(lambda x:len(x)!=0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10833b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_task.to_json(output_path+\"sg_ie/test_scirex_tasks_methods_clusters_final_f.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a53d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
