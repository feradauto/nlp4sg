{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92eaf96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54aef898",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../../data/\"\n",
    "output_path=\"../../outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb18fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(output_path+\"sg_ie/positives_ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176b4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(abstract_for_prompt=df.abstract_for_prompt.fillna(\"\"))\n",
    "\n",
    "df=df.assign(paper_text=\"Title: \"+df.title_clean+\"\\n\"+df.abstract_for_prompt)\n",
    "\n",
    "ack_preprompt=\"\"\"Identify the NLP task(s) addressed in this paper. Answer in the format [task1,...,taskn,...]\"\"\"\n",
    "\n",
    "ack_postprompt=\"\"\"The NLP tasks addressed in this paper are:\\n[\"\"\"\n",
    "\n",
    "df=df.assign(task_prompt_text=ack_preprompt+\"\\n\"+df.paper_text+\"\\n\"+ack_postprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaa179b",
   "metadata": {},
   "source": [
    "## cost estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77a898f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1475484"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['task_prompt_text'].str.split().apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "$0.0600 / 1K tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940ff871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8952, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab73dd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358080"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8952*40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "1627921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da41912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146.68511999999998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((1475484+358080)*1000/750)/1000)*0.0600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca199c2",
   "metadata": {},
   "source": [
    "## requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in df.iterrows():\n",
    "    input_prompt=d['task_prompt_text']\n",
    "    if ((i%100==0) or i<100):\n",
    "        print(input_prompt)\n",
    "        print(\"###################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in df.iterrows():\n",
    "    input_prompt=d['task_prompt_text']\n",
    "    completion = openai.Completion.create(engine=\"text-davinci-002\", prompt=input_prompt,temperature=0,max_tokens=40)\n",
    "    df.loc[i,'GPT3_response']=completion.choices[0].text\n",
    "    f = open(\"/cluster/scratch/fgonzalez/logs_gpt3/responses_full.txt\", \"a\")\n",
    "    f.write(d['task_prompt_text'])\n",
    "    f.write(completion.choices[0].text)\n",
    "    f.write(\"################################\")\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    if ((i%100==0) or i<100):\n",
    "        print(input_prompt)\n",
    "        print(completion.choices[0].text)\n",
    "        print(\"################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f48655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(clean_response=df.GPT3_response.replace(\"\\n\",\"\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(\"(?:The|The NLP|)(?:NLP|)\\stasks addressed in this paper\\s?(?:are|include|):\",\"\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(\"NLP tasks:\",\"\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(\"[?Tt]ask\\s?\\d: \",\"\",regex=True).replace(\"\\[?[tT]ask\\d\\]\",\",\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(\"\\[?\\d\\]\",\",\",regex=True).replace(\"\\d\\.\",\",\",regex=True).replace(\"\\(?\\d\\)\",\",\",regex=True).replace(\"task1,\\s?task2,\\.\\.\\.\\]\",\"\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(',,',',',regex=True).replace('  ',' ',regex=True).str.rstrip(']').str.lstrip(',').str.lstrip(' '))\n",
    "\n",
    "df=df.assign(clean_response=df.clean_response.str.split(\",\"))\n",
    "\n",
    "tasks=df.loc[:,['ID','clean_response']]\n",
    "\n",
    "tasks=tasks.explode(\"clean_response\")\n",
    "\n",
    "tasks=tasks.rename(columns={'clean_response':'tasks'})\n",
    "\n",
    "tasks=tasks.assign(tasks=tasks.tasks.str.lstrip().str.rstrip())\n",
    "tasks=tasks.loc[tasks.tasks!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eec7fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin-etal-2006-generative</td>\n",
       "      <td>discourse analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin-etal-2006-generative</td>\n",
       "      <td>text classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ghosh-etal-2020-iitp</td>\n",
       "      <td>Offensive Language Identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ghosh-etal-2020-iitp</td>\n",
       "      <td>Target Categorization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grouin-2016-identification</td>\n",
       "      <td>identification of mentions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>Language (technology) is power: The need to be...</td>\n",
       "      <td>stance detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>Language (technology) is power: The need to be...</td>\n",
       "      <td>opinion mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>Gender in Danger? Evaluating Speech Translatio...</td>\n",
       "      <td>speech recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>Gender in Danger? Evaluating Speech Translatio...</td>\n",
       "      <td>speech translation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>Gender in Danger? Evaluating Speech Translatio...</td>\n",
       "      <td>text classification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26448 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     ID  \\\n",
       "0                              lin-etal-2006-generative   \n",
       "0                              lin-etal-2006-generative   \n",
       "1                                  ghosh-etal-2020-iitp   \n",
       "1                                  ghosh-etal-2020-iitp   \n",
       "2                            grouin-2016-identification   \n",
       "...                                                 ...   \n",
       "8950  Language (technology) is power: The need to be...   \n",
       "8950  Language (technology) is power: The need to be...   \n",
       "8951  Gender in Danger? Evaluating Speech Translatio...   \n",
       "8951  Gender in Danger? Evaluating Speech Translatio...   \n",
       "8951  Gender in Danger? Evaluating Speech Translatio...   \n",
       "\n",
       "                                  tasks  \n",
       "0                    discourse analysis  \n",
       "0                   text classification  \n",
       "1     Offensive Language Identification  \n",
       "1                 Target Categorization  \n",
       "2            identification of mentions  \n",
       "...                                 ...  \n",
       "8950                   stance detection  \n",
       "8950                     opinion mining  \n",
       "8951                 speech recognition  \n",
       "8951                 speech translation  \n",
       "8951                text classification  \n",
       "\n",
       "[26448 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f11c2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path+\"sg_ie/gpt3/GPT3_responses_task_full.csv\",index=False)\n",
    "\n",
    "tasks.to_csv(output_path+\"sg_ie/gpt3/GPT3_responses_task_full_cleaned.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ae93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
