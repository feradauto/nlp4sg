{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1411e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037e7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../../data/\"\n",
    "output_path=\"../../outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e3c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(output_path+\"sg_ie/positives_ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0af5113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(abstract_for_prompt=df.abstract_for_prompt.fillna(\"\"))\n",
    "\n",
    "df=df.assign(paper_text=\"Title: \"+df.title_clean+\"\\n\"+df.abstract_for_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5662834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ack_preprompt=\"\"\"Identify the NLP methods employed in this paper. Answer in the format [method1,...,methodn] Answer up to 3 methods.\"\"\"\n",
    "\n",
    "ack_postprompt=\"\"\"What are the methods employed to solve the tasks? Don't include tasks in the answer. The NLP methods used in this paper are:\\n[\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b780e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(method_prompt_text=ack_preprompt+\"\\n\"+df.paper_text+\"\\n\"+ack_postprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84efc0",
   "metadata": {},
   "source": [
    "## cost estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8cf4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1654524"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['method_prompt_text'].str.split().apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31297fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "$0.0600 / 1K tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84ae57c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8952, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e4ac78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8952*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23bf79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1627921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d01382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.16992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((1654524+447600)*1000/750)/1000)*0.0600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a22a1",
   "metadata": {},
   "source": [
    "## requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in df.iterrows():\n",
    "    input_prompt=d['method_prompt_text']\n",
    "    if ((i%100==0) or i<100):\n",
    "        print(input_prompt)\n",
    "        print(\"###################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff540d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in df.iterrows():\n",
    "    input_prompt=d['method_prompt_text']\n",
    "    completion = openai.Completion.create(engine=\"text-davinci-002\", prompt=input_prompt,temperature=0,max_tokens=40)\n",
    "    df.loc[i,'GPT3_response']=completion.choices[0].text\n",
    "    f = open(\"/cluster/scratch/fgonzalez/logs_gpt3/responses_full_m2.txt\", \"a\")\n",
    "    f.write(d['method_prompt_text'])\n",
    "    f.write(completion.choices[0].text)\n",
    "    f.write(\"################################\")\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    if ((i%50==0) or i<100):\n",
    "        print(input_prompt)\n",
    "        print(completion.choices[0].text)\n",
    "        print(\"################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12766d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(clean_response=df.GPT3_response.replace(\"\\n\",\"\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(\"(?:The|The NLP|)(?:NLP|)\\smethods addressed in this paper\\s?(?:are|include|):\",\"\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(\"NLP methods:\",\"\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(\"[?Tt]ask\\s?\\d: \",\"\",regex=True).replace(\"\\[?[tT]ask\\d\\]\",\",\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(\"\\[?\\d\\]\",\",\",regex=True).replace(\"\\d\\.\",\",\",regex=True).replace(\"\\(?\\d\\)\",\",\",regex=True).replace(\"method1,\\s?method2,\\.\\.\\.\\]\",\"\",regex=True))\n",
    "df=df.assign(clean_response=df.clean_response.replace(',,',',',regex=True).replace('  ',' ',regex=True).str.rstrip(']').str.lstrip(',').str.lstrip(' '))\n",
    "\n",
    "df=df.assign(clean_response=df.clean_response.str.split(\",\"))\n",
    "\n",
    "methods=df.loc[:,['ID','clean_response']]\n",
    "\n",
    "methods=methods.explode(\"clean_response\")\n",
    "\n",
    "methods=methods.rename(columns={'clean_response':'methods'})\n",
    "\n",
    "methods=methods.assign(methods=methods.methods.str.lstrip().str.rstrip())\n",
    "methods=methods.loc[methods.methods!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a651992",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin-etal-2006-generative</td>\n",
       "      <td>generative models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin-etal-2006-generative</td>\n",
       "      <td>Hidden Markov Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin-etal-2006-generative</td>\n",
       "      <td>Support Vector Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ghosh-etal-2020-iitp</td>\n",
       "      <td>BiGRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ghosh-etal-2020-iitp</td>\n",
       "      <td>deep neural network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>Language (technology) is power: The need to be...</td>\n",
       "      <td>Lemmatization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>Language (technology) is power: The need to be...</td>\n",
       "      <td>POS tagging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>Gender in Danger? Evaluating Speech Translatio...</td>\n",
       "      <td>statistical machine translation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>Gender in Danger? Evaluating Speech Translatio...</td>\n",
       "      <td>automatic speech recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>Gender in Danger? Evaluating Speech Translatio...</td>\n",
       "      <td>natural language processing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26853 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     ID  \\\n",
       "0                              lin-etal-2006-generative   \n",
       "0                              lin-etal-2006-generative   \n",
       "0                              lin-etal-2006-generative   \n",
       "1                                  ghosh-etal-2020-iitp   \n",
       "1                                  ghosh-etal-2020-iitp   \n",
       "...                                                 ...   \n",
       "8950  Language (technology) is power: The need to be...   \n",
       "8950  Language (technology) is power: The need to be...   \n",
       "8951  Gender in Danger? Evaluating Speech Translatio...   \n",
       "8951  Gender in Danger? Evaluating Speech Translatio...   \n",
       "8951  Gender in Danger? Evaluating Speech Translatio...   \n",
       "\n",
       "                              methods  \n",
       "0                   generative models  \n",
       "0                Hidden Markov Models  \n",
       "0             Support Vector Machines  \n",
       "1                               BiGRU  \n",
       "1                 deep neural network  \n",
       "...                               ...  \n",
       "8950                    Lemmatization  \n",
       "8950                      POS tagging  \n",
       "8951  statistical machine translation  \n",
       "8951     automatic speech recognition  \n",
       "8951      natural language processing  \n",
       "\n",
       "[26853 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bc292dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path+\"sg_ie/gpt3/GPT3_responses_full_method2.csv\",index=False)\n",
    "\n",
    "methods.to_csv(output_path+\"sg_ie/gpt3/GPT3_responses_full_method2_cleaned.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb0fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
