{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4773e049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 00:59:11.639700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/gcc-6.3.0/openblas-0.2.20-cot3cawsqf4pkxjwzjexaykbwn2ch3ii/lib:/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64:/cluster/spack/apps/linux-centos7-x86_64/gcc-4.8.5/gcc-6.3.0-sqhtfh32p5gerbkvi5hih7cfvcpmewvj/lib64:/cluster/spack/apps/linux-centos7-x86_64/gcc-4.8.5/gcc-6.3.0-sqhtfh32p5gerbkvi5hih7cfvcpmewvj/lib:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib\n",
      "2022-07-16 00:59:11.639750: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5028c74c19e4703bd79b8624fe1d922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 00:59:35 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-07-16 00:59:35 INFO: Use device: gpu\n",
      "2022-07-16 00:59:35 INFO: Loading: tokenize\n",
      "2022-07-16 00:59:46 INFO: Loading: pos\n",
      "2022-07-16 00:59:46 INFO: Loading: lemma\n",
      "2022-07-16 00:59:46 INFO: Loading: depparse\n",
      "2022-07-16 00:59:47 INFO: Loading: sentiment\n",
      "2022-07-16 00:59:47 INFO: Loading: constituency\n",
      "2022-07-16 00:59:47 INFO: Loading: ner\n",
      "2022-07-16 00:59:48 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline('en', processors={'ner': 'OntoNotes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e52844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_org(x):\n",
    "    doc=nlp(x)\n",
    "    orgs=[]\n",
    "    for sentence in doc.sentences:\n",
    "        for e in sentence.ents:\n",
    "            if e.type=='ORG':\n",
    "                orgs.append(e.text)\n",
    "    return orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8cca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_organizations(positives):\n",
    "    \"\"\"\n",
    "    Use stanza to parse organizations from the acknowledgments and if that section doesn't exist, get them from\n",
    "    the abstract restricting to organizations that are common in the acknowledgments\n",
    "    \"\"\"\n",
    "    positives=positives.assign(abstract_for_prompt=positives.abstract_for_prompt.fillna(\"\"))\n",
    "    positives=positives.assign(acknowledgments_for_prompt=positives.acknowledgments_for_prompt.fillna(\"\"))\n",
    "\n",
    "\n",
    "    positives=positives.assign(organization_ack=positives.acknowledgments_for_prompt.apply(lambda x:get_org(x)))\n",
    "\n",
    "    positives=positives.assign(organization_abstract=positives.title_abstract_clean.apply(lambda x:get_org(x)))\n",
    "    ## Acknowledgments\n",
    "    orgs_ack=positives.loc[:,['ID','organization_ack']]\n",
    "    orgs_ack=orgs_ack.explode('organization_ack')\n",
    "    orgs_ack=orgs_ack.dropna()\n",
    "\n",
    "    # abstract\n",
    "    orgs_abs=positives.loc[:,['ID','organization_abstract']]\n",
    "    orgs_abs=orgs_abs.explode('organization_abstract')\n",
    "    orgs_abs=orgs_abs.dropna()\n",
    "    ## restrict the ones extracted from abstract\n",
    "    orgs_ack_common=orgs_ack.organization_ack.value_counts().reset_index().rename(columns={'index':'name'}).head(400)\n",
    "    orgs_ack_common=orgs_ack_common.loc[~orgs_ack_common.name.isin(['No organization','Twitter', 'NLP', 'Reddit', 'Facebook',\n",
    "           'Social Media', 'EU', 'ASR', 'BioNLP', 'AI', 'BioASQ', 'Google','IBM'\n",
    "           'CLARIN', 'Amazon', 'ACL', 'ERC', 'Microsoft', 'SemEval'])]\n",
    "    orgs_abs_real=orgs_abs.loc[orgs_abs.organization_abstract.isin(orgs_ack_common.name.unique())]\n",
    "\n",
    "    orgs_ack=orgs_ack.rename(columns={'organization_ack':'organization'})\n",
    "    orgs_abs_real=orgs_abs_real.rename(columns={'organization_abstract':'organization'})\n",
    "    # concat them\n",
    "    organizations=pd.concat([orgs_ack,orgs_abs_real])\n",
    "    ## hand crafted rules\n",
    "    organizations=organizations.loc[~organizations.organization.isin(['NLP'])]\n",
    "    organizations=organizations.assign(organization=organizations.organization.str.lstrip(\"the \"))\n",
    "    organizations=organizations.assign(organization=np.where(organizations.organization.isin(['NSF']),\n",
    "                                                            \"Natural Science Foundation\",\n",
    "                                                            organizations.organization))\n",
    "    return organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e398a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_path=\"../../data/\"\n",
    "    output_path=\"../../outputs/\"\n",
    "\n",
    "    positives=pd.read_csv(output_path+\"sg_ie/positives_ready.csv\")\n",
    "    organizations=get_organizations(positives)\n",
    "    organizations.to_csv(output_path+\"sg_ie/organizations_stanza_ontonotes_final.csv\",index=False)\n",
    "    \n",
    "    test=pd.read_csv(output_path+\"sg_ie/test_ready.csv\")\n",
    "    organizations_test=get_organizations(test)\n",
    "    organizations_test.to_csv(output_path+\"sg_ie/organizations_test_stanza_ontonotes_final.csv\",index=False)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3048f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
