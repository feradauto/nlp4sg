{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a303db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import operator\n",
    "from sklearn.metrics import classification_report\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8abf91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../../data/\"\n",
    "outputs_path=\"../../outputs/\"\n",
    "\n",
    "df_test_final=pd.read_csv(outputs_path+\"general/test_set_final.csv\")\n",
    "df_test_final=df_test_final.iloc[:2000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8bf132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa06ec7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df_test_final.reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d45f1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprompt=\"There is an NLP paper with the following title:\\n\"\n",
    "\n",
    "#question=\"Could it be argued that this paper directly contributes to the UN Sustainable Development Goals? Answer yes or no.\"\n",
    "#question=\"Is this paper directly or indirectly contributing to the UN Sustainable Development Goals? Answer yes or no, then explain.\"\n",
    "question=\"Is this paper contributing to the UN Sustainable Development Goals? Answer yes or no. If the answer is \\\"yes\\\", mention which goal the paper is contributing to and in which way.\"\n",
    "df=df.assign(statement=preprompt+df.title_clean+\"\\n\"+question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in df.iterrows():\n",
    "    input_prompt=d['statement']\n",
    "    print(input_prompt)\n",
    "    print(\"original label: \",d['label'],d['goal1_raw'],d['goal2_raw'],d['goal3_raw'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c164cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in df.iterrows():\n",
    "    input_prompt=d['statement']\n",
    "    completion = openai.Completion.create(engine=\"text-davinci-002\", prompt=input_prompt,temperature=0,max_tokens=50,logprobs=10)\n",
    "    dict_norm={}\n",
    "    dict_uniques={}\n",
    "    ## new part, get the first element where there the most probable is not a break of line\n",
    "    for choices in completion['choices'][0][\"logprobs\"]['top_logprobs']:\n",
    "        choice=dict(choices)\n",
    "        max_val=max(choice.items(), key=operator.itemgetter(1))[0]\n",
    "        if \"\\n\" not in max_val:\n",
    "            elements=choices\n",
    "            break\n",
    "    for e in elements:\n",
    "        e_modified=e.lower().lstrip(' ')\n",
    "        if e_modified in dict_uniques:\n",
    "            dict_uniques[e_modified]=dict_uniques[e_modified]+np.exp(elements[e])\n",
    "        else:\n",
    "            dict_uniques[e_modified]=np.exp(elements[e])\n",
    "\n",
    "    if ('no' in dict_uniques.keys()) and ('yes' in dict_uniques.keys()):\n",
    "        dict_norm={'no':dict_uniques['no'],'yes':dict_uniques['yes']}\n",
    "    elif ('no' in dict_uniques.keys()):\n",
    "        dict_norm={'no':dict_uniques['no'],'yes':0}\n",
    "    elif ('yes' in dict_uniques.keys()):\n",
    "        dict_norm={'no':0,'yes':dict_uniques['yes']}\n",
    "\n",
    "    factor=1.0/sum(dict_norm.values())\n",
    "    for k in dict_norm:\n",
    "        dict_norm[k] = dict_norm[k]*factor    \n",
    "\n",
    "    df.loc[i,'full_prompt']=input_prompt\n",
    "    df.loc[i,'GPT3_response']=completion.choices[0].text\n",
    "    df.loc[i,'proba_1']=dict_norm['yes']\n",
    "    df.loc[i,'proba_0']=dict_norm['no']\n",
    "    print(input_prompt)\n",
    "    print(completion.choices[0].text)\n",
    "    print(\"proba yes: \",dict_norm['yes'])\n",
    "    print(\"original label: \",d['label'],d['goal1_raw'],d['goal2_raw'],d['goal3_raw'])\n",
    "    print(\"#########################################\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f818107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(prediction_proba=np.where(df.proba_1>0.5,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72320579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.assign(textual_pred=np.where(((df.GPT3_response.str.lower().str.startswith(\"yes\")) | \n",
    "                                     (df.GPT3_response.str.lower().str.contains(\"is contrib\"))\n",
    "                                     ),1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8991d348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1709\n",
       "1     291\n",
       "Name: prediction_proba, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prediction_proba.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99bbabda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8923    0.8785    0.8853      1736\n",
      "           1     0.2749    0.3030    0.2883       264\n",
      "\n",
      "    accuracy                         0.8025      2000\n",
      "   macro avg     0.5836    0.5907    0.5868      2000\n",
      "weighted avg     0.8108    0.8025    0.8065      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## zero shot title \n",
    "print(classification_report(df.label,df.prediction_proba,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edea508e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1092\n",
       "1     908\n",
       "Name: textual_pred, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.textual_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff8f27eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9103    0.5726    0.7030      1736\n",
      "           1     0.1828    0.6288    0.2833       264\n",
      "\n",
      "    accuracy                         0.5800      2000\n",
      "   macro avg     0.5465    0.6007    0.4931      2000\n",
      "weighted avg     0.8142    0.5800    0.6476      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label,df.textual_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5b235e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(outputs_path+\"sg_classifier/gpt3_zshot_title_f.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afa24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
