{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db85663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "from datasets import load_metric\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import re\n",
    "from collections import Counter\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af93cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=predictions)\n",
    "    recall = recall_score(y_true=labels, y_pred=predictions)\n",
    "    precision = precision_score(y_true=labels, y_pred=predictions)\n",
    "    recall_w = recall_score(y_true=labels, y_pred=predictions,average='weighted')\n",
    "    precision_w = precision_score(y_true=labels, y_pred=predictions,average='weighted')\n",
    "    f1 = f1_score(y_true=labels, y_pred=predictions)\n",
    "    f1_pos = f1_score(y_true=labels, y_pred=predictions,average='binary',pos_label=1)\n",
    "    f1_micro = f1_score(y_true=labels, y_pred=predictions,average='micro')\n",
    "    f1_weighted = f1_score(y_true=labels, y_pred=predictions,average='weighted')\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall,\n",
    "             \"precision_w\": precision_w, \"recall_w\": recall_w,\n",
    "             \"f1\": f1,\"f1_pos\": f1_pos,\n",
    "            \"f1_micro\": f1_micro,\"f1_weighted\": f1_weighted} \n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True,max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd826fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(df_results):\n",
    "    \"\"\"Get classification report\n",
    "\n",
    "    Parameters:\n",
    "    df_results: should have column label and prediction\n",
    "    \"\"\"\n",
    "    cr=classification_report(df_results.label,df_results.prediction,digits=4,output_dict=True)\n",
    "\n",
    "    cr=pd.DataFrame(cr).reset_index().rename(columns={'index':'metric'})\n",
    "\n",
    "    cr_df=pd.melt(cr,id_vars=['metric'],value_vars=['0','1','accuracy','macro avg','weighted avg'])\n",
    "\n",
    "    cr_df=cr_df.loc[cr_df.metric!=\"support\"]\n",
    "    cr_df=cr_df.loc[~((cr_df.variable==\"accuracy\") & (cr_df.metric.isin(['precision','recall'])))]\n",
    "\n",
    "    cr_df=cr_df.assign(variable=np.where(cr_df.variable=='0','negative',\n",
    "                                        np.where(cr_df.variable=='1','positive',cr_df.variable)))\n",
    "\n",
    "    cr_df=cr_df.assign(value=cr_df.value.apply(lambda x:round(x,4)*100))\n",
    "    return cr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae2ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_results(df_predictions,df_labeled):\n",
    "    df_labeled=df_labeled.assign(prediction=df_labeled.label)\n",
    "    df_predictions=pd.concat([df_predictions,df_labeled])\n",
    "    total_positives=df_predictions.loc[df_predictions.prediction==1]\n",
    "    total_negatives=df_predictions.loc[df_predictions.prediction==0]\n",
    "    total_negatives=total_negatives.loc[:,['ID','title','abstract','url','year','title_abstract']]\n",
    "    total_negatives=total_negatives.assign(label=0)\n",
    "    total_positives=total_positives.loc[:,['ID','title','abstract','url','year','title_abstract']]\n",
    "    total_positives=total_positives.assign(label=1)\n",
    "    return total_positives,total_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f30f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df_test_final,trainer,threshold=0.5):\n",
    "    \"\"\"Get predictions\n",
    "\n",
    "    Parameters:\n",
    "    df_test_final (df): dataframe with text for predictions\n",
    "    trainer: Trainer with all the configurations\n",
    "    Returns:\n",
    "    dataset_test_final_pd\n",
    "    \"\"\"\n",
    "    dataset_test_final = Dataset.from_pandas(df_test_final)\n",
    "    tokenized_datasets_test_final = dataset_test_final.map(tokenize_function, batched=True)\n",
    "\n",
    "    test_results_final = trainer.predict(tokenized_datasets_test_final)\n",
    "    preds_final=[]\n",
    "    for e in test_results_final.predictions:\n",
    "        preds_final.append(np.array(torch.softmax(torch.Tensor(e), dim=0)))\n",
    "\n",
    "    preds_final=np.vstack(preds_final)\n",
    "    dataset_test_final_pd=tokenized_datasets_test_final.data.to_pandas()\n",
    "\n",
    "    dataset_test_final_pd=dataset_test_final_pd.assign(proba0=preds_final[:,0])\n",
    "    dataset_test_final_pd=dataset_test_final_pd.assign(proba1=preds_final[:,1])\n",
    "    dataset_test_final_pd=dataset_test_final_pd.assign(prediction=np.where(dataset_test_final_pd.proba1>threshold,1,0))\n",
    "    return dataset_test_final_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb742c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"../../data/\"\n",
    "outputs_path=\"../../outputs/\"\n",
    "## READ DATA\n",
    "workshops=pd.read_csv(data_path+\"others/sg_workshops_v3.csv\")\n",
    "keywords=pd.read_csv(data_path+\"others/sg_keywords_v6.csv\")\n",
    "## text info of the dataset (it is more complete since it was extracted directly from the pdfs)\n",
    "\n",
    "## annotated test dataset\n",
    "df_test_final=pd.read_csv(outputs_path+\"general/test_set_final.csv\")\n",
    "df_dev_final=pd.read_csv(outputs_path+\"general/dev_set_final.csv\")\n",
    "\n",
    "df_unused=pd.read_csv(outputs_path+\"sg_classifier/weakly_labeled_unused_bronze_title_15pct_f.csv\")\n",
    "df_unlabeled=pd.read_csv(outputs_path+\"sg_classifier/unlabeled_set_bronze_title_15pct_f.csv\")\n",
    "df_unused=df_unused.assign(text=df_unused.title_abstract)\n",
    "df_unlabeled=df_unlabeled.assign(text=df_unlabeled.title_abstract)\n",
    "\n",
    "df_labeled=pd.read_csv(outputs_path+\"sg_classifier/train_set_labeled_bronze_title_15pct_f.csv\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./model_scibert/\", num_labels=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3439ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict test dataset\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"./model_scibert/\", evaluation_strategy=\"epoch\",\n",
    "                                 per_device_train_batch_size=16,per_device_eval_batch_size=16,\n",
    "                                 seed=42,num_train_epochs=5,auto_find_batch_size=True,\n",
    "                                     do_train = False,do_predict = True)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ebd76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_general=pd.concat([df_unused,df_unlabeled]).reset_index(drop=True)\n",
    "\n",
    "df_general.label=df_general.label.fillna(0)\n",
    "\n",
    "df_general.label=df_general.label.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e1c8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37644, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_general.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c901bac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cce77711444025a41cd31d9f3b69f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: abstract, ID, text, title_abstract, year, url, title. If abstract, ID, text, title_abstract, year, url, title are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 37644\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(37644, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions=evaluate(df_general,trainer,0.5)\n",
    "\n",
    "total_positives,total_negatives=get_all_results(df_predictions,df_labeled)\n",
    "#total_positives.to_csv(outputs_path+\"sg_classifier/all_positive_examples_final.csv\",index=False)\n",
    "#total_negatives.to_csv(outputs_path+\"sg_classifier/all_negative_examples_final.csv\",index=False)\n",
    "\n",
    "df_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd007784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8133, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_positives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41326b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e458b1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8449, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_positives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a53457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb2a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final=df_test_final.iloc[:2000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb293bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b49b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "#random_pred=np.random.uniform(0,1,df_test_final.shape[0])\n",
    "random_pred=np.random.choice([0, 1], size=(df_test_final.shape[0],), p=[0.5, 0.5])\n",
    "df_test_final['random_proba_1']=random_pred\n",
    "\n",
    "df_random=df_test_final.assign(prediction=np.where(df_test_final.random_proba_1>0.5,1,0))\n",
    "\n",
    "cr_random=get_report(df_random)\n",
    "\n",
    "#df_minority=df_test_final.assign(prediction=1)\n",
    "\n",
    "#cr_random=get_report(df_minority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65001cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>negative</td>\n",
       "      <td>83.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>negative</td>\n",
       "      <td>47.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>negative</td>\n",
       "      <td>60.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precision</td>\n",
       "      <td>positive</td>\n",
       "      <td>10.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recall</td>\n",
       "      <td>positive</td>\n",
       "      <td>39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>positive</td>\n",
       "      <td>16.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>46.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>precision</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>47.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recall</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>43.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>38.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>precision</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>74.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>46.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>54.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric      variable  value\n",
       "0   precision      negative  83.89\n",
       "1      recall      negative  47.67\n",
       "2    f1-score      negative  60.79\n",
       "4   precision      positive  10.27\n",
       "5      recall      positive  39.54\n",
       "6    f1-score      positive  16.30\n",
       "10   f1-score      accuracy  46.60\n",
       "12  precision     macro avg  47.08\n",
       "13     recall     macro avg  43.61\n",
       "14   f1-score     macro avg  38.55\n",
       "16  precision  weighted avg  74.21\n",
       "17     recall  weighted avg  46.60\n",
       "18   f1-score  weighted avg  54.94"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "424c783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "random_pred=np.random.choice([0, 1], size=(df_test_final.shape[0],), p=[0.9, 0.1])\n",
    "df_test_final['random_proba_1']=random_pred\n",
    "\n",
    "df_random=df_test_final.assign(prediction=np.where(df_test_final.random_proba_1>0.5,1,0))\n",
    "\n",
    "cr_random=get_report(df_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "167ac6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>negative</td>\n",
       "      <td>86.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>negative</td>\n",
       "      <td>89.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>negative</td>\n",
       "      <td>88.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precision</td>\n",
       "      <td>positive</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recall</td>\n",
       "      <td>positive</td>\n",
       "      <td>6.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>positive</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>78.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>precision</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>47.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recall</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>48.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>47.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>precision</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>76.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>78.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>77.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric      variable  value\n",
       "0   precision      negative  86.41\n",
       "1      recall      negative  89.69\n",
       "2    f1-score      negative  88.02\n",
       "4   precision      positive   9.14\n",
       "5      recall      positive   6.84\n",
       "6    f1-score      positive   7.83\n",
       "10   f1-score      accuracy  78.80\n",
       "12  precision     macro avg  47.77\n",
       "13     recall     macro avg  48.27\n",
       "14   f1-score     macro avg  47.92\n",
       "16  precision  weighted avg  76.25\n",
       "17     recall  weighted avg  78.80\n",
       "18   f1-score  weighted avg  77.48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c25b78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fc45f729f04581b4708d3c6b1407be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: abstract_clean, method_annotation, title, text, org_annotation, goal1_raw, year, task_annotation, url, abstract, title_clean, goal3_raw, acknowledgments_clean, ID, title_abstract_clean, goal2_raw. If abstract_clean, method_annotation, title, text, org_annotation, goal1_raw, year, task_annotation, url, abstract, title_clean, goal3_raw, acknowledgments_clean, ID, title_abstract_clean, goal2_raw are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 500\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results_dev=evaluate(df_dev_final,trainer,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29242018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 23)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0872b9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       437\n",
      "           1     0.1260    1.0000    0.2238        63\n",
      "\n",
      "    accuracy                         0.1260       500\n",
      "   macro avg     0.0630    0.5000    0.1119       500\n",
      "weighted avg     0.0159    0.1260    0.0282       500\n",
      "\n",
      "##########################\n",
      "0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9438    0.9611    0.9524       437\n",
      "           1     0.6909    0.6032    0.6441        63\n",
      "\n",
      "    accuracy                         0.9160       500\n",
      "   macro avg     0.8174    0.7821    0.7982       500\n",
      "weighted avg     0.9120    0.9160    0.9135       500\n",
      "\n",
      "##########################\n",
      "0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9420    0.9657    0.9537       437\n",
      "           1     0.7115    0.5873    0.6435        63\n",
      "\n",
      "    accuracy                         0.9180       500\n",
      "   macro avg     0.8268    0.7765    0.7986       500\n",
      "weighted avg     0.9129    0.9180    0.9146       500\n",
      "\n",
      "##########################\n",
      "0.15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9425    0.9748    0.9584       437\n",
      "           1     0.7708    0.5873    0.6667        63\n",
      "\n",
      "    accuracy                         0.9260       500\n",
      "   macro avg     0.8567    0.7811    0.8125       500\n",
      "weighted avg     0.9209    0.9260    0.9216       500\n",
      "\n",
      "##########################\n",
      "0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9404    0.9748    0.9573       437\n",
      "           1     0.7660    0.5714    0.6545        63\n",
      "\n",
      "    accuracy                         0.9240       500\n",
      "   macro avg     0.8532    0.7731    0.8059       500\n",
      "weighted avg     0.9184    0.9240    0.9192       500\n",
      "\n",
      "##########################\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9404    0.9748    0.9573       437\n",
      "           1     0.7660    0.5714    0.6545        63\n",
      "\n",
      "    accuracy                         0.9240       500\n",
      "   macro avg     0.8532    0.7731    0.8059       500\n",
      "weighted avg     0.9184    0.9240    0.9192       500\n",
      "\n",
      "##########################\n",
      "0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9405    0.9771    0.9585       437\n",
      "           1     0.7826    0.5714    0.6606        63\n",
      "\n",
      "    accuracy                         0.9260       500\n",
      "   macro avg     0.8616    0.7743    0.8095       500\n",
      "weighted avg     0.9206    0.9260    0.9209       500\n",
      "\n",
      "##########################\n",
      "0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9405    0.9771    0.9585       437\n",
      "           1     0.7826    0.5714    0.6606        63\n",
      "\n",
      "    accuracy                         0.9260       500\n",
      "   macro avg     0.8616    0.7743    0.8095       500\n",
      "weighted avg     0.9206    0.9260    0.9209       500\n",
      "\n",
      "##########################\n",
      "0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9405    0.9771    0.9585       437\n",
      "           1     0.7826    0.5714    0.6606        63\n",
      "\n",
      "    accuracy                         0.9260       500\n",
      "   macro avg     0.8616    0.7743    0.8095       500\n",
      "weighted avg     0.9206    0.9260    0.9209       500\n",
      "\n",
      "##########################\n",
      "0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9405    0.9771    0.9585       437\n",
      "           1     0.7826    0.5714    0.6606        63\n",
      "\n",
      "    accuracy                         0.9260       500\n",
      "   macro avg     0.8616    0.7743    0.8095       500\n",
      "weighted avg     0.9206    0.9260    0.9209       500\n",
      "\n",
      "##########################\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9405    0.9771    0.9585       437\n",
      "           1     0.7826    0.5714    0.6606        63\n",
      "\n",
      "    accuracy                         0.9260       500\n",
      "   macro avg     0.8616    0.7743    0.8095       500\n",
      "weighted avg     0.9206    0.9260    0.9209       500\n",
      "\n",
      "##########################\n",
      "0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9405    0.9771    0.9585       437\n",
      "           1     0.7826    0.5714    0.6606        63\n",
      "\n",
      "    accuracy                         0.9260       500\n",
      "   macro avg     0.8616    0.7743    0.8095       500\n",
      "weighted avg     0.9206    0.9260    0.9209       500\n",
      "\n",
      "##########################\n",
      "0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9364    0.9771    0.9563       437\n",
      "           1     0.7727    0.5397    0.6355        63\n",
      "\n",
      "    accuracy                         0.9220       500\n",
      "   macro avg     0.8546    0.7584    0.7959       500\n",
      "weighted avg     0.9158    0.9220    0.9159       500\n",
      "\n",
      "##########################\n",
      "0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9364    0.9771    0.9563       437\n",
      "           1     0.7727    0.5397    0.6355        63\n",
      "\n",
      "    accuracy                         0.9220       500\n",
      "   macro avg     0.8546    0.7584    0.7959       500\n",
      "weighted avg     0.9158    0.9220    0.9159       500\n",
      "\n",
      "##########################\n",
      "0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9365    0.9794    0.9575       437\n",
      "           1     0.7907    0.5397    0.6415        63\n",
      "\n",
      "    accuracy                         0.9240       500\n",
      "   macro avg     0.8636    0.7595    0.7995       500\n",
      "weighted avg     0.9182    0.9240    0.9177       500\n",
      "\n",
      "##########################\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9365    0.9794    0.9575       437\n",
      "           1     0.7907    0.5397    0.6415        63\n",
      "\n",
      "    accuracy                         0.9240       500\n",
      "   macro avg     0.8636    0.7595    0.7995       500\n",
      "weighted avg     0.9182    0.9240    0.9177       500\n",
      "\n",
      "##########################\n",
      "0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9345    0.9794    0.9564       437\n",
      "           1     0.7857    0.5238    0.6286        63\n",
      "\n",
      "    accuracy                         0.9220       500\n",
      "   macro avg     0.8601    0.7516    0.7925       500\n",
      "weighted avg     0.9158    0.9220    0.9151       500\n",
      "\n",
      "##########################\n",
      "0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9304    0.9794    0.9543       437\n",
      "           1     0.7750    0.4921    0.6019        63\n",
      "\n",
      "    accuracy                         0.9180       500\n",
      "   macro avg     0.8527    0.7357    0.7781       500\n",
      "weighted avg     0.9108    0.9180    0.9099       500\n",
      "\n",
      "##########################\n",
      "0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9306    0.9817    0.9555       437\n",
      "           1     0.7949    0.4921    0.6078        63\n",
      "\n",
      "    accuracy                         0.9200       500\n",
      "   macro avg     0.8627    0.7369    0.7816       500\n",
      "weighted avg     0.9135    0.9200    0.9117       500\n",
      "\n",
      "##########################\n",
      "0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9247    0.9840    0.9534       437\n",
      "           1     0.8000    0.4444    0.5714        63\n",
      "\n",
      "    accuracy                         0.9160       500\n",
      "   macro avg     0.8624    0.7142    0.7624       500\n",
      "weighted avg     0.9090    0.9160    0.9053       500\n",
      "\n",
      "##########################\n"
     ]
    }
   ],
   "source": [
    "best_threshold=0.5\n",
    "best_f1=0\n",
    "#for p in [0,0.01,0.02,0.03,0.04,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.96,0.97,0.98,0.99,0.999,0.9999,0.99999,0.9999999]:\n",
    "for p in [0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95]:\n",
    "    df_analyze=df_results_dev.assign(prediction2=np.where(df_results_dev.proba1>p,1,0))\n",
    "    f1=classification_report(df_analyze.label,df_analyze.prediction2,digits=4,output_dict=True)['1']['f1-score']\n",
    "    if f1>best_f1:\n",
    "        best_f1=f1\n",
    "        best_threshold=p\n",
    "    print(p)\n",
    "    print(classification_report(df_analyze.label,df_analyze.prediction2,digits=4))\n",
    "    print(\"##########################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86c183b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0203bfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "691a2efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdcc7520ae94a909c3aa8025466e3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: abstract_clean, method_annotation, title, text, org_annotation, goal1_raw, random_proba_1, year, task_annotation, url, abstract, title_clean, goal3_raw, acknowledgments_clean, ID, title_abstract_clean, goal2_raw. If abstract_clean, method_annotation, title, text, org_annotation, goal1_raw, random_proba_1, year, task_annotation, url, abstract, title_clean, goal3_raw, acknowledgments_clean, ID, title_abstract_clean, goal2_raw are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results=evaluate(df_test_final,trainer,best_threshold)\n",
    "\n",
    "cr_final=get_report(df_results)\n",
    "cr_final=cr_final.rename(columns={'value':'Fine tuned BERT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36c1a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9447    0.9741    0.9592      1737\n",
      "           1     0.7847    0.6236    0.6949       263\n",
      "\n",
      "    accuracy                         0.9280      2000\n",
      "   macro avg     0.8647    0.7988    0.8270      2000\n",
      "weighted avg     0.9237    0.9280    0.9244      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gold\n",
    "print(best_threshold)\n",
    "print(best_f1)\n",
    "print(classification_report(df_results.label,df_results.prediction,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2daf92d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.6721311475409837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9513    0.9551    0.9532      1737\n",
      "           1     0.6953    0.6768    0.6859       263\n",
      "\n",
      "    accuracy                         0.9185      2000\n",
      "   macro avg     0.8233    0.8160    0.8196      2000\n",
      "weighted avg     0.9176    0.9185    0.9180      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gold\n",
    "print(best_threshold)\n",
    "print(best_f1)\n",
    "print(classification_report(df_results.label,df_results.prediction,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "351fdb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.7924528301886793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9461    0.9902    0.9677      1737\n",
      "           1     0.9066    0.6274    0.7416       263\n",
      "\n",
      "    accuracy                         0.9425      2000\n",
      "   macro avg     0.9263    0.8088    0.8546      2000\n",
      "weighted avg     0.9409    0.9425    0.9379      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#silver_keytitle_15pct_f\n",
    "print(best_threshold)\n",
    "print(best_f1)\n",
    "print(classification_report(df_results.label,df_results.prediction,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c813d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.7924528301886793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9441    0.9925    0.9677      1737\n",
      "           1     0.9253    0.6122    0.7368       263\n",
      "\n",
      "    accuracy                         0.9425      2000\n",
      "   macro avg     0.9347    0.8023    0.8523      2000\n",
      "weighted avg     0.9417    0.9425    0.9374      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#silver_keytitle_15pct_f\n",
    "print(best_threshold)\n",
    "print(best_f1)\n",
    "print(classification_report(df_results.label,df_results.prediction,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12c5bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.7826086956521738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9525    0.9816    0.9668      1737\n",
      "           1     0.8476    0.6768    0.7526       263\n",
      "\n",
      "    accuracy                         0.9415      2000\n",
      "   macro avg     0.9001    0.8292    0.8597      2000\n",
      "weighted avg     0.9387    0.9415    0.9387      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#bronze\n",
    "print(best_threshold)\n",
    "print(best_f1)\n",
    "print(classification_report(df_results.label,df_results.prediction,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eaa19cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.7826086956521738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9525    0.9822    0.9671      1737\n",
      "           1     0.8517    0.6768    0.7542       263\n",
      "\n",
      "    accuracy                         0.9420      2000\n",
      "   macro avg     0.9021    0.8295    0.8607      2000\n",
      "weighted avg     0.9393    0.9420    0.9391      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#bronze\n",
    "print(best_threshold)\n",
    "print(best_f1)\n",
    "print(classification_report(df_results.label,df_results.prediction,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad3e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd585c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d84bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfaaa574",
   "metadata": {},
   "source": [
    "## Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6edcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=df_results.assign(goal1=np.where(df_results['goal1_raw'].str.lower().str.contains(\"education\"),'Quality Education',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"poverty\"),'No Poverty',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"hunger\"),'Zero Hunger',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"clean_water\"),'Clean Water and Sanitation',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"clean_energy\"),'Affordable and Clean Energy',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"life_land\"),'Life on Land',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"marine_life\"),'Life Below Water',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"health\"),'Good Health and Well-Being',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"climate\"),'Climate Action',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"peace|privacy|disinformation_and_fake_news|deception|hate\"),'Peace, Justice and Strong Institutions',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"social biases|race & identity\"),'Reduced Inequalities',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"industry|innovation|research\"),'Industry, Innovation and Infrastructure',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"sustainable cities|sustainable_cities\"),'Sustainable Cities and Communities',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"gender\"),'Gender Equality',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"decent work|decent_work_and_economy\"),'Decent Work and Economic Growth',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"partnership\"),'Partnership for the goals',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"responsible_consumption_and_production\"),'Responsible Consumption and Production',\n",
    "                    np.where(df_results['goal1_raw'].str.lower().str.contains(\"reduced|social_equality\"),'Reduced Inequalities',''\n",
    "                          )))))))))))))))))))\n",
    "\n",
    "df_results=df_results.assign(goal2=np.where(df_results['goal2_raw'].str.lower().str.contains(\"education\"),'Quality Education',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"poverty\"),'No Poverty',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"hunger\"),'Zero Hunger',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"clean_water\"),'Clean Water and Sanitation',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"clean_energy\"),'Affordable and Clean Energy',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"life_land\"),'Life on Land',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"marine_life\"),'Life Below Water',         \n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"health\"),'Good Health and Well-Being',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"climate\"),'Climate Action',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"peace|privacy|disinformation_and_fake_news|deception|hate\"),'Peace, Justice and Strong Institutions',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"social biases|race & identity\"),'Reduced Inequalities',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"industry|innovation|research\"),'Industry, Innovation and Infrastructure',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"sustainable cities|sustainable_cities\"),'Sustainable Cities and Communities',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"gender\"),'Gender Equality',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"decent work|decent_work_and_economy\"),'Decent Work and Economic Growth',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"partnership\"),'Partnership for the goals',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"responsible_consumption_and_production\"),'Responsible Consumption and Production',\n",
    "                    np.where(df_results['goal2_raw'].str.lower().str.contains(\"reduced|social_equality\"),'Reduced Inequalities',''\n",
    "                          )))))))))))))))))))\n",
    "\n",
    "df_results=df_results.assign(goal3=np.where(df_results['goal3_raw'].str.lower().str.contains(\"education\"),'Quality Education',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"poverty\"),'No Poverty',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"hunger\"),'Zero Hunger',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"clean_water\"),'Clean Water and Sanitation',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"clean_energy\"),'Affordable and Clean Energy',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"life_land\"),'Life on Land',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"marine_life\"),'Life Below Water',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"health\"),'Good Health and Well-Being',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"climate\"),'Climate Action',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"peace|privacy|disinformation_and_fake_news|deception|hate\"),'Peace, Justice and Strong Institutions',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"social biases|race & identity\"),'Reduced Inequalities',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"industry|innovation|research\"),'Industry, Innovation and Infrastructure',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"sustainable cities|sustainable_cities\"),'Sustainable Cities and Communities',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"gender\"),'Gender Equality',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"decent work|decent_work_and_economy\"),'Decent Work and Economic Growth',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"partnership\"),'Partnership for the goals',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"responsible_consumption_and_production\"),'Responsible Consumption and Production',\n",
    "                    np.where(df_results['goal3_raw'].str.lower().str.contains(\"reduced|social_equality\"),'Reduced Inequalities',''\n",
    "                          )))))))))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0876792",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong=df_results.loc[(df_results.proba1<=0.5) & (df_results.label==1)].sort_values('proba1',ascending=False).copy()\n",
    "\n",
    "wrong_fp=df_results.loc[(df_results.proba1>0.5) & (df_results.label==0)].sort_values('proba1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89f87fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_fp=df_results.loc[(df_results.proba1>0.5) & (df_results.label==0)].sort_values('proba1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bc17680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.loc[df_results.label==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3b5f3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           6.511364\n",
       "Peace, Justice and Strong Institutions     0.291667\n",
       "Good Health and Well-Being                 0.265152\n",
       "Quality Education                          0.208333\n",
       "Industry, Innovation and Infrastructure    0.094697\n",
       "Decent Work and Economic Growth            0.087121\n",
       "Reduced Inequalities                       0.060606\n",
       "Gender Equality                            0.034091\n",
       "Partnership for the goals                  0.022727\n",
       "Name: goal1, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['goal1'].value_counts()/df_results.loc[df_results.label==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9c1a0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quality Education                          0.303371\n",
       "Industry, Innovation and Infrastructure    0.202247\n",
       "Peace, Justice and Strong Institutions     0.191011\n",
       "Decent Work and Economic Growth            0.123596\n",
       "Good Health and Well-Being                 0.101124\n",
       "Partnership for the goals                  0.056180\n",
       "Reduced Inequalities                       0.022472\n",
       "Name: goal1, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong['goal1'].value_counts()/wrong.loc[df_results.label==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3adaf958",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           1719\n",
       "Peace, Justice and Strong Institutions       77\n",
       "Good Health and Well-Being                   70\n",
       "Quality Education                            55\n",
       "Industry, Innovation and Infrastructure      25\n",
       "Decent Work and Economic Growth              23\n",
       "Reduced Inequalities                         16\n",
       "Gender Equality                               9\n",
       "Partnership for the goals                     6\n",
       "Name: goal1, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['goal1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7758bee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quality Education                          27\n",
       "Industry, Innovation and Infrastructure    18\n",
       "Peace, Justice and Strong Institutions     17\n",
       "Decent Work and Economic Growth            11\n",
       "Good Health and Well-Being                  9\n",
       "Partnership for the goals                   5\n",
       "Reduced Inequalities                        2\n",
       "Name: goal1, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong['goal1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45be9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "most_common=Counter(\" \".join(df_results[\"text\"].str.lower()).split()).most_common(60)\n",
    "\n",
    "common=set()\n",
    "for e,c in most_common:\n",
    "    common.add(e)\n",
    "\n",
    "\n",
    "wrong_common_fp=Counter(\" \".join(wrong_fp[\"text\"]).split()).most_common(60)\n",
    "\n",
    "wr_common_fp=set()\n",
    "for e,c in wrong_common_fp:\n",
    "    wr_common_fp.add(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b763ce42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 168),\n",
       " ('and', 119),\n",
       " ('of', 117),\n",
       " ('a', 82),\n",
       " ('to', 60),\n",
       " ('in', 59),\n",
       " ('for', 46),\n",
       " ('that', 29),\n",
       " ('with', 27),\n",
       " ('is', 27),\n",
       " ('on', 25),\n",
       " ('we', 24),\n",
       " ('The', 23),\n",
       " ('We', 22),\n",
       " ('as', 22),\n",
       " ('by', 20),\n",
       " ('are', 20),\n",
       " ('this', 18),\n",
       " ('an', 17),\n",
       " ('our', 15),\n",
       " ('from', 14),\n",
       " ('translation', 12),\n",
       " ('In', 11),\n",
       " ('A', 9),\n",
       " ('can', 9),\n",
       " ('which', 9),\n",
       " ('different', 9),\n",
       " ('Language', 8),\n",
       " ('paper', 8),\n",
       " ('have', 8),\n",
       " ('MT', 8),\n",
       " ('KD', 8),\n",
       " ('performance', 8),\n",
       " ('method', 7),\n",
       " ('show', 7),\n",
       " ('given', 7),\n",
       " ('how', 7),\n",
       " ('task', 7),\n",
       " ('system', 7),\n",
       " ('data', 7),\n",
       " ('use', 7),\n",
       " ('into', 7),\n",
       " ('between', 7),\n",
       " ('at', 7),\n",
       " ('social', 7),\n",
       " ('these', 6),\n",
       " ('results', 6),\n",
       " ('provide', 6),\n",
       " ('research', 6),\n",
       " ('approach', 6),\n",
       " ('or', 6),\n",
       " ('This', 6),\n",
       " ('be', 6),\n",
       " ('methods', 6),\n",
       " ('work', 6),\n",
       " ('propose', 6),\n",
       " ('error', 6),\n",
       " ('using', 5),\n",
       " ('their', 5),\n",
       " ('they', 5)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_common_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "350743b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'In',\n",
       " 'KD',\n",
       " 'Language',\n",
       " 'MT',\n",
       " 'The',\n",
       " 'This',\n",
       " 'We',\n",
       " 'error',\n",
       " 'given',\n",
       " 'how',\n",
       " 'into',\n",
       " 'method',\n",
       " 'methods',\n",
       " 'propose',\n",
       " 'provide',\n",
       " 'research',\n",
       " 'social',\n",
       " 'they',\n",
       " 'work'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wr_common_fp-common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bceaff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=df_results.loc[(df_results.proba1>=0.5) & (df_results.label==1)].sort_values('proba1',ascending=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d640353f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18285714285714286"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.loc[tp.text.str.contains('social')].shape[0]/tp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6481e9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0365"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.loc[df_results.text.str.contains('social')].shape[0]/df_results.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19cd0f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_fp.loc[wrong_fp.text.str.contains('social')].shape[0]/wrong_fp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47e5c25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"LIE: Leadership, Influence and Expertise. This paper describes our research into methods for inferring social and instrumental roles and relationships from document and discourse corpora. The goal is to identify the roles of initial authors and participants in internet discussions with respect to leadership, influence and expertise. Web documents, forums and blogs provide data from which the relationships between these concepts are empirically derived and compared. Using techniques from Natural Language Processing (NLP), characterizations of authority and expertise are hypothesized and then tested to see if these pick out the same or different participants as may be chosen by techniques based on social network analysis (Huffaker 2010) see if they pick out the same discourse participants for any given level of these qualities (i.e. leadership, expertise and influence). Our methods could be applied, in principle, to any domain topic, but this paper will describe an initial investigation into two subject areas where a range of differing opinions are available and which differ in the nature of their appeals to authority and truth: 'genetic engineering' and a 'Muslim Forum'. The available online corpora for these topics contain discussions from a variety of users with different levels of expertise, backgrounds and personalities.\",\n",
       "       \"Sentiment, Subjectivity, and Social Analysis Go ToWork: An Industry View - Invited Talk. Seth Grimes Alta Plana Corporation grimes@altaplana.com\\nAffective computing has a commercial side. Numerous products and projects provide sentiment, emotion, and intent extraction capabilities, applied in consumer and financial markets, for healthcare and customer care, and for media, policy, and politics. Academic and industry researchers are naturally interested how sentiment and social technologies are being applied and in commercial market opportunities and trends, in what's being funded, what's falling flat, and what's on business's roadmap. Analyst Seth Grimes will provide an industry overview, surveying companies and applications in the sentiment and social analytics spaces as well as work at the tech giants. He will discuss commercialization strategy and the affective market outlook.\",\n",
       "       'The Road to Success: Assessing the Fate of Linguistic Innovations in Online Communities. We investigate the birth and diffusion of lexical innovations in a large dataset of online social communities. We build on sociolinguistic theories and focus on the relation between the spread of a novel term and the social role of the individuals who use it, uncovering characteristics of innovators and adopters. Finally, we perform a prediction task that allows us to anticipate whether an innovation will successfully spread within a community.',\n",
       "       'Meaning and Discourse - A Computer Model of Psychoanalytic Speech and Cognition. Colby, and Schank; he offers homage to HACKER and kudos to CONNIVER; he ignores both linguistics and AI work in natural-language generation; he invents a grammar of English; he performs validation tests on a hand-simulated program; and he closes by warning us about ignoring the social impact of computers in the future. All of this is background to a program that models one, halting paragraph of speech by a depressed patient whose request to change the form in which she pays her therapist is, we are told in great detail, a desire for intercourse.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_fp.loc[wrong_fp.text.str.contains('social')].text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6239dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if args.option=='0':\n",
    "    df_results=evaluate(df_test_final,trainer)\n",
    "    df_results=df_results.merge(df_lan,how='left')\n",
    "    df_results=df_results.loc[df_results.lan=='en',:]\n",
    "    cr_final=get_report(df_results)\n",
    "    cr_final=cr_final.rename(columns={'value':'Fine tuned BERT'})\n",
    "    cr_final.to_csv(outputs_path+\"sg_classifier/scores_bert.csv\",index=False)\n",
    "elif args.option=='1':\n",
    "    df_test_final=df_test_final.merge(df_lan,how='left')\n",
    "    df_test_final=df_test_final.loc[df_test_final.lan=='en',:]\n",
    "    df_results=evaluate(df_test_final,trainer)\n",
    "    df_rules=get_rules_classifier(df_test_final,match_unique,keywords,workshops)\n",
    "    df_unlabeled=evaluate(df_unlabeled,trainer)\n",
    "\n",
    "    total_positives,total_negatives=get_all_results(df_unused_positive,df_labeled,df_unlabeled)\n",
    "    total_positives.to_csv(outputs_path+\"sg_classifier/all_positive_examples.csv\",index=False)\n",
    "    total_negatives.to_csv(outputs_path+\"sg_classifier/all_negative_examples.csv\",index=False)\n",
    "\n",
    "    cr_model=get_report(df_results)\n",
    "    cr_df_rules=get_report(df_rules)\n",
    "    cr_df_rules=cr_df_rules.rename(columns={'value':'Rules classifier'})\n",
    "    cr_model=cr_model.rename(columns={'value':'Fine tuned BERT'})\n",
    "    cr_final=cr_model.merge(cr_df_rules,on=['metric','variable'])\n",
    "    cr_final.to_csv(outputs_path+\"sg_classifier/scores.csv\",index=False)\n",
    "\n",
    "print(cr_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72137bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(add_help=True)\n",
    "    parser.add_argument('-o','--option', nargs='?', help='1 for full results, 0 evaluate only test set',default='1')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89f792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
