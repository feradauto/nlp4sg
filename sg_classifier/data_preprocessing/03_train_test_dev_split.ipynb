{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4f3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7d11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_abstract=['korhonen-2002-assigning', 'pusateri-glass-2004-modeling',\n",
    "       'castillo-etal-2004-talp', 'claveau-sebillot-2004-efficiency','vauquois-etal-1965-syntaxe',\n",
    "       'webster-1994-building', 'patrick-etal-2002-slinerc','kipper-etal-2004-using',\n",
    "       'korhonen-preiss-2003-improving', 'hui-2002-measuring','engel-etal-2002-parsing',\n",
    "       'blache-2003-meta', 'bechet-etal-2000-tagging','purver-etal-2001-means','elenko-etal-2004-coreference',\n",
    "       'kim-etal-2000-phrase','pirrelli-battista-1996-monotonic','russell-1976-computer',\n",
    "       'purver-2002-processing','simmons-bennett-novak-1975-semantically',\n",
    "       'mori-2002-information', 'habash-dorr-2001-large','bilgram-keson-1998-construction',\n",
    "       'seneff-polifroni-2001-hypothesis', 'johnson-1997-personal','ferragne-etal-2012-rocme'\n",
    "       'hovy-2002-building', 'schiehlen-2004-annotation','nn-1977-finite-string-volume-14-number-7',\n",
    "       'zelenko-etal-2002-kernel', 'suzuki-etal-2002-topic','von-glasersfeld-1974-yerkish',\n",
    "       'murata-etal-2001-using', 'bilac-tanaka-2004-hybrid','tseng-etal-2021-aspect',\n",
    "       'nightingale-tanaka-2003-comparing','shapiro-1975-generation',\n",
    "       'yangarber-etal-2002-unsupervised', 'lee-bryant-2002-contextual','lin-etal-2006-information',\n",
    "       'dong-1990-transtar', 'lager-1998-logic','ipper-etal-2004-using','yamabana-etal-2000-lexicalized',\n",
    "       'takeuchi-etal-2004-construction', 'freitag-2004-toward','shudo-etal-2000-collocations',\n",
    "       'ueffing-etal-2002-generation', 'munteanu-etal-2004-improved','hajicova-kucerova-2002-argument',\n",
    "       'forbes-webber-2002-semantic', 'foret-nir-2002-rigid','moschitti-2010-kernel','von-glasersfeld-1974-yerkish',\n",
    "            'lin-etal-2006-information',\n",
    "        'navigli-velardi-2002-automatic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e238959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(df_test_final,anthology):\n",
    "    \"\"\"Format test dataset\n",
    "\n",
    "    Parameters:\n",
    "    df_test_final (df): Test dataset \n",
    "    anthology (df): Dataframe with all papers information\n",
    "    Returns:\n",
    "    df_test_final\n",
    "    \"\"\"\n",
    "    df_test_final=df_test_final.rename(columns={\"Zhijing's annotation of SG_or_not\":\"label\"})\n",
    "    df_test_final[\"label\"]=df_test_final[\"label\"].fillna(0)\n",
    "    df_test_final=df_test_final.loc[:,['ID','url','label','task_annotation','method_annotation','org_annotation','Most Related SG goal',\n",
    "       '(if exists) 2nd Related SG Goal', '(if exists) 3rd Related SG Goal']]\n",
    "    anthology=anthology.assign(acknowledgments=anthology.acknowledgments.fillna(''))\n",
    "    anthology=anthology.assign(abstract=anthology.abstract.fillna(''))\n",
    "    anthology=anthology.assign(title_clean=anthology.title.replace(\"{\",\"\",regex=True).replace(\"}\",\"\",regex=True))\n",
    "    anthology=anthology.assign(abstract_clean=anthology.abstract.replace(\"{\",\"\",regex=True).replace(\"}\",\"\",regex=True))\n",
    "    anthology=anthology.assign(acknowledgments_clean=anthology.acknowledgments.replace(\"{\",\"\",regex=True).replace(\"}\",\"\",regex=True))\n",
    "    anthology=anthology.assign(title_abstract_clean=anthology.title_clean+\". \"+anthology.abstract_clean)\n",
    "    anthology=anthology.loc[:,['ID','title_abstract_clean','title','abstract','title_clean','abstract_clean','acknowledgments_clean']]\n",
    "    df_test_final=df_test_final.merge(anthology,on=['ID'])\n",
    "    df_test_final=df_test_final.assign(text=df_test_final.title_abstract_clean)\n",
    "    df_test_final=df_test_final.loc[~df_test_final.label.isna()]\n",
    "    df_test_final.label=df_test_final.label.apply(int)\n",
    "    return df_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506189b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_papers(df_test_final,df_lan_all,df_lan):\n",
    "\n",
    "    ## just english papers\n",
    "    df_test_final=df_test_final.merge(df_lan,how='left')\n",
    "    df_test_final=df_test_final.loc[(df_test_final.lan=='en') | (df_test_final.lan.isna()),:]\n",
    "\n",
    "    df_lan_all=df_lan_all.rename(columns={'lan':'lang_all'})\n",
    "    df_test_final=df_test_final.merge(df_lan_all,how='left')\n",
    "    df_test_final=df_test_final.loc[(df_test_final.lang_all=='en') | (df_test_final.lang_all.isna()),:]\n",
    "\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.lower().str.startswith('book review')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.lower().str.startswith('copyright information')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.lower().str.startswith('session')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.lower().str.startswith('transcript')]\n",
    "\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.lower().str.startswith('(invited presentation)')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.lower().str.startswith('program of the')]\n",
    "\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.contains('\\[In Chinese\\].')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.contains('\\[In French\\].')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.contains('\\[In Portuguese\\].')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.contains('\\[In Spanish\\].')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.contains('Author Index: Volumes')]\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.str.contains('Author Index: Volume')]\n",
    "\n",
    "    df_test_final=df_test_final.loc[~df_test_final.text.isin([\n",
    "        \"語料庫為本的語義訊息抽取與辨析以近義詞研究為例 (Synonym Discrimination Based on Corpus) [In Chinese]. \",\n",
    "        \"台灣共通語言 (Taiwan Common Language) [In Chinese]. \",\n",
    "        \"American Journal of Computational Linguistics (February 1976). \",\n",
    "        \"Author Index: Volumes 6-19. \",\n",
    "        \"基於訊息配對相似度估計的聊天記錄解構(Chat Log Disentanglement based on Message Pair Similarity Estimation). \",\n",
    "        \"基於BERT模型之多國語言機器閱讀理解研究(Multilingual Machine Reading Comprehension based on BERT Model). \",\n",
    "        \"An Introduction to MT. \",\n",
    "        \"Author and Keyword Index. \",\n",
    "        \"CITAC Computer, Inc.. \",\n",
    "        \"American Journal of Computational Linguistics (September 1975). \",\n",
    "        \"ACL in 1977. \",\n",
    "        \"Summary of Session 7 -- Natural Language (Part 2). \",\n",
    "        \"25th Annual Meeting of the Association for Computational Linguistics. \"\n",
    "    ])]\n",
    "\n",
    "    df_test_final=df_test_final.reset_index(drop=True)\n",
    "    return df_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad039f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_path=\"../../data/\"\n",
    "    outputs_path=\"../../outputs/\"\n",
    "\n",
    "    df=pd.read_csv(data_path+\"test_data/test_set_SG_annotate_5k2_gold_new_annot.csv\")\n",
    "    anthology_test=pd.read_csv(data_path+\"test_data/papers_test_set_ack.csv\")\n",
    "    df_lan_all=pd.read_csv(outputs_path+\"general/test_set_5k2_languages.csv\")\n",
    "    match_unique=pd.read_csv(outputs_path+\"general/papers_uniques.csv\")\n",
    "    df_lan=pd.read_csv(outputs_path+\"general/test_set_language.csv\")\n",
    "    \n",
    "    anthology_test=anthology_test.assign(abstract=np.where(anthology_test.ID.isin(no_abstract),\"\",anthology_test.abstract))\n",
    "\n",
    "    df_test_final=process_dataset(df,anthology_test)\n",
    "\n",
    "    df_year=match_unique.loc[:,['ID','year']]\n",
    "\n",
    "    df_test_final=df_test_final.merge(df_year,on=['ID'])\n",
    "\n",
    "    df_test_final=filter_papers(df_test_final,df_lan_all,df_lan)\n",
    "\n",
    "    df_test_final=df_test_final.loc[:,df_test_final.columns[:-2]]\n",
    "\n",
    "    df_test_final=df_test_final.rename(columns={'Most Related SG goal':'goal1_raw',\n",
    "           '(if exists) 2nd Related SG Goal':'goal2_raw', '(if exists) 3rd Related SG Goal':'goal3_raw'})\n",
    "\n",
    "    test_set=df_test_final.loc[:2087].copy()\n",
    "    dev_set=df_test_final.loc[2088:2587].copy()\n",
    "    train_set=df_test_final.loc[2588:].copy()\n",
    "\n",
    "    test_set.to_csv(outputs_path+\"general/test_set_final.csv\",index=False)\n",
    "    train_set.to_csv(outputs_path+\"general/train_set_final.csv\",index=False)\n",
    "    dev_set.to_csv(outputs_path+\"general/dev_set_final.csv\",index=False)    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e69a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
