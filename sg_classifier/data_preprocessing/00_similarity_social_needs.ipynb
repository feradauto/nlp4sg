{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a32b877",
   "metadata": {},
   "source": [
    "## Overview of how well papers' topics match social needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7dce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 01:51:19.931545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/gcc-6.3.0/openblas-0.2.20-cot3cawsqf4pkxjwzjexaykbwn2ch3ii/lib:/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64:/cluster/spack/apps/linux-centos7-x86_64/gcc-4.8.5/gcc-6.3.0-sqhtfh32p5gerbkvi5hih7cfvcpmewvj/lib64:/cluster/spack/apps/linux-centos7-x86_64/gcc-4.8.5/gcc-6.3.0-sqhtfh32p5gerbkvi5hih7cfvcpmewvj/lib:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib\n",
      "2022-06-21 01:51:19.931589: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0352fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dfs(df,social_needs):\n",
    "    \"\"\"format input dataframes\n",
    "\n",
    "    Parameters:\n",
    "    df (df): Dataframe with papers information\n",
    "    social_needs (df): Dataframes with social needs\n",
    "    Returns:\n",
    "    Dataframes \n",
    "\n",
    "   \"\"\"\n",
    "    social_needs_list=social_needs.loc[:,['Goal']]\n",
    "\n",
    "    df=df.loc[:,['ID','title','abstract','year']]\n",
    "\n",
    "    ## remove not relevant rows\n",
    "    repeated=df.title.value_counts().reset_index().rename(columns={'title':'counts','index':'title'})\n",
    "\n",
    "    repeated=repeated.loc[repeated.counts>2]\n",
    "    df=df.loc[~df.title.isin(repeated.title.unique())]\n",
    "\n",
    "    df=df.assign(abstract=df.abstract.fillna(''))\n",
    "\n",
    "    df=df.assign(title_abstract=df.title+\" \"+df.abstract)\n",
    "\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "    social_needs_melted=pd.melt(social_needs,id_vars=['Goal','Goal_Desc'],value_vars=social_needs.columns[2:],var_name=['Target'],value_name='Target_Desc')\n",
    "\n",
    "    social_needs_melted=social_needs_melted.loc[~social_needs_melted['Target_Desc'].isna()]\n",
    "\n",
    "    social_needs=social_needs.loc[:,['Goal','Goal_Desc']]\n",
    "\n",
    "    social_needs=social_needs.assign(social_need=social_needs.Goal+\" \"+social_needs.Goal_Desc)\n",
    "\n",
    "    df=df.reset_index().rename(columns={'index':'row_id'})\n",
    "    social_needs=social_needs.reset_index().rename(columns={'index':'social_id'})\n",
    "    \n",
    "    return (df,social_needs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459f39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarities(df,social_needs):\n",
    "    \"\"\"Get cosine similarities between 2 dfs\n",
    "\n",
    "    Parameters:\n",
    "    df (df): Dataframe with papers information\n",
    "    social_needs (df): Dataframes with social needs\n",
    "    Returns:\n",
    "    dataframe with cosine similarity \n",
    "\n",
    "   \"\"\"\n",
    "\n",
    "    model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
    "\n",
    "    embeddings_abstract = model.encode(df.title_abstract)\n",
    "    embeddings_social = model.encode(social_needs.social_need)\n",
    "\n",
    "    df_merged=df.merge(social_needs,how=\"cross\")\n",
    "\n",
    "    for i,d in df_merged.iterrows():\n",
    "        similarity=cosine_similarity([embeddings_abstract[d['row_id']]],[embeddings_social[d['social_id']]])[0][0]\n",
    "        df_merged.loc[i,['cosine_similarity']]=similarity\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e3cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_match(df_merged):\n",
    "\n",
    "    df_merged['words']=df_merged['title_abstract'].str.split().str.len()\n",
    "    ## remove entries that are not normal papers\n",
    "    df_merged_filtered=df_merged.loc[df_merged.words>1]\n",
    "    df_merged_filtered=df_merged_filtered.loc[~df_merged_filtered.title_abstract.str.lower().str.contains('proceedings of|international workshop on|international conference on|international journal of computational|workshop on|summary of discussion|summary of the discussion|title index: volume|minutes of the')]\n",
    "    df_merged_filtered=df_merged_filtered.loc[~df_merged_filtered.title_abstract.str.lower().str.contains('conference on applied natural language processing|program committee|computational linguistics, volume|call for papers|reports from session chairs|{i}nternational {c}onference on|{u}niversity of {w}ashington presentation')]\n",
    "\n",
    "    match_unique=df_merged_filtered.sort_values('cosine_similarity',ascending=False).drop_duplicates(subset=['title_abstract'])\n",
    "    return match_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f2f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/project/sachan/fgonzalez/ie/lib64/python3.7/site-packages/ipykernel_launcher.py:15: DtypeWarning: Columns (17,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_path=\"../../data/\"\n",
    "    outputs_path=\"../../outputs/\"\n",
    "    df=pd.read_csv(data_path+\"papers/anthology.csv\")\n",
    "    social_needs=pd.read_csv(data_path+\"others/social_needs.csv\")\n",
    "    df,social_needs=format_dfs(df,social_needs)\n",
    "    #df_merged=get_similarities(df,social_needs)\n",
    "    #df_merged.to_csv(outputs_path+\"general/social_abstracts_cosine_clean.csv\",index=False)\n",
    "    df_merged=pd.read_csv(outputs_path+\"general/social_abstracts_cosine_clean.csv\")\n",
    "    match_unique=get_best_match(df_merged)\n",
    "    match_unique=match_unique.sample(frac=1,random_state=42)\n",
    "    match_unique.to_csv(outputs_path+\"general/papers_uniques.csv\",index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828627ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
