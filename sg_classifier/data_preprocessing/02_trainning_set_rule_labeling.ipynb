{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba7c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8c242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(train_set,test_set,keywords,workshops,acl_labeled,website_positive):\n",
    "    \"\"\"Label the dataset (social good or not) with a set of rules \n",
    "\n",
    "    Parameters:\n",
    "    train_set (df): Dataframe with papers information\n",
    "    test_set (df): Dataframe with papers information\n",
    "    keywords (df):\n",
    "    workshops (df):\n",
    "    acl_labeled (df): Labeled df with positive examples\n",
    "    website_positive (df): Labeled df with positive examples\n",
    "    Returns:\n",
    "    dataframe labeled for training,\n",
    "    dataframe with positive observations not in the train set\n",
    "    unlabeled dataset\n",
    "    \"\"\"\n",
    "    keywords=keywords.assign(Keywords=np.where(keywords.Keywords=='asl',' asl ',keywords.Keywords))\n",
    "    percentiles=train_set.cosine_similarity.describe(percentiles=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99]).reset_index()\n",
    "    perc_99=percentiles.loc[percentiles['index']==\"99%\"].cosine_similarity.values[0]\n",
    "\n",
    "    ## take positive examples from acl set\n",
    "    acl_labeled=acl_labeled.loc[~acl_labeled['social good domain'].isna()].reset_index(drop=True)\n",
    "    ## make sure it doesnt contain observations in the training set\n",
    "    acl_labeled=acl_labeled.loc[~acl_labeled.paper_name.isin(test_set.title)]\n",
    "    acl_labeled=acl_labeled.loc[:,['paper_name']]\n",
    "    acl_labeled_add=acl_labeled.loc[~acl_labeled.paper_name.isin(train_set.title.values)].reset_index(drop=True)\n",
    "    acl_labeled_add=acl_labeled_add.rename(columns={'paper_name':'title'})\n",
    "    acl_labeled_add=acl_labeled_add.assign(title_abstract=acl_labeled_add.title)\n",
    "    acl_labeled_add=acl_labeled_add.assign(abstract=\"\")\n",
    "    acl_labeled_add=acl_labeled_add.assign(year=2020)\n",
    "    acl_labeled_add=acl_labeled_add.assign(ID=acl_labeled_add.title)\n",
    "    acl_labeled_add=acl_labeled_add.assign(positive=1)\n",
    "\n",
    "    ## concat positive examples and unlabeled ones \n",
    "    train_set=train_set.assign(positive=np.where(train_set.title.isin(acl_labeled.paper_name.values),1,0))\n",
    "    train_set=pd.concat([train_set,acl_labeled_add])\n",
    "    train_set=train_set.assign(abstract=train_set.abstract.fillna(''))\n",
    "    train_set=train_set.assign(title_abstract=train_set.title+\". \"+train_set.abstract)\n",
    "    train_set.title_abstract=train_set.title_abstract.replace(\"{\",\"\",regex=True).replace(\"}\",\"\",regex=True)\n",
    "\n",
    "    ## website labeled positive examples\n",
    "    website_positive=website_positive.assign(title_abstract=website_positive.title+\". \"+website_positive.abstract)\n",
    "    website_positive=website_positive.rename(columns={'paperId':'ID'})\n",
    "    website_positive=website_positive.assign(label=1)\n",
    "    website_positive=website_positive.loc[:,['ID','title','abstract','title_abstract','label','year','url']]\n",
    "\n",
    "    ## rule based identification of positive and negative examples\n",
    "    train_set_positive=train_set.loc[(train_set.url.str.lower().str.contains('|'.join(list(workshops.Event.values))))|\n",
    "               (train_set.title_abstract.str.lower().str.contains('|'.join(list(keywords.Keywords.values)))) |\n",
    "               (train_set.cosine_similarity>=perc_99),:]\n",
    "\n",
    "    train_set_negative=train_set.loc[~((train_set.url.str.lower().str.contains('|'.join(list(workshops.Event.values))))|\n",
    "               (train_set.title_abstract.str.lower().str.contains('|'.join(list(keywords.Keywords.values)))) |\n",
    "               (train_set.cosine_similarity>=perc_99)),:]\n",
    "\n",
    "    ## take negative examples with the lowest cosine similarity with social needs\n",
    "    median_cos_sim=round(train_set_negative.cosine_similarity.median(),6)\n",
    "\n",
    "    train_set_worst=train_set_negative.loc[train_set_negative.cosine_similarity<median_cos_sim]\n",
    "\n",
    "    ## label those examples\n",
    "    train_set_positive=train_set_positive.assign(label=1)\n",
    "    train_set_worst=train_set_worst.assign(label=0)\n",
    "\n",
    "    train_set_positive=train_set_positive.loc[:,['ID','title','abstract','title_abstract','label','year','url']]\n",
    "    train_set_worst=train_set_worst.loc[:,['ID','title','abstract','title_abstract','label','year','url']]\n",
    "\n",
    "    train_set_positive=pd.concat([train_set_positive,website_positive])\n",
    "\n",
    "    ## create a trainning set with the same proportion of positive examples as the original set\n",
    "    proportion=round(train_set_positive.shape[0]/(train_set_positive.shape[0]+train_set_negative.shape[0]),3)\n",
    "    ## proportion around 10 percent\n",
    "    positive_obs=round(train_set_worst.shape[0]*0.10)\n",
    "\n",
    "    train_set_positive_sample=train_set_positive.sample(n=positive_obs,random_state=42)\n",
    "\n",
    "    train_set_final=pd.concat([train_set_worst,train_set_positive_sample])\n",
    "\n",
    "    train_set_final=train_set_final.drop_duplicates(subset=['title'])\n",
    "\n",
    "    unused_positive=train_set_positive.loc[~train_set_positive.title.isin(train_set_final.title.unique())].drop_duplicates(subset=['title'])\n",
    "\n",
    "    unlabeled=train_set_negative.loc[(~train_set_negative.title.isin(train_set_final.title.unique())) &\n",
    "                                     (~train_set_negative.title.isin(unused_positive.title.unique())),\n",
    "                                     ['ID', 'title', 'abstract', 'title_abstract', 'year', 'url']].drop_duplicates(subset=['title'])\n",
    "\n",
    "\n",
    "    return (train_set_final,unused_positive,unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30cfa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/project/sachan/fgonzalez/ie/lib64/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_path=\"../../data/\"\n",
    "    outputs_path=\"../../outputs/\"\n",
    "    train_set=pd.read_csv(outputs_path+\"general/train_set.csv\")\n",
    "    test_set=pd.read_csv(outputs_path+\"general/test_set_SG_annotate.csv\")\n",
    "    ## help for filtering positive examples\n",
    "    workshops=pd.read_csv(data_path+\"others/sg_workshops.csv\")\n",
    "    keywords=pd.read_csv(data_path+\"others/sg_keywords.csv\")\n",
    "    ## labeled positive examples\n",
    "    acl_labeled=pd.read_csv(data_path+\"papers/acl20_long.csv\",error_bad_lines=False)\n",
    "    website_positive=pd.read_json(data_path+\"papers/papers.json\")\n",
    "    \n",
    "    train_set_final,unused_positive,unlabeled=label_data(train_set,test_set,keywords,workshops,acl_labeled,website_positive)\n",
    "    \n",
    "    train_set_final.to_csv(outputs_path+\"sg_classifier/train_set_labeled.csv\",index=False)\n",
    "    unlabeled.to_csv(outputs_path+\"sg_classifier/unlabeled_set.csv\",index=False)\n",
    "    unused_positive.to_csv(outputs_path+\"sg_classifier/unused_positive.csv\",index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff089a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
