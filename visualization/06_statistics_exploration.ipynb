{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a5bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9da12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_path=\"../outputs/\"\n",
    "data_path=\"../data/\"\n",
    "\n",
    "df_labels_task=pd.read_json(outputs_path+\"sg_ie/positives_tasks_methods_clusters_final_f.json\")\n",
    "df_task_test=pd.read_json(outputs_path+\"sg_ie/test_scirex_tasks_methods_clusters_final_f.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ea701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled=pd.read_csv(outputs_path+\"sg_classifier/train_set_labeled_bronze_title_15pct_nk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f458b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_negatives=pd.read_csv(outputs_path+\"sg_classifier/all_negative_examples_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf915ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pos=pd.read_csv(outputs_path+\"sg_classifier/all_positive_examples_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06cea852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8703, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d430f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title_abstract</th>\n",
       "      <th>label</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ostendorff-etal-2020-aspect</td>\n",
       "      <td>Aspect-based Document Similarity for Research ...</td>\n",
       "      <td>Traditional document similarity measures provi...</td>\n",
       "      <td>Aspect-based Document Similarity for Research ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://aclanthology.org/2020.coling-main.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>zhou-etal-2010-exploiting</td>\n",
       "      <td>Exploiting Multi-Features to Detect Hedges and...</td>\n",
       "      <td>In this paper, we present a machine learning a...</td>\n",
       "      <td>Exploiting Multi-Features to Detect Hedges and...</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>https://aclanthology.org/W10-3015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>dilsizian-etal-2014-new</td>\n",
       "      <td>A New Framework for Sign Language Recognition ...</td>\n",
       "      <td>Current approaches to sign recognition by comp...</td>\n",
       "      <td>A New Framework for Sign Language Recognition ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>http://www.lrec-conf.org/proceedings/lrec2014/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>losch-etal-2018-european</td>\n",
       "      <td>{E}uropean Language Resource Coordination: Col...</td>\n",
       "      <td>In order to help improve the quality, coverage...</td>\n",
       "      <td>European Language Resource Coordination: Colle...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>https://aclanthology.org/L18-1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>koizumi-etal-2002-annotated</td>\n",
       "      <td>An Annotated {J}apanese {S}ign {L}anguage Corpus</td>\n",
       "      <td>Sign language is characterized by its interact...</td>\n",
       "      <td>An Annotated Japanese Sign Language Corpus. Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>http://www.lrec-conf.org/proceedings/lrec2002/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>owoputi-etal-2013-improved</td>\n",
       "      <td>Improved Part-of-Speech Tagging for Online Con...</td>\n",
       "      <td>We consider the problem of part-of-speech tagg...</td>\n",
       "      <td>Improved Part-of-Speech Tagging for Online Con...</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>https://aclanthology.org/N13-1039.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>kang-etal-2020-neural</td>\n",
       "      <td>Neural Mask Generator: Learning to Generate Ad...</td>\n",
       "      <td>We propose a method to automatically generate ...</td>\n",
       "      <td>Neural Mask Generator: Learning to Generate Ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://aclanthology.org/2020.emnlp-main.493.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>ligozat-2013-question</td>\n",
       "      <td>Question Classification Transfer</td>\n",
       "      <td>Question answering systems have been developed...</td>\n",
       "      <td>Question Classification Transfer. Question ans...</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>https://aclanthology.org/P13-2076.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>hozumi-etal-1993-integration</td>\n",
       "      <td>Integration of Morphological and Syntactic Ana...</td>\n",
       "      <td>Morphological analysis of Japanese is very dif...</td>\n",
       "      <td>Integration of Morphological and Syntactic Ana...</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>https://aclanthology.org/1993.iwpt-1.10.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>maruf-etal-2021-explaining</td>\n",
       "      <td>Explaining Decision-Tree Predictions by Addres...</td>\n",
       "      <td>We offer an approach to explain Decision Tree ...</td>\n",
       "      <td>Explaining Decision-Tree Predictions by Addres...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://aclanthology.org/2021.inlg-1.12.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ID  \\\n",
       "385    ostendorff-etal-2020-aspect   \n",
       "386      zhou-etal-2010-exploiting   \n",
       "387        dilsizian-etal-2014-new   \n",
       "388       losch-etal-2018-european   \n",
       "389    koizumi-etal-2002-annotated   \n",
       "...                            ...   \n",
       "7061    owoputi-etal-2013-improved   \n",
       "7062         kang-etal-2020-neural   \n",
       "7063         ligozat-2013-question   \n",
       "7064  hozumi-etal-1993-integration   \n",
       "7065    maruf-etal-2021-explaining   \n",
       "\n",
       "                                                  title  \\\n",
       "385   Aspect-based Document Similarity for Research ...   \n",
       "386   Exploiting Multi-Features to Detect Hedges and...   \n",
       "387   A New Framework for Sign Language Recognition ...   \n",
       "388   {E}uropean Language Resource Coordination: Col...   \n",
       "389    An Annotated {J}apanese {S}ign {L}anguage Corpus   \n",
       "...                                                 ...   \n",
       "7061  Improved Part-of-Speech Tagging for Online Con...   \n",
       "7062  Neural Mask Generator: Learning to Generate Ad...   \n",
       "7063                   Question Classification Transfer   \n",
       "7064  Integration of Morphological and Syntactic Ana...   \n",
       "7065  Explaining Decision-Tree Predictions by Addres...   \n",
       "\n",
       "                                               abstract  \\\n",
       "385   Traditional document similarity measures provi...   \n",
       "386   In this paper, we present a machine learning a...   \n",
       "387   Current approaches to sign recognition by comp...   \n",
       "388   In order to help improve the quality, coverage...   \n",
       "389   Sign language is characterized by its interact...   \n",
       "...                                                 ...   \n",
       "7061  We consider the problem of part-of-speech tagg...   \n",
       "7062  We propose a method to automatically generate ...   \n",
       "7063  Question answering systems have been developed...   \n",
       "7064  Morphological analysis of Japanese is very dif...   \n",
       "7065  We offer an approach to explain Decision Tree ...   \n",
       "\n",
       "                                         title_abstract  label  year  \\\n",
       "385   Aspect-based Document Similarity for Research ...      1  2020   \n",
       "386   Exploiting Multi-Features to Detect Hedges and...      1  2010   \n",
       "387   A New Framework for Sign Language Recognition ...      1  2014   \n",
       "388   European Language Resource Coordination: Colle...      1  2018   \n",
       "389   An Annotated Japanese Sign Language Corpus. Si...      1  2002   \n",
       "...                                                 ...    ...   ...   \n",
       "7061  Improved Part-of-Speech Tagging for Online Con...      0  2013   \n",
       "7062  Neural Mask Generator: Learning to Generate Ad...      0  2020   \n",
       "7063  Question Classification Transfer. Question ans...      0  2013   \n",
       "7064  Integration of Morphological and Syntactic Ana...      0  1993   \n",
       "7065  Explaining Decision-Tree Predictions by Addres...      0  2021   \n",
       "\n",
       "                                                    url  \n",
       "385       https://aclanthology.org/2020.coling-main.545  \n",
       "386                   https://aclanthology.org/W10-3015  \n",
       "387   http://www.lrec-conf.org/proceedings/lrec2014/...  \n",
       "388                   https://aclanthology.org/L18-1213  \n",
       "389   http://www.lrec-conf.org/proceedings/lrec2002/...  \n",
       "...                                                 ...  \n",
       "7061              https://aclanthology.org/N13-1039.pdf  \n",
       "7062   https://aclanthology.org/2020.emnlp-main.493.pdf  \n",
       "7063              https://aclanthology.org/P13-2076.pdf  \n",
       "7064        https://aclanthology.org/1993.iwpt-1.10.pdf  \n",
       "7065        https://aclanthology.org/2021.inlg-1.12.pdf  \n",
       "\n",
       "[2500 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.loc[df_labeled.ID.isin(df_task_test.ID.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af277ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58941, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_negatives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f80dcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63941"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58941+5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ec0eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8133, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82975e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=pd.read_csv(outputs_path+\"general/test_set_final.csv\")\n",
    "train_set=pd.read_csv(outputs_path+\"general/train_set_final.csv\")\n",
    "dev_set=pd.read_csv(outputs_path+\"general/dev_set_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f055c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp4sg=pd.concat([train_set,dev_set,test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b7d7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp4sg=nlp4sg.loc[nlp4sg.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aeb53d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8133"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f681867a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8416-8133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "778b2e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 17)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp4sg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4a7ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_test=df_task_test.loc[df_task_test.ID.isin(nlp4sg.ID.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b08c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_task=pd.concat([df_labels_task,df_task_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82e258f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8463"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "957bdece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_task['Method']=[list([]) for _ in range(df_labels_task.shape[0])]\n",
    "df_labels_task['Task']=[list() for _ in range(df_labels_task.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f77a423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in df_labels_task.iterrows():\n",
    "    tasks=[]\n",
    "    for e in d['task_scirex']:\n",
    "        tasks.append(e['top_word'])\n",
    "    df_labels_task.at[i,'Task']=tasks\n",
    "    methods=[]\n",
    "    for e in d['method_scirex']:\n",
    "        methods.append(e['top_word'])\n",
    "    df_labels_task.at[i,'Method']=methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67885924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_task=df_labels_task.explode('Task').rename(columns={'Task':'tasks'})\n",
    "\n",
    "df_labels_task=df_labels_task.explode('Method').rename(columns={'Method':'methods'})\n",
    "\n",
    "df_labels_task=df_labels_task.loc[~df_labels_task.tasks.isin(['natural language processing','nlp','nlp applications'])]\n",
    "\n",
    "df_labels_task=df_labels_task.loc[~df_labels_task.methods.isin(['natural language processing','nlp','nlp applications'])]\n",
    "\n",
    "df_labels_task.methods=df_labels_task.methods.fillna('no_method')\n",
    "df_labels_task.tasks=df_labels_task.tasks.fillna('no_task')\n",
    "\n",
    "df_labels_task['total_methods']=df_labels_task.groupby(['ID']).methods.transform('count')\n",
    "\n",
    "df_labels_task['weight']=1/df_labels_task.total_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d636f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "###df_mapping=pd.read_csv(outputs+\"words_mapping.csv\")\n",
    "df_mapping=pd.read_csv(\"../sg_match/clusters.psv\",sep='|')\n",
    "\n",
    "df_mapping.center=df_mapping.center.fillna(method='ffill')\n",
    "\n",
    "df_mapping=df_mapping.loc[df_mapping.word!='Cluster name: ']\n",
    "\n",
    "df_mapping.word=df_mapping.word.str.rstrip(' ').str.lstrip(' ')\n",
    "df_mapping.center=df_mapping.center.str.rstrip(' ').str.lstrip(' ')\n",
    "\n",
    "df_mapping_tasks=df_mapping.rename(columns={'word':'tasks','center':'center_task'})\n",
    "df_mapping_methods=df_mapping.rename(columns={'word':'methods','center':'center_method'})\n",
    "\n",
    "df_labels_task=df_labels_task.merge(df_mapping_tasks,on=['tasks'],how='left').merge(df_mapping_methods,on=['methods'],how='left')\n",
    "\n",
    "df_labels_task=df_labels_task.assign(tasks=np.where((~df_labels_task.center_task.isna()),df_labels_task.center_task,df_labels_task.tasks))\n",
    "\n",
    "df_labels_task=df_labels_task.assign(methods=np.where((~df_labels_task.center_method.isna()),df_labels_task.center_method,df_labels_task.methods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69eed728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8446.278571428573"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cced3ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    81286.000000\n",
       "mean         0.103908\n",
       "std          0.135970\n",
       "min          0.005556\n",
       "25%          0.033333\n",
       "50%          0.055556\n",
       "75%          0.111111\n",
       "max          1.000000\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.weight.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b35878e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_count=df_labels_task.loc[:,['ID','tasks']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fc0d41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasks</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine translation</th>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_task</th>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicity detection</th>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annotation</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>named entity recognition</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment analysis</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text summarization</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computational linguistics</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question answering</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ID\n",
       "tasks                         \n",
       "machine translation        530\n",
       "classification             342\n",
       "no_task                    323\n",
       "toxicity detection         279\n",
       "annotation                 213\n",
       "named entity recognition   184\n",
       "sentiment analysis         127\n",
       "text summarization         125\n",
       "computational linguistics  117\n",
       "question answering         117"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_count.groupby(['tasks']).count().sort_values('ID',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aac4504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tasks</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10590</th>\n",
       "      <td>no_task</td>\n",
       "      <td>323.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9074</th>\n",
       "      <td>machine translation</td>\n",
       "      <td>209.191903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>hate speech</td>\n",
       "      <td>146.405891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>classification</td>\n",
       "      <td>113.442039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>annotation</td>\n",
       "      <td>67.861086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>combining vision</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13967</th>\n",
       "      <td>spatial language learning and reasoning</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13968</th>\n",
       "      <td>spatial language understanding</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13965</th>\n",
       "      <td>spatial information extraction</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>formalizing spatial concepts</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16268 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tasks      weight\n",
       "10590                                  no_task  323.000000\n",
       "9074                       machine translation  209.191903\n",
       "6889                               hate speech  146.405891\n",
       "2337                            classification  113.442039\n",
       "561                                 annotation   67.861086\n",
       "...                                        ...         ...\n",
       "2757                          combining vision    0.041667\n",
       "13967  spatial language learning and reasoning    0.041667\n",
       "13968           spatial language understanding    0.041667\n",
       "13965           spatial information extraction    0.041667\n",
       "6389              formalizing spatial concepts    0.041667\n",
       "\n",
       "[16268 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.groupby(['tasks']).weight.sum().reset_index().sort_values('weight',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "540174bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count=df_labels_task.loc[:,['ID','methods']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d57a1d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methods</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_method</th>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning methods</th>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language models</th>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep neural network</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine translation</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformers</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word embeddings</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support vector machine</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ID\n",
       "methods                       \n",
       "no_method                 1005\n",
       "bert                       359\n",
       "machine learning methods   335\n",
       "classification             251\n",
       "language models            229\n",
       "deep neural network        211\n",
       "machine translation        188\n",
       "transformers               182\n",
       "word embeddings            151\n",
       "support vector machine     136"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_count.groupby(['methods']).count().sort_values('ID',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efb24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5d8dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count=methods_count.assign(llm=np.where(methods_count.methods.str.lower().str.contains('transformer|language model|bert|gpt|xlnet|electra|t5|bloom|lamda'),'language model',methods_count.methods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b55e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count=methods_count.sort_values('llm').drop_duplicates(subset=['ID','llm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10c79186",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count=methods_count.assign(llm=np.where(methods_count.methods=='bert','bert',methods_count.llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19b7cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count=methods_count.drop_duplicates(['ID','llm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43691653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>methods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_method</th>\n",
       "      <td>1005</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language model</th>\n",
       "      <td>773</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning methods</th>\n",
       "      <td>335</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep neural network</th>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine translation</th>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word embeddings</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support vector machine</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp applications</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditional random field</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural network</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolutional neural network</th>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annotation</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble methods</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ID  methods\n",
       "llm                                        \n",
       "no_method                     1005     1005\n",
       "language model                 773      773\n",
       "machine learning methods       335      335\n",
       "bert                           252      252\n",
       "classification                 251      251\n",
       "deep neural network            211      211\n",
       "machine translation            188      188\n",
       "word embeddings                151      151\n",
       "support vector machine         136      136\n",
       "nlp applications               119      119\n",
       "lstm                           111      111\n",
       "conditional random field       101      101\n",
       "neural network                  96       96\n",
       "convolutional neural network    87       87\n",
       "annotation                      83       83\n",
       "ensemble methods                70       70"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_count.groupby(['llm']).count().sort_values('ID',ascending=False).head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ba2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count=methods_count.assign(llm=np.where(methods_count.methods.str.lower().str.contains('transformer|language model|bert|gpt|xlnet|electra|t5|bloom|lamda'),'language model',methods_count.methods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d7995b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>methods</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>aspect based document similarity</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>compilation techniques</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>data structures</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>attribute value logic</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24356</th>\n",
       "      <td>warrens abstract machine</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>classification</td>\n",
       "      <td>119.533886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>bert</td>\n",
       "      <td>122.103022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12870</th>\n",
       "      <td>machine translation</td>\n",
       "      <td>144.750638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12840</th>\n",
       "      <td>machine learning methods</td>\n",
       "      <td>162.749206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15433</th>\n",
       "      <td>no_method</td>\n",
       "      <td>1387.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25089 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                methods       weight\n",
       "973    aspect based document similarity     0.038462\n",
       "3547             compilation techniques     0.041667\n",
       "5011                    data structures     0.041667\n",
       "1151              attribute value logic     0.041667\n",
       "24356          warrens abstract machine     0.041667\n",
       "...                                 ...          ...\n",
       "2964                     classification   119.533886\n",
       "1794                               bert   122.103022\n",
       "12870               machine translation   144.750638\n",
       "12840          machine learning methods   162.749206\n",
       "15433                         no_method  1387.000000\n",
       "\n",
       "[25089 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.groupby(['methods']).weight.sum().reset_index().sort_values('weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning? , attention. mlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad6293e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count=methods_count.assign(llm3=np.where(methods_count.methods.str.lower().str.contains('transformer|language model|bert|gpt|xlnet|electra|t5|bloom|lamda'),'language model','other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a07efd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count=methods_count.assign(llm2=np.where(methods_count.llm.str.lower().str.contains('transfer learning|attention|transformer|language model|bert|gpt|xlnet|electra|t5|bloom|lamda'),1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c001e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    759\n",
       "Name: llm2, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_count.loc[methods_count.llm=='language model'].llm2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_count.loc[methods_count.llm=='language model'].llm2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "397fa1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other             8324\n",
       "language model    1025\n",
       "Name: llm3, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_count.drop_duplicates(subset=['ID','llm3']).llm3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ceafc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9349, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_count.drop_duplicates(subset=['ID','llm3']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e7f7fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8303\n",
       "1    1232\n",
       "Name: llm2, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_count.drop_duplicates(subset=['ID','llm2']).llm2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49e90349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8416"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7854ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12179182509505704"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1025/8416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fab5bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878208174904943"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(1025/8416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ee8121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_task=df_labels_task.assign(llm=np.where(df_labels_task.methods.str.lower().str.contains('transfer learning|attention|transformer|language model|bert|gpt|xlnet|electra|t5|bloom|lamda'),1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26dcc184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12107\n",
       "1      763\n",
       "Name: llm, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.drop_duplicates(subset=['ID']).llm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "517a1a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05928515928515928"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "763/(12107+763)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "909168bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04755244755244755"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "612/(12258+612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f16d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['roberta', 'bert', 'bert baseline classifier',\n",
       "       'mbert transformer model', 'multi depth distilbert',\n",
       "       'domain specific language model scibert', 'graphbert model',\n",
       "       'bert base model', 'bert representations',\n",
       "       'gpt 2 fine tuned models',\n",
       "       'bert large cased question answering model',\n",
       "       'xlnet natural language inference model', 'xlnet', 'gpt',\n",
       "       'bert based adverse drug effect tweet classification',\n",
       "       'bert based hierarchical aggregation model', 'bert classifiers',\n",
       "       'bert based architectures', 'bert based multilingual model',\n",
       "       'vl bert', 'bert multilingual model', 'bert language model',\n",
       "       'covid twitter bert', 'bert - based classifier',\n",
       "       'fine tuned bert bidirectional encoder representations',\n",
       "       'bert based dual encoder model', 'roberta base model',\n",
       "       'roberta pre trained model', 'biobert baseline',\n",
       "       'bert based classification model', 'romanian bert model',\n",
       "       'jurbert', 'bert and derivative models', 'marbert',\n",
       "       'sentencebert based clustering',\n",
       "       'feature - and bert - based classifiers', 'biobert model',\n",
       "       'openais gpt', 'bert benchmarking classifiers', 'txtbert',\n",
       "       'inference chain based gpt model', 'domain specific bert',\n",
       "       'bert based information extraction system', 'spanbert',\n",
       "       'bert based token classification',\n",
       "       'roberta token classification checkpoints',\n",
       "       'empathetic bert2bert conversational model',\n",
       "       'dense bert based representation',\n",
       "       'roberta based transformer architecture', 'bert base arabic',\n",
       "       'multi channel bert', 'bert based one pass multi task model',\n",
       "       'bert - based neural baselines', 'roberta based models',\n",
       "       'german gpt - 2 model',\n",
       "       'robustly optimized bert pretraining approach', 'gpt3series',\n",
       "       'clinical biobert', 'roberta base', 'gpt neoj',\n",
       "       'recovery dialogpt model', 'dialogpt model',\n",
       "       'bert - based nlp model', 'distilbert model',\n",
       "       'bert - based system', 'gpt 2 based property generation model',\n",
       "       'bert based fine tuned model',\n",
       "       'col bert late interaction ranking model',\n",
       "       'colberts expressive maxsim operator', 'germanbert models',\n",
       "       'cellbert', 'dis tilbert', 'dialogpt', 'albert based model',\n",
       "       'bert based neural models', 'bert transformer', 'xml roberta',\n",
       "       'multiple bert model', 'multiple bert model framework',\n",
       "       'bert based analysis', 'ordinal regression multi source bert',\n",
       "       'mt bert', 'hbert', 'gpt 2 pubnub', 'bertbilstm',\n",
       "       'anonymized bert', 'word2vec and bert semantic representations',\n",
       "       'bert checkpoints', 'gpt 2 based models', 'bertsum',\n",
       "       'bert based baselines', 'bert pretrained baseline',\n",
       "       'adversarial and domain - aware bert', 'task agnostic bert',\n",
       "       'climatebert', 'bert encoder', 'pretrained language gpt 2 model',\n",
       "       'german bert model', 'bert variations', 'transformer m bert',\n",
       "       'mixture of berts', 'generic and domain specific bert',\n",
       "       'entity enriched relation classification bert model',\n",
       "       'multi tasking bert model', 'mbg clinicalbert', 'in dicbert',\n",
       "       'roberta classifier', 'bert based sequence labeling model',\n",
       "       'finbert fine tuning', 'sentence bert',\n",
       "       'fine tuned bert based token classifier', 'macbert',\n",
       "       'bert based adversarial network', 'finbert',\n",
       "       'ssndibertsitylt edi eacl2021', 'legal bert', 'hurtbert',\n",
       "       'bert based ensemble learning approach', 'bertbased model',\n",
       "       'neural bert representations', 'roberta pre training',\n",
       "       'pretrained bert', 'context dependent bert',\n",
       "       'contextual word embedding xlm roberta', 'transformers bert',\n",
       "       'clini calbert', 'bert based framework', 'empath bert',\n",
       "       'biomedical bert', 'gpt lm', 'bert based topic classifier',\n",
       "       'retrained bert', 'hatebert', 'general bert model',\n",
       "       'bert and roberta architectures', 'spanbert model', 'habertor',\n",
       "       'bagging bert models', 'bert based fine tuning method',\n",
       "       'fine tuned albert', 'elmo and bert embeddings',\n",
       "       'bert based hidden layer representations',\n",
       "       'bert based sequence labelling model', 'bio bert embeddings',\n",
       "       'bert gpt', 'chinese medical bert model', 'cmedbert',\n",
       "       'facebooks robustly optimized bert pretraining approach',\n",
       "       'bert bilstm based span level propaganda classification model',\n",
       "       'juribert', 'stack of bert and lstm layers', 'pre trained bert',\n",
       "       'bert based adversarial example generation', 'bert mlms',\n",
       "       'pre training bert', 'bioclinicalbert', 'umlsbert', 'umls bert',\n",
       "       'phs bert', 'bertoxic', 'multilabel ct bert', 'arabicbert',\n",
       "       'bert cnn', 'distill - bert', 'asafya bert', 'arabert base',\n",
       "       'deep learning bert based language models',\n",
       "       'multitask arabert approach', 'biobertpt', 'bertbased',\n",
       "       'bert based multi tasklearning',\n",
       "       'mlm fine tuned roberta based classifier',\n",
       "       'berts bidirectional encoder representations', 'sroberta',\n",
       "       'sentence roberta sroberta embeddings model',\n",
       "       'continued pretraining of generic bert', 'bert based transformers',\n",
       "       'bert based graph initializer', 'roberta transformer',\n",
       "       'comment domain bert model', 'bert based answer re ranking system',\n",
       "       'pretrained bert models', 'language representation model bert',\n",
       "       'distilled and finetuned gpt 2 models',\n",
       "       'bert and logistic regression classifiers',\n",
       "       'language model roberta', 'fine tuned bert model', 'terbert',\n",
       "       'char acterbert', 'ensemble bert bilstm attention model',\n",
       "       'bert bidirectional encoder representations', 'bert fine tuning',\n",
       "       'vanilla bert', 'no transfer bert baseline',\n",
       "       'bert neural language model', 'timbert', 'bert pre trained model',\n",
       "       'multi task roberta based bi encoder model',\n",
       "       'bert based ensembles', 'ensemble bert',\n",
       "       'roberta based language model', 'clinical xlnet', 'mribert',\n",
       "       'bert based variations', 'german bert',\n",
       "       'zero shot bert based models',\n",
       "       'fine tuned roberta document embeddings', 'privbert', 'smedbert',\n",
       "       'roberta based approach', 'multilingual bert models',\n",
       "       'ensemble of mbert and xlm roberta models', 'xlnet approach',\n",
       "       'roberta based text classification model',\n",
       "       'ensemble of bert based models', 'albert modellan', 'bertmoticon',\n",
       "       'biobert based ner', 'toxicbert classification',\n",
       "       'domainspecific bert models', 'bert - based models',\n",
       "       'efficientbert', 'tinybert', 'mobilebert', 'fbert', 'toxicbert',\n",
       "       'bert crf', 'wikipedia stance detection bert (ws - bert)',\n",
       "       'bertchem ddi', 'domain specific biobert embedding',\n",
       "       'language model bert', 'bert embedding models',\n",
       "       'bertbased language models', 'bert based multimodal models',\n",
       "       'endr bert', 'chemical structure bert based encoder',\n",
       "       'cross lingual and cross modal bert based models',\n",
       "       'pretrained bert base', 'biobert embeddings',\n",
       "       'reinforced bert based approaches', 'cobert',\n",
       "       'bert based response selection model', 'hierarchical bert',\n",
       "       'indicbert and bert architectures', 'biomedbert', 'distil bert',\n",
       "       'contextual knowledge enhanced gpt model',\n",
       "       'bert based transfer learning',\n",
       "       'xlm roberta pre trained language model',\n",
       "       'high precision crossencoder bert model', 'phobert',\n",
       "       'bert contextualized word embeddings', 'bert like models',\n",
       "       'reproducing kernel hilbert spaces',\n",
       "       'roberta and albert based baselines',\n",
       "       'single language bert models', 'teacher bert', 'distilling bert',\n",
       "       'tiny bert', 'roberta large model',\n",
       "       'marbert and mazajak embedding', 'deberta model', 'lv bert',\n",
       "       'external bert representations', 'contextualized bert', 'fin bert',\n",
       "       'bert based sequence labeling models', 'bertoids',\n",
       "       'holistic bert ensemble', 'bert based module',\n",
       "       'domain finetuned bert', 'finetuned bert model',\n",
       "       'distillbert architectures', 'bert knn',\n",
       "       'bert and bart based rankers', 'multilingual bert embeddings',\n",
       "       'mtsi bert', 'bertserini', 'pdbert', 'gpt d', 'kinyabert',\n",
       "       'charbert', 'bert bilstm capsule model', 'berts', 'kg bert',\n",
       "       'pretrained language specific bert', 'estbert',\n",
       "       'pretrained transformer based language specific bert model',\n",
       "       'dilbert', 'rust bert', 'lgam bert',\n",
       "       'level grained attention masked bert', 'bertscore', 'ms bert',\n",
       "       'bertviz', 'bilingual bert', 'scibert sentence representation',\n",
       "       'grubert', 'bert hidden layers', 'tinybert and dis tilbert models',\n",
       "       'distilbert based classifier', 'bert large', 'bert persner',\n",
       "       'roberta pre trained language models', 'deproberta', 'copybert',\n",
       "       'variational autoencoder based model ege - roberta',\n",
       "       'bert base architecture', 'open ai gpt model',\n",
       "       'roberta - large pre - trained model',\n",
       "       'collobert and weston 2008 embeddings', 'newsbert',\n",
       "       'trade and tod bert models', 'arabert pretrained model',\n",
       "       'pretrained roberta model', 'gpt 2 network',\n",
       "       'xlnet language models', 'bert based distillation',\n",
       "       'pre - bert methods', 'regular bert', 'knowberts',\n",
       "       'knowledge enhanced bert', 'gpt networks',\n",
       "       'bert based cross lingual model', 'bertweetfr',\n",
       "       'finetuning bert based model', 'quadrupletbert',\n",
       "       'quadru pletbert model', 'bert masked language model',\n",
       "       'czert czech bert like model', 'bert encodings'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_task.loc[df_labels_task.methods.str.lower().str.contains('bert|gpt|xlnet|electra|t5')].methods.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82ff3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "others=df_labels_task.loc[~df_labels_task.methods.str.lower().str.contains('transformer|language model|bert|gpt|xlnet|electra|t5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a15bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "others=others.groupby(['methods']).weight.sum().reset_index().sort_values('weight',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae7badb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_method',\n",
       " 'machine learning methods',\n",
       " 'machine translation',\n",
       " 'classification',\n",
       " 'deep neural network',\n",
       " 'word embeddings',\n",
       " 'annotation',\n",
       " 'nlp applications',\n",
       " 'support vector machine',\n",
       " 'neural network',\n",
       " 'conditional random field',\n",
       " 'lstm',\n",
       " 'neural models',\n",
       " 'language technology',\n",
       " 'unsupervised algorithm',\n",
       " 'convolutional neural network',\n",
       " 'supervised learning',\n",
       " 'computational models',\n",
       " 'recurrent neural networks',\n",
       " 'multi task learning',\n",
       " 'transfer learning',\n",
       " 'named entity recognition',\n",
       " 'ensemble methods',\n",
       " 'topic models',\n",
       " 'part of speech',\n",
       " 'parser',\n",
       " 'attention',\n",
       " 'domain adaption',\n",
       " 'wordnet',\n",
       " 'feature engineering',\n",
       " 'logistic regression',\n",
       " 'automatic speech recognition',\n",
       " 'umls',\n",
       " 'search engine',\n",
       " 'dialogue system',\n",
       " 'rule based system',\n",
       " 'evaluation methods',\n",
       " 'error analysis',\n",
       " 'pretrained models',\n",
       " 'fact checking',\n",
       " 'grammar',\n",
       " 'hybrid approach',\n",
       " 'computational model',\n",
       " 'sentiment analysis',\n",
       " 'fine tuning',\n",
       " 'active learning',\n",
       " 'statistical analysis',\n",
       " 'probabilistic model',\n",
       " 'parsers',\n",
       " 'propaganda techniques',\n",
       " 'dialogue systems',\n",
       " 'covid 19',\n",
       " 'event extraction',\n",
       " 'hidden markov models',\n",
       " 'natural language generation',\n",
       " 'graph neural networks',\n",
       " 'statistical models',\n",
       " 'computational linguistics',\n",
       " 'crowdsourcing',\n",
       " 'information retrieval',\n",
       " 'coreference resolution',\n",
       " 'adversarial training',\n",
       " 'predictive models',\n",
       " 'supervised approach',\n",
       " 'latent dirichlet allocation',\n",
       " 'elmo',\n",
       " 'word2vec',\n",
       " 'question answering',\n",
       " 'reinforcement learning',\n",
       " 'hate speech',\n",
       " 'multilingual models',\n",
       " 'statistical methods',\n",
       " 'naive bayes',\n",
       " 'text summarization',\n",
       " 'encoder',\n",
       " 'mwe',\n",
       " 'hlt',\n",
       " 'psycholinguistics',\n",
       " 'information extraction',\n",
       " 'twitter',\n",
       " 'bayesian model',\n",
       " 'predictions',\n",
       " 'rhetorical structure theory',\n",
       " 'fasttext',\n",
       " 'binary classifier',\n",
       " 'backtranslation',\n",
       " 'semantic representations',\n",
       " 'automatic methods',\n",
       " 'knowledge base',\n",
       " 'learning algorithm',\n",
       " 'artificial intelligence',\n",
       " 'joint model',\n",
       " 'regression model',\n",
       " 'statistical model',\n",
       " 'computational approach',\n",
       " 'dependency parsing',\n",
       " 'predictive model',\n",
       " 'data augmentation',\n",
       " 'plms',\n",
       " 'distributional semantic models',\n",
       " 'translation model',\n",
       " 'statistical approach',\n",
       " 'speech technologies',\n",
       " 'mwes',\n",
       " 'text analysis techniques',\n",
       " 'linguistic analysis',\n",
       " 'semi supervised approach',\n",
       " 'relation extraction',\n",
       " 'bidirectional encoder representations',\n",
       " 'fake news detection',\n",
       " 'tutorial dialogue system',\n",
       " 'tagger',\n",
       " 'cat tools',\n",
       " 'debiasing methods',\n",
       " 'semantic representation',\n",
       " 'framenet',\n",
       " 'amazon mechanical turk',\n",
       " 'latent semantic analysis',\n",
       " 'data driven approach',\n",
       " 'ocr',\n",
       " 'automatic method',\n",
       " 'semi supervised learning',\n",
       " 'pretraining',\n",
       " 'phrase based smt system',\n",
       " 'zipfs law',\n",
       " 'clarin',\n",
       " 'recommender systems',\n",
       " 'end system',\n",
       " 'tf idf',\n",
       " 'supervised learning approach',\n",
       " 'maximum entropy classifier',\n",
       " 'lexical resource',\n",
       " 'moses',\n",
       " 'dependency parsers',\n",
       " 'learning process',\n",
       " 'clustering',\n",
       " 'ud',\n",
       " 'wsd system',\n",
       " 'statistical method',\n",
       " 'joint inference',\n",
       " 'linguistic models',\n",
       " 'intelligent tutoring system',\n",
       " 'machine learning classifier',\n",
       " 'sentiment analysis techniques',\n",
       " 'web application',\n",
       " 'combinatory categorial grammar',\n",
       " 'automatic classifiers',\n",
       " 'accuracy',\n",
       " 'linear classifier',\n",
       " 'spoken dialogue systems',\n",
       " 'automated tools',\n",
       " 'reddit',\n",
       " 'corpus based approach',\n",
       " 'supervised classifier',\n",
       " 'contextual embeddings',\n",
       " 'parameter tuning',\n",
       " 'tm',\n",
       " 'taggers',\n",
       " 'qualitative analysis',\n",
       " 'language processing tools',\n",
       " 'regression',\n",
       " 'speech recognizer',\n",
       " 'centering theory',\n",
       " 'information technology',\n",
       " 'lda',\n",
       " 'spoken dialogue system',\n",
       " 'information extraction techniques',\n",
       " 'joint modeling',\n",
       " 'computational tools',\n",
       " 'linguists',\n",
       " 'morphological analysis',\n",
       " 'automated methods',\n",
       " 'sequence to sequence models',\n",
       " 'distant supervision',\n",
       " 'ranking model',\n",
       " 'translation tools',\n",
       " 'ldc',\n",
       " 'nlp system',\n",
       " 'seq2seq',\n",
       " 'distributional semantics',\n",
       " 'pre training',\n",
       " 'automatic systems',\n",
       " 'model architectures',\n",
       " 'vector representations',\n",
       " 'knowledge distillation',\n",
       " 'smm4h',\n",
       " 'hybrid approaches',\n",
       " 'supervised model',\n",
       " 'automatic approach',\n",
       " 'joint models',\n",
       " 'syntactic analysis',\n",
       " 'regularization',\n",
       " 'business models',\n",
       " 'knowledge graph',\n",
       " 'dictionaries',\n",
       " 'kb',\n",
       " 'statistical machine translation systems',\n",
       " 'automatic system',\n",
       " 'tree adjoining grammar',\n",
       " 'correlation analysis',\n",
       " 'content analysis',\n",
       " 'treebank',\n",
       " 'semeval',\n",
       " 'self training',\n",
       " 'random forest classifier',\n",
       " 'ensembling',\n",
       " 'intelligent tutoring systems',\n",
       " 'computer program',\n",
       " 'training process',\n",
       " 'parsing algorithms',\n",
       " 'linguist',\n",
       " 'summarization system',\n",
       " 'heuristic rules',\n",
       " 'graph based method',\n",
       " 'random forest',\n",
       " 'topic model',\n",
       " 'rule based methods',\n",
       " 'gru',\n",
       " 'unified framework',\n",
       " 'supervised models',\n",
       " 'nlg system',\n",
       " 'annotation schemas',\n",
       " 'recursive neural networks',\n",
       " 'data - driven methods',\n",
       " 'bootstrapping algorithm',\n",
       " 'finite state transducers',\n",
       " 'vector space models',\n",
       " 'morphological analyzer',\n",
       " 'online system',\n",
       " 'pipeline approach',\n",
       " 'clustering algorithm',\n",
       " 'ml',\n",
       " 'genetic algorithm',\n",
       " 'annotation approach',\n",
       " 'data driven approaches',\n",
       " 'wikipedia',\n",
       " 'computational linguists',\n",
       " 'acoustic models',\n",
       " 'attribute selection',\n",
       " 'semantic models',\n",
       " 'conversational agents',\n",
       " 'theoretical framework',\n",
       " 'aligner',\n",
       " 'cat',\n",
       " 'inference',\n",
       " 'ebmt system',\n",
       " 'variational autoencoders',\n",
       " 'linear regression',\n",
       " 'supervised training',\n",
       " 'supervised classification system',\n",
       " 'speech translation system',\n",
       " 'elra',\n",
       " 'nlp approach',\n",
       " 'probabilistic approach',\n",
       " 'automatic means',\n",
       " 'lexicon',\n",
       " 'curriculum learning',\n",
       " 'neural network architecture',\n",
       " 'supervised methods',\n",
       " 'dependency grammar',\n",
       " 'hybrid method',\n",
       " 'semantic parsers',\n",
       " 'language representations',\n",
       " 'writing system',\n",
       " 'topic modelling',\n",
       " 'extraction methods',\n",
       " 'linguistic annotation framework',\n",
       " 'linear regression model',\n",
       " 'embedding models',\n",
       " 'nave bayes',\n",
       " 'ccg',\n",
       " 'bag of words model',\n",
       " 'systran',\n",
       " 'hpsg',\n",
       " 'user model',\n",
       " 'discriminator',\n",
       " 'supervised approaches',\n",
       " 'multimodal approach',\n",
       " 'olac',\n",
       " 'natural language processing system',\n",
       " 'learning',\n",
       " 'pre processing',\n",
       " 'alignment model',\n",
       " 'natural language processing algorithms',\n",
       " 'natural language system',\n",
       " 'dialogue models',\n",
       " 'statistical framework',\n",
       " 'google translate',\n",
       " 'data augmentation methods',\n",
       " 'statistics',\n",
       " 'information theory',\n",
       " 'tramooc',\n",
       " 'coding scheme',\n",
       " 'majority voting',\n",
       " 'bm25',\n",
       " 'acl',\n",
       " 'maximum entropy model',\n",
       " 'annotation framework',\n",
       " 'cl',\n",
       " 'character n grams',\n",
       " 'medslt',\n",
       " 'automated techniques',\n",
       " 's2s',\n",
       " 'supervised framework',\n",
       " 'log linear model',\n",
       " 'summarizers',\n",
       " 'evaluation procedures',\n",
       " 'lsa',\n",
       " 'lexical functional grammar',\n",
       " 'concordancer',\n",
       " 'duluth systems',\n",
       " 'heuristics',\n",
       " 'nlp technology',\n",
       " 'supervised system',\n",
       " 'mt softwares',\n",
       " 'hopeedi',\n",
       " 'corpus analysis',\n",
       " 'crowd - sourcing',\n",
       " 'annotation layer',\n",
       " 'covid - 19',\n",
       " 'hawkes processes',\n",
       " 'machine translator',\n",
       " 'word embedding methods',\n",
       " 'umls metathesaurus',\n",
       " 'rule - based system',\n",
       " 'pattern mining',\n",
       " \"amazon's mechanical turk\",\n",
       " 'elicitation protocol',\n",
       " 'babel',\n",
       " 'information extraction system',\n",
       " 'distributional methods',\n",
       " 'linguistic processing',\n",
       " 'multidimensional analysis',\n",
       " 'clustering method',\n",
       " 'generative model',\n",
       " 'random forests',\n",
       " 'statistical approaches',\n",
       " 'metamap',\n",
       " 'wsd',\n",
       " 'multilingual system',\n",
       " 'lrs',\n",
       " 'automated approaches',\n",
       " 'markov logic',\n",
       " 'computer technology',\n",
       " 'hierarchical clustering',\n",
       " 'data model',\n",
       " 'deep convolutional neural network',\n",
       " 'meaning representation',\n",
       " 'transfer learning approach',\n",
       " 'zero shot learning',\n",
       " 'feature analysis',\n",
       " 'data augmentation techniques',\n",
       " 'amr',\n",
       " 'mt engines',\n",
       " 'tipster program',\n",
       " 'bootstrapping approach',\n",
       " 'computer system',\n",
       " 'n grams',\n",
       " 'bpe',\n",
       " 'scate',\n",
       " 'multimodal models',\n",
       " 'information extraction systems',\n",
       " 'extractive',\n",
       " 'integrated framework',\n",
       " 'supervised systems',\n",
       " 'distributional representations',\n",
       " 'metal system',\n",
       " 'annotation procedures',\n",
       " 'automatic tagger',\n",
       " 'pagerank',\n",
       " 'dialogue strategies',\n",
       " 'multi layer annotation scheme',\n",
       " 'language resources',\n",
       " 'evaluation strategies',\n",
       " 'decision trees',\n",
       " 'post processing',\n",
       " 'baseline models',\n",
       " 'learning system',\n",
       " 'inside outside algorithm',\n",
       " 'bootstrapping',\n",
       " 'search system',\n",
       " 'mtl',\n",
       " 'semantic networks',\n",
       " 'k means',\n",
       " 'student model',\n",
       " 'distributed representations',\n",
       " 'rewriting rules',\n",
       " 'google',\n",
       " 'information extraction tools',\n",
       " 'interlingual representation',\n",
       " 'assistive technology',\n",
       " 'translation memory systems',\n",
       " 'automatic speech recognition system',\n",
       " 'classification techniques',\n",
       " 'nlp solutions',\n",
       " 'maximum entropy models',\n",
       " 'long short term memory networks',\n",
       " 'linear model',\n",
       " 'system architecture',\n",
       " 'model architecture',\n",
       " 'random baseline',\n",
       " 'bbn',\n",
       " 'seq2seq models',\n",
       " 'frame semantics',\n",
       " 'modelling approach',\n",
       " 'phrase based statistical machine translation',\n",
       " 'data augmentation technique',\n",
       " 'random selection',\n",
       " 'business model',\n",
       " 'knowledge bases',\n",
       " 'machine translation engine',\n",
       " 'sentence embeddings',\n",
       " 'knowledge representation',\n",
       " 'sequence to sequence model',\n",
       " 'toxic spans detection',\n",
       " 'interactive tool',\n",
       " 'grammar rules',\n",
       " 'moses decoder',\n",
       " 'semantic search engine',\n",
       " 'corpus based method',\n",
       " 'discourse analysis',\n",
       " 'preprocessing techniques',\n",
       " 'linguistic theory',\n",
       " 'representation learning',\n",
       " 'linguistic resource',\n",
       " 'sdl',\n",
       " 'compositionality',\n",
       " 'python',\n",
       " 'majority class baseline',\n",
       " 'data augmentation method',\n",
       " 'classification algorithms',\n",
       " 'stance detection',\n",
       " 'beam search',\n",
       " 'meta net',\n",
       " 'artificial neural networks',\n",
       " 'markov logic networks',\n",
       " 'parsing strategy',\n",
       " 'meteor',\n",
       " 'cfgs',\n",
       " 'statistical classifier',\n",
       " 'generative grammar',\n",
       " 'online tool',\n",
       " 'learned representations',\n",
       " 'weakly supervised method',\n",
       " 'annotation methodology',\n",
       " 'text classifier',\n",
       " 'max margin framework',\n",
       " 'dialogue agent',\n",
       " 'lexical resources',\n",
       " 'learning methods',\n",
       " 'optical character recognition',\n",
       " 'first order logic',\n",
       " 'embedding methods',\n",
       " 'integer linear programming',\n",
       " 'hybrid model',\n",
       " 'lfg',\n",
       " 'pipeline architecture',\n",
       " 'text representation',\n",
       " 'ensemble models',\n",
       " 'kernel functions',\n",
       " 'global model',\n",
       " 'example based mt',\n",
       " 'segmentation model',\n",
       " 'negex',\n",
       " 'type system',\n",
       " 'chunker',\n",
       " 'conversational agent',\n",
       " 'expert system',\n",
       " 'mapping',\n",
       " 'meaningful representations',\n",
       " 'alis translation solutions',\n",
       " 'alis technologies',\n",
       " 'graph theory',\n",
       " 'topic signatures',\n",
       " 'stander',\n",
       " 'stance detection systems',\n",
       " 'ri',\n",
       " 'reputation system',\n",
       " 'dictionary based approach',\n",
       " 'data collection method',\n",
       " 'mdl',\n",
       " 'pronoun resolution system',\n",
       " 'statistical systems',\n",
       " 'dialogue game',\n",
       " 'naive bayes model',\n",
       " 'kaggle',\n",
       " 'ht',\n",
       " 'beer',\n",
       " 'tipster',\n",
       " 'communication strategies',\n",
       " 'dlt',\n",
       " 'generative approach',\n",
       " 'iso timeml',\n",
       " 'pca',\n",
       " 'translation technology',\n",
       " 'unsupervised machine learning',\n",
       " 'data mining techniques',\n",
       " 'estwn',\n",
       " 'lexical substitution',\n",
       " 'structured representations']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(others.head(500).methods.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31e50a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others.index('drugbank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "152603bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auto encoder based differentially private text transformation',\n",
       " 'mia attacks',\n",
       " 'membership inference attacks',\n",
       " 'transformation process',\n",
       " 'supervised and semi supervised approaches',\n",
       " 'nearly unsupervised hashcode representations',\n",
       " 'kernelized locality sensitive hashcodes',\n",
       " 'sign language translation system',\n",
       " 'bigram models of non manual features',\n",
       " 'sequence classification',\n",
       " 'unigram',\n",
       " 'bilingual sign language dictionary',\n",
       " 'www',\n",
       " 'class classification',\n",
       " 'supervised and unsupervised methods',\n",
       " 'stock investment taxonomy',\n",
       " 'companion teaching',\n",
       " 'dialogue policy',\n",
       " 'initial policy',\n",
       " 'bigram',\n",
       " 'k nn',\n",
       " 'nave bayes',\n",
       " 'emotion words',\n",
       " 'classification systems',\n",
       " 'graph memory networks',\n",
       " 'training pipeline',\n",
       " 'software systems',\n",
       " 'pyreval',\n",
       " 'content models',\n",
       " 'natural language processing software',\n",
       " 'machine aids',\n",
       " 'grader ensemble',\n",
       " 'localization processes',\n",
       " 'runet',\n",
       " 'open source framework',\n",
       " 'mudes',\n",
       " 'automatic detection methods',\n",
       " 'automated annotation scheme learning',\n",
       " 'support vector machine svm based text mining system',\n",
       " 'agreement',\n",
       " 'variable substitution',\n",
       " 'unification variable matching',\n",
       " 'unification',\n",
       " 'contextual classification strategy',\n",
       " 'polarity classification strategies',\n",
       " 'therapeutic dialogue',\n",
       " 'global content strategies',\n",
       " 'affective strategies',\n",
       " 'unipi',\n",
       " 'sequence labelling',\n",
       " 'constrainedunconstrained systems',\n",
       " 'phrasebased moses system',\n",
       " 'affective lexicons',\n",
       " 'unified probabilistic modeling framework',\n",
       " 'stance classification models',\n",
       " 'joint models of disagreement and stance',\n",
       " 'local classifier',\n",
       " 'capsule network',\n",
       " 'stacked bidirectional gated recurrent units',\n",
       " 'stacked bigru model',\n",
       " 'fasttext tools',\n",
       " 'sentence representation',\n",
       " 'medeval',\n",
       " 'cross validation',\n",
       " 'hand tracker',\n",
       " 'feature descriptors',\n",
       " 'multiple instance learning based segmentation system',\n",
       " 'recognition strategies',\n",
       " 'collaboration strategies',\n",
       " 'collaborative translation platform',\n",
       " 'knowledge engineering manner',\n",
       " 'productivity promotion strategies',\n",
       " 'mutual learning',\n",
       " 'translator collaboration technologies',\n",
       " 'csn',\n",
       " 'quantitative data driven machine learning approach',\n",
       " 'foss service',\n",
       " 'document similarity based features',\n",
       " \"nakagawa's flr\",\n",
       " 'reframing techniques',\n",
       " 'prompting algorithms',\n",
       " 'xslt',\n",
       " 'smil',\n",
       " 'bidirectional conversion',\n",
       " 'generalization capacity',\n",
       " 'reporting bias',\n",
       " 'opinion extraction system',\n",
       " 'recommendation system',\n",
       " 'sdrts',\n",
       " 'rfc',\n",
       " 'pre processing pipelines',\n",
       " 'resource heavy system',\n",
       " 'optimality theorys neglected lexicon optimization module',\n",
       " 'gradual learning algorithm',\n",
       " 'heuristic baselines',\n",
       " 'supervised classification algorithms',\n",
       " 'adaptation stage',\n",
       " 'domain specific vocabulary expansion',\n",
       " 'adapt and distill',\n",
       " 'general pretrained models',\n",
       " 'pretrained networks',\n",
       " 'human in the loop machine learning',\n",
       " 'safeguards',\n",
       " 'attribute and class based outlier detection',\n",
       " 'clinical decision support systems',\n",
       " 'inference based learner like agent',\n",
       " 'entailment modelings',\n",
       " 'event annotation approach',\n",
       " 'temporal segmentation',\n",
       " 'ocr engines',\n",
       " 'multi task hierarchical recurrent network',\n",
       " 'deep network',\n",
       " 'unsupervised topic modeling',\n",
       " 'supervised text classification methods',\n",
       " 'unigram representation',\n",
       " 'statistical feature selection',\n",
       " 'assertion analysis',\n",
       " 'predictive modeling',\n",
       " 'risk analysis',\n",
       " 'textcoop discourse analysis platform',\n",
       " 'dynamic layout',\n",
       " 'corpus based approach',\n",
       " 'exploratory statistical methods',\n",
       " 'collostructional analysis',\n",
       " 'chinese grammatical error diagnosis',\n",
       " 'lst m long short term memory',\n",
       " 'contextualized character representation',\n",
       " 'automatic diagnosis system',\n",
       " 'transcriptions',\n",
       " 'syntactic and shallow semantic tree kernels',\n",
       " 'lsabased models',\n",
       " 'lsa',\n",
       " 'latent semantic analysis',\n",
       " 'bi directional parsing',\n",
       " 'clavius',\n",
       " 'unsupervised machine learning',\n",
       " 'multimodal biometric authentication system',\n",
       " 'conversational agent technology',\n",
       " 'narrow scientific ie system',\n",
       " 'open ie systems',\n",
       " 'narrow ie extractions',\n",
       " 'ie',\n",
       " 'fobie',\n",
       " 'scientific method',\n",
       " 'pragmatic masking',\n",
       " 'surrogate fine tuning',\n",
       " 'denoising voice conversion system',\n",
       " 'neural network bandwidth extension',\n",
       " 'two level opinion and sentiment model',\n",
       " 'decop',\n",
       " 'automatic approaches',\n",
       " 'rnn based models',\n",
       " 'text extraction system',\n",
       " 'character based models',\n",
       " 'zd',\n",
       " 'zero detector',\n",
       " 'natural language processing based linguistic analysis tool',\n",
       " 'zds',\n",
       " 'maximal clique factorization technique',\n",
       " 'relation extraction method',\n",
       " 'automatic speech recognition technologies',\n",
       " 'text tospeech synthesis technologies',\n",
       " 'speech recognition and synthesis technologies',\n",
       " 'phonological comparison',\n",
       " 'adversarial meta evaluation of factuality',\n",
       " 'factuality checkers',\n",
       " 'meta evaluation methodologies',\n",
       " 'cws',\n",
       " 'fws',\n",
       " 'fw',\n",
       " 'teacher lms',\n",
       " 'mergedistill',\n",
       " 'task agnostic knowledge distillation',\n",
       " 'pre trained distillation',\n",
       " 'oli',\n",
       " 'hsd',\n",
       " 'spartanslt edi eacl2021',\n",
       " 'optical motion capture',\n",
       " 'anvil',\n",
       " 'character and token level embeddings',\n",
       " 'multi domain sentiment model',\n",
       " 'neurosent pdi',\n",
       " '7b safety layer model',\n",
       " 'io reddit model',\n",
       " 'labrador retrievers',\n",
       " 'saferdialogues',\n",
       " 'open domain conversational models',\n",
       " 'bst2',\n",
       " 'regularization techniques',\n",
       " 'chatbot text classification data quality',\n",
       " 'nex cv',\n",
       " 'semeval',\n",
       " 'shapley values',\n",
       " 'model specific approach',\n",
       " 'model agnostic method',\n",
       " 'learnability argument',\n",
       " 'learners',\n",
       " 'color aesthetics',\n",
       " 'collocational analysis',\n",
       " 'ctp',\n",
       " 'susy',\n",
       " 'forward and backward reasoning',\n",
       " 'tree adjoining grammar',\n",
       " 'automatic triage systems',\n",
       " 'manual flagging',\n",
       " 'wikipedia',\n",
       " 'aspect sentiment',\n",
       " 'statistical relational models',\n",
       " 'hinge loss markov random fields',\n",
       " 'variation measurement tool',\n",
       " 'dynamic time warping',\n",
       " 'sign method',\n",
       " 'scoring model',\n",
       " 'marker based motion capture setup',\n",
       " 'computer vision based descriptors',\n",
       " 'computer vision method',\n",
       " 'multivariate linear and non linar regression methods',\n",
       " 'non intrusive computer vision method',\n",
       " 'coh metrix esp',\n",
       " 'complexity binary classifier',\n",
       " 'complexity analysis tool',\n",
       " 'coh metrix',\n",
       " 'creative approach',\n",
       " 'electronic surveillance tools',\n",
       " 'argumentation - driven supervised learning method',\n",
       " 'text chat interface',\n",
       " 'relative usefulness of questions',\n",
       " 'ranking model',\n",
       " 'biased model',\n",
       " 'biased instance detection methods',\n",
       " 'dataset bias mitigation techniques',\n",
       " 'partial input and limitedcapacity models',\n",
       " 'wmt2016 shared task',\n",
       " 'translation system based features',\n",
       " 'ter',\n",
       " 'automated semantic role labeling',\n",
       " 'nlp4sg',\n",
       " 'coaching strategies',\n",
       " 'knowledge representation and reasoning system',\n",
       " 'uno natural language processing',\n",
       " 'boolean algebra computational model',\n",
       " 'assistive technology',\n",
       " 'self paced reading method',\n",
       " 'deliberative dialogue',\n",
       " \"tagalog linguistic inquiry and word count (liwc) `disaster' dictionary\",\n",
       " 'expertise model',\n",
       " 'preprocessing element',\n",
       " 'pearsons ',\n",
       " 'unsupervised readability assessor',\n",
       " 'first order models',\n",
       " 'tier approach',\n",
       " 'entailment recognizer',\n",
       " 'yesno response classifier',\n",
       " 'lmf',\n",
       " 'lexical resources',\n",
       " \"brown and levinson's model\",\n",
       " 'logistic regression svm classifiers',\n",
       " 'statistically based automatic tagging',\n",
       " 'gnu emacs editor',\n",
       " 'manual review',\n",
       " 'generalized markup language',\n",
       " 'computer program',\n",
       " 'ltrc',\n",
       " 'neural multi task learning',\n",
       " 'nyt',\n",
       " 'cl rules',\n",
       " 'induced models',\n",
       " 'supervised statistical learning techniques',\n",
       " 'reasoning and knowledge transfer methods',\n",
       " 'evaluation methods',\n",
       " 'lexification of emotion concepts',\n",
       " 'cross cultural similarity features',\n",
       " 'pragmatically driven transfer',\n",
       " 'cidoc conceptual reference model',\n",
       " 'bcms',\n",
       " 'unconstrained systems',\n",
       " 'digital representation',\n",
       " 'erasmus programme',\n",
       " 'ebmt',\n",
       " 'example based mt',\n",
       " 'inequality me model',\n",
       " 'inequality models',\n",
       " 'gaussian map estimation',\n",
       " 'prost',\n",
       " 'physical reasoning concepts',\n",
       " 'formal meaning representation',\n",
       " 'formal reasoning',\n",
       " 'formal ontology',\n",
       " 'cidoc',\n",
       " 'pattern based method',\n",
       " 'dmoz taxonomy',\n",
       " 'amesure',\n",
       " 'readability formula',\n",
       " 'digitization process',\n",
       " 'sri',\n",
       " 'cmu',\n",
       " 'bbn',\n",
       " 'atis system',\n",
       " 'cumulator',\n",
       " 'green algorithms',\n",
       " 'experiment impact tracker',\n",
       " 'costbenefit analysis',\n",
       " 'nlp experiments',\n",
       " 'wearable and conversational agent',\n",
       " 'proof ofconcept framework',\n",
       " 'everyday living artificial intelligence',\n",
       " 'minimallysupervised approach',\n",
       " 'minimal supervision',\n",
       " 'engineering models',\n",
       " 'linguistics blind approach',\n",
       " 'statistical methods',\n",
       " 'analyst stakeholder interviews',\n",
       " 'computational linguistics techniques',\n",
       " 'tanbih',\n",
       " 'intelligent analysis tools',\n",
       " 'news aggregator',\n",
       " 'recursive long audio alignment procedure',\n",
       " 'transfer learning based approach',\n",
       " 'neural prediction model',\n",
       " 'graph based approaches',\n",
       " 'focus model',\n",
       " 'context modelling',\n",
       " 'contextual analysis',\n",
       " 'conceptor debiasing',\n",
       " 'word embedding association test',\n",
       " 'grid',\n",
       " 'grid virtual organization',\n",
       " 'morpho syntactic tagging',\n",
       " 'n gram statistics processing',\n",
       " 'multra',\n",
       " 'language modules',\n",
       " 'mats system',\n",
       " 'mt prototype',\n",
       " 'explicon ab',\n",
       " 'deep hpsg parser',\n",
       " 'query interface',\n",
       " 'abstraction methods',\n",
       " 'english resource grammar',\n",
       " 'web browser based application',\n",
       " 'hybrid nlp architecture',\n",
       " 'relation based search',\n",
       " 'ls',\n",
       " 'volmac lingware services',\n",
       " 'attribute selection',\n",
       " 'cultural relativism',\n",
       " 'decentralized tool',\n",
       " 'snis product metal',\n",
       " 'englishj',\n",
       " 'learning icelandic',\n",
       " 'flashcards',\n",
       " 'assessing authenticity',\n",
       " 'pluricentric model',\n",
       " 'reviewing practices',\n",
       " 'am',\n",
       " 'switch scanning',\n",
       " 'spoken dialog systems toolkits',\n",
       " 'shallower systems',\n",
       " 'linguistic analysis',\n",
       " 'incremental model',\n",
       " 'knowledge based approach',\n",
       " 'shallow models',\n",
       " 'training and decoding approaches',\n",
       " 'prague school framework',\n",
       " 'kpml',\n",
       " 'reinforcement learning',\n",
       " 'question generation model',\n",
       " 'automatic analysis',\n",
       " 'mime nlg',\n",
       " 'mobile medical monitoring system',\n",
       " 'estonian language technology',\n",
       " 'facebook',\n",
       " 'tpack framework',\n",
       " 'blended learning framework',\n",
       " 'social networking site',\n",
       " '3d virtual worlds',\n",
       " 'mid 3d',\n",
       " 'dqn',\n",
       " 'postprocessing strategy',\n",
       " 'dqn based approach',\n",
       " 'deep q learning network',\n",
       " 'case analysis',\n",
       " 'inductive generalization',\n",
       " 'acquisition procedures',\n",
       " 'learnability theory',\n",
       " 'rule overgeneralization',\n",
       " 'empiricist model',\n",
       " 'linguists',\n",
       " 'lmu',\n",
       " 'phrase based systems',\n",
       " 'feature rich discriminative model',\n",
       " 'crowdsource systems',\n",
       " 'keyword matching',\n",
       " 'bootstrapping technique',\n",
       " 'theoretical models',\n",
       " 'priming',\n",
       " 'nomad',\n",
       " 'linguistic resources',\n",
       " 'analysis and visualization technologies',\n",
       " 'semantic parser',\n",
       " 'incremental probabilistic learner',\n",
       " 'ccg grammatical framework',\n",
       " 'online variational bayesian expectation maximization',\n",
       " 'meaning representations',\n",
       " 'syntactic method',\n",
       " 'syntactic and lexical approaches',\n",
       " 'hierarchical lexical method',\n",
       " 'mixed initiative dialog strategies',\n",
       " 'multi input multi output sequence labeling',\n",
       " 'multi output module',\n",
       " 'asbd model',\n",
       " 'antisocial behavior detection system',\n",
       " 'label wise attention',\n",
       " 'bigrus',\n",
       " 'neural classifiers',\n",
       " 'lmtc',\n",
       " 'context sensitive elmo embeddings',\n",
       " 'retraining mechanism',\n",
       " '2 level classifier',\n",
       " 'personalising interaction',\n",
       " 'bootstrapping deep lexical resources',\n",
       " 'precision grammar',\n",
       " 'wmt13',\n",
       " 'eca',\n",
       " 'sound symbolism',\n",
       " 'competitive strategy',\n",
       " 'comprise cloud platform',\n",
       " 'cloud platform',\n",
       " 'continuous speech recognition capability',\n",
       " 'dragon systems',\n",
       " 'natural language system',\n",
       " 'expected idcellhood estimator',\n",
       " 'good turing method',\n",
       " 'statistical',\n",
       " 'hop prediction module',\n",
       " 'symbolic representations',\n",
       " 'selective sampling',\n",
       " 'pjiits systems',\n",
       " 'unsupervised transliteration models',\n",
       " 'web meta search service',\n",
       " 'squirrel',\n",
       " 'machine learning explainability tools',\n",
       " 'dependency based evaluation',\n",
       " 'depevalsumm',\n",
       " 'de pevalsumm',\n",
       " 'reranking parser',\n",
       " 'partial matching',\n",
       " 'portulan clarin research infrastructure',\n",
       " 'crls approach',\n",
       " 'learning methods',\n",
       " 'parsing strategy',\n",
       " 'agfl',\n",
       " 'computer programs',\n",
       " 'writirig specific grammar rules',\n",
       " 'linguist',\n",
       " 'ad hoe approaches',\n",
       " '1',\n",
       " 'robustness device',\n",
       " 'semantic analyzer',\n",
       " 'active learning scheme',\n",
       " 'tagger',\n",
       " 'semi supervised method',\n",
       " 'cross lingual transfer',\n",
       " 'ontological semantics',\n",
       " 'formal representation',\n",
       " 'label smoothing',\n",
       " 'ulmfit',\n",
       " 'upf cobalt',\n",
       " 'self induced curriculum learning',\n",
       " 'ssnmt',\n",
       " 'system internal representation types',\n",
       " 'voice - based technologies',\n",
       " 'race',\n",
       " 'first order reasoner',\n",
       " 'modular debiasing approach',\n",
       " 'task adapters',\n",
       " 'debiasing adapters',\n",
       " 'adele',\n",
       " 'kpu',\n",
       " 'set theory',\n",
       " 'french - spoken promptto - picture matching task',\n",
       " 'generalization of searle\\'s \"propositional\" act of referring',\n",
       " 'time expression reasoner',\n",
       " 'event coreference',\n",
       " 'intrinsic evaluation methodology',\n",
       " 'tempevals',\n",
       " 'dualist tool',\n",
       " 'tracking relationships between nations',\n",
       " 'human centered models',\n",
       " 'geoparsing large digital historical textual',\n",
       " 'spacy',\n",
       " 'tokenisation',\n",
       " 'defoe',\n",
       " 'user oriented evaluation approach',\n",
       " 'multi part coding scheme',\n",
       " 'dialogue agent evaluation practices',\n",
       " 'tcxt pieturc combiniltious',\n",
       " 'plantased multimedia prcseatation system',\n",
       " 'mental representations',\n",
       " 'concept activation',\n",
       " 'representational similarity analysis',\n",
       " 'intersectionality theory',\n",
       " 'unequal representations',\n",
       " 'contextualized and non contextualized embeddings',\n",
       " 'neural re rankers',\n",
       " 'evidence retrieval module',\n",
       " 'annisvis',\n",
       " 'geographical visualization solutions',\n",
       " 'webapp',\n",
       " 'extractive approaches',\n",
       " 'hybrid term frequencydocument term frequency',\n",
       " 'tsix',\n",
       " 'rationalism',\n",
       " 'reg08',\n",
       " 'reg algorithms',\n",
       " 'maise',\n",
       " 'amazons mechanical turk',\n",
       " 'ie system',\n",
       " 'finite state engine',\n",
       " 'thesaurus',\n",
       " 'nlp framework',\n",
       " 'partitioning approach',\n",
       " 'morphosyntactic analysis',\n",
       " 'spanish parser',\n",
       " 'constraint grammar formalism',\n",
       " 'monitoring hospital acquired infections',\n",
       " 'social computing',\n",
       " 'intelligent agents',\n",
       " 'social networking platforms',\n",
       " 'dialogue collection and enrichment framework',\n",
       " 'affect analysis system',\n",
       " 'rocksteady',\n",
       " 'ldst',\n",
       " 'kamusi project',\n",
       " 'smartphone application',\n",
       " 'kamusi',\n",
       " 'trustfulness',\n",
       " 'word count weighted training scheme',\n",
       " 'language based predictive models of users psychological traits',\n",
       " 'det',\n",
       " 'dialogue evaluation tool det',\n",
       " 'dialogue design',\n",
       " 'semantic representation of biomedical documents',\n",
       " 'nil ucm evotap',\n",
       " 'evolutionary algorithms',\n",
       " 'selection rules',\n",
       " 'crossover and mutation genetic operators',\n",
       " 'evolutionary and case based approaches',\n",
       " 'smokeng',\n",
       " 'finegrained classification mechanism',\n",
       " 'mechanical thesaurus;',\n",
       " 'classification techniques',\n",
       " 'text extraction',\n",
       " 'keycite',\n",
       " 'business models',\n",
       " 'term frequency inverse document frequency tf idf',\n",
       " 'linguistic account',\n",
       " 'parse tree fittiug 5',\n",
       " 'syntactical robustness',\n",
       " 'atn framework',\n",
       " 'declarative parsing formalisms',\n",
       " 'case frame approaches',\n",
       " 'weakness approach',\n",
       " 'linguistic theory of robustness',\n",
       " 'developmental robustness approaches',\n",
       " 'mt api',\n",
       " 'adobe systems',\n",
       " 'mt technologies',\n",
       " 'cut',\n",
       " 'graphical schemes',\n",
       " 'visual conceptual schemes',\n",
       " 'visual thinkers',\n",
       " 'capping and sampling data methods',\n",
       " 'frequency',\n",
       " 'defminer',\n",
       " 'supervised sequence labeling system',\n",
       " 'm5p model',\n",
       " 'feature selection algorithm',\n",
       " 'svm regression models',\n",
       " 'regression tree',\n",
       " 'sdl',\n",
       " 'ms word help',\n",
       " 'isolde',\n",
       " 'decision tree classifiers',\n",
       " 'aggregation mechanism',\n",
       " 'word clusters',\n",
       " 'situated data',\n",
       " 'bias aware methodology',\n",
       " 'computational linguist',\n",
       " 'bioasq suite',\n",
       " 'social network',\n",
       " 'assessment tool',\n",
       " 'web tools',\n",
       " 'nieuw novel incentives',\n",
       " 'project oriented approaches',\n",
       " 'linguistic data consortiums strategy',\n",
       " 'neural machine',\n",
       " 'project management institute',\n",
       " 'unified taxonomy of harmful content',\n",
       " 'social semantic owl 2 based knowledge platform',\n",
       " 'ontology aware user and nlp assisted flexible and multidimensional approach',\n",
       " 'modeling platform',\n",
       " 'realtime knowledge architecture',\n",
       " 'user and nlp assisted strategic workflow',\n",
       " 'semantic web standards',\n",
       " 'truthteller',\n",
       " 'standalone publiclyavailable tool',\n",
       " 'semantic annotation type',\n",
       " 'active curriculum learning',\n",
       " 'curriculum learning',\n",
       " 'curriculum heuristics',\n",
       " 'machine learning disciplines',\n",
       " 'extractive methods',\n",
       " 'neural sentence representations',\n",
       " 'template specification language',\n",
       " 'nat urm language system',\n",
       " 'summarization technique',\n",
       " 'discursive typology',\n",
       " 'document typology',\n",
       " 'similarity based learning method',\n",
       " 'metrical phonology',\n",
       " 'consensus linguistic analysis',\n",
       " 'learning algorithm',\n",
       " 'instance based learning',\n",
       " 'augmented version',\n",
       " 'data oriented approach',\n",
       " 'detection systems',\n",
       " 'factorisation',\n",
       " 'periodical models',\n",
       " 'qacg',\n",
       " 'pretrained deep learning models',\n",
       " 'feature enrichment',\n",
       " 'emory team',\n",
       " 'ldc',\n",
       " 'gclr',\n",
       " 'odni',\n",
       " 'explainable neural network architectures',\n",
       " 'ad hominem',\n",
       " 'pre annotation framework',\n",
       " 'linguistic analyzers',\n",
       " 'aspell spellchecker',\n",
       " 'lexicon based approach',\n",
       " 'natural language systems',\n",
       " 'glossary tools',\n",
       " 'translation rating mechanisms',\n",
       " 'reputation systems',\n",
       " 'cognitive representation',\n",
       " 'jam system',\n",
       " 'ilcm',\n",
       " 'research computing',\n",
       " 'integrated research environment',\n",
       " 'saas',\n",
       " 'leipzig corpus miner',\n",
       " 'as a service architecture',\n",
       " 'lcm',\n",
       " 'virtual research infrastructure',\n",
       " 'rhetorical relations labeling',\n",
       " 'cfcs',\n",
       " 'max margin framework',\n",
       " 'online model updates',\n",
       " 'geolocation systems',\n",
       " 'f1 score',\n",
       " 'taus dqf integration',\n",
       " 'operational tools',\n",
       " 'correction model',\n",
       " 'factual corrector model',\n",
       " 'graph attention',\n",
       " 'fact aware summarization model',\n",
       " 'language learning systems',\n",
       " 'exills',\n",
       " 'multimedia technologies',\n",
       " 'true elearning solution',\n",
       " 'troffi',\n",
       " 'mozilla firefox',\n",
       " 'web browser',\n",
       " 'comprehensive management system',\n",
       " 'microplanning rules',\n",
       " 'lthelsinki',\n",
       " 'hogent',\n",
       " 'lt3',\n",
       " 'dialogue strategy',\n",
       " 'generation evaluation framework',\n",
       " 'compound assessment',\n",
       " 'ensemble models',\n",
       " 'default theories',\n",
       " 'first order theories',\n",
       " 'interpolation',\n",
       " 'discourse network analysis framework',\n",
       " 'lois wordnets',\n",
       " 'ewn framework',\n",
       " 'classification schemes',\n",
       " 'modular architecture',\n",
       " 'eurowordnet ewn framework',\n",
       " 'word countbased',\n",
       " 'csr',\n",
       " 'discourse planning approach',\n",
       " 'unigram baseline',\n",
       " 'support vector machine svm classifier',\n",
       " 'augmentation technique',\n",
       " 'sentence similarity measures',\n",
       " 'telefnicas portfolio',\n",
       " 'web based uis',\n",
       " 'theoretical framework',\n",
       " 'voice activity detection',\n",
       " 'language learning programs',\n",
       " 'automated speech tools',\n",
       " 'privacy preserving workflow',\n",
       " 'austkin ii',\n",
       " 'online geospatial interface',\n",
       " 'argument mining techniques',\n",
       " 'automatic speech recognition system',\n",
       " 'semantic similarity measures',\n",
       " 'phase approach',\n",
       " 'discourse parser',\n",
       " 'linguistically informed models',\n",
       " 'tokenization method',\n",
       " 'slp models',\n",
       " 'hybrid framework',\n",
       " 'stochastic and symbolic techniques',\n",
       " 'rosetta foundation',\n",
       " 'herfindahl hirschman index',\n",
       " 'it tools',\n",
       " 'industry analysts',\n",
       " 'weakly supervised learning framework',\n",
       " 'predictive model of income',\n",
       " 'deep learning toolkit',\n",
       " 'aranet',\n",
       " 'bidirectional encoders',\n",
       " 'deep learning arabic social media processing tools',\n",
       " 'generic and specific models',\n",
       " 'viewgen project',\n",
       " 'belief system',\n",
       " 'mgr algorithm',\n",
       " 'model generative reasoning',\n",
       " 'viewgen',\n",
       " 'multi - level taxonomy',\n",
       " 'commercial search engine',\n",
       " 'sequence labeling',\n",
       " 'sweat',\n",
       " 'sliced word embedding association test',\n",
       " 'soft cosine similarity',\n",
       " 'decomposed graph entailment',\n",
       " 'smooth inverse frequency',\n",
       " 'labelling model',\n",
       " 'gradient boosted decision trees',\n",
       " 'da model',\n",
       " 'sirius ltg',\n",
       " 'word movers distance',\n",
       " 'sparql query',\n",
       " 'sentence selection',\n",
       " 'statistical dialogue agent',\n",
       " 'rulebased adversary',\n",
       " 'optimised agent',\n",
       " 'bayesian probabilistic model',\n",
       " 'lekbot',\n",
       " 'signwriting',\n",
       " 'textual description',\n",
       " 'notation systems',\n",
       " 'collaborative institutional training initiative',\n",
       " 'multimodal algorithm',\n",
       " 'elra',\n",
       " 'lrec',\n",
       " 'web portal',\n",
       " 'verta',\n",
       " 'linguistically motivated metric',\n",
       " 'verta eq',\n",
       " 'siamese setting',\n",
       " 'tapas model',\n",
       " 'atn',\n",
       " 'wh movement',\n",
       " 'miffed treatment',\n",
       " 'trace theory',\n",
       " 'transformational grammar',\n",
       " 'atn grsmmar',\n",
       " 'extended tandard theory',\n",
       " 'atn parser',\n",
       " 'automatic scoring system',\n",
       " 'multiplex graph convolutional network',\n",
       " 'multi gcn',\n",
       " 'multiplex graph summarization multi gras model',\n",
       " 'contextual embedding',\n",
       " 'multiple choice cnn',\n",
       " 'logical reasoning',\n",
       " 'leave one out testing procedure',\n",
       " 'ai techniques',\n",
       " 'templated based system',\n",
       " 'seqgen',\n",
       " 'neural network based system',\n",
       " 'templgen',\n",
       " 'reconstruction loss',\n",
       " 'ablation studies',\n",
       " 'supertags',\n",
       " 'perceptrons',\n",
       " 'word segmentation',\n",
       " 'ims',\n",
       " 'data augmentation strategy',\n",
       " 'tdmsci',\n",
       " 'framenet',\n",
       " 'automatic relation extraction engine jrex',\n",
       " 'step strategy',\n",
       " 'supervised model',\n",
       " 'ecnu',\n",
       " 'pac',\n",
       " 'limit framework',\n",
       " 'sdtes',\n",
       " 'tuning strategy',\n",
       " 'city exploration dialogue system',\n",
       " 'android app',\n",
       " 'samsung s voice',\n",
       " 'google search',\n",
       " 'filtering news',\n",
       " 'bag of sentences approach',\n",
       " 'multidimensional analysis',\n",
       " 'semantic search engine',\n",
       " 'grid processing',\n",
       " 'camtology system',\n",
       " 'deep factorization machines',\n",
       " 'wide and deep learning model',\n",
       " 'item response theory models',\n",
       " 'syntactic and semantic features',\n",
       " 'neural network based method',\n",
       " 'prosper thy neighbour',\n",
       " 'extractive summarization architecture',\n",
       " 'linguistic representations',\n",
       " 'cooperative component',\n",
       " 'shared workspace framework',\n",
       " 'dialogue model',\n",
       " 'machine translator',\n",
       " 'organisationalinstitutional level',\n",
       " 'language data management practices',\n",
       " 'token based',\n",
       " 'lemma based approach',\n",
       " 'lemmatized version',\n",
       " 'llms',\n",
       " 'template based approach',\n",
       " 'globalization technology',\n",
       " 'sharable components',\n",
       " 'architecture demonstration system',\n",
       " 'socio - semantic representation',\n",
       " 'hccl',\n",
       " 'neural network architecture',\n",
       " 'speech - based measures',\n",
       " 'synonymy networks',\n",
       " 'random walks',\n",
       " 'pcl',\n",
       " 'dictionary - based analyses of reddit communities',\n",
       " 'one pass curriculum strategies',\n",
       " 'curriculum pacing',\n",
       " 'nlp algorithms',\n",
       " 'wmt 2007 shared task',\n",
       " 'in domain model',\n",
       " 'ecolomedia',\n",
       " 'tf . idf based method',\n",
       " 'coding scheme',\n",
       " 'deep language representation model',\n",
       " 'labelling scheme',\n",
       " 'lexical heuristics',\n",
       " 'text matching',\n",
       " 'semantic feature representation',\n",
       " 'bag of super word embeddings',\n",
       " 'residualized factor adaptation',\n",
       " 'ilc cnr',\n",
       " 'term extraction tool',\n",
       " 'dictating machines',\n",
       " 'typewriters',\n",
       " 'semantic representations',\n",
       " 'dialogue move taxonomy',\n",
       " 'intermediate representation',\n",
       " 'location embeddings',\n",
       " 'physical trajectories',\n",
       " 'cell embeddings',\n",
       " 'numerically aware graph neural network table fact verification model',\n",
       " 'table parsing',\n",
       " 'tabfact',\n",
       " 'structural encoding',\n",
       " 'debugging environment',\n",
       " 'error inflation',\n",
       " 'ui system',\n",
       " 'information retrieval packages',\n",
       " 'act',\n",
       " 'label propagation algorithm',\n",
       " 'affect control theory',\n",
       " 'affective reasoning',\n",
       " 'sentiment analysis techniques',\n",
       " 'surface sentence extraction',\n",
       " 'robust parsing technology',\n",
       " 'text production methods',\n",
       " 'deep phrase selection',\n",
       " 'display resources',\n",
       " 'content analysis',\n",
       " 'coneatenatton',\n",
       " 'statlstlcally baeed sentence extrachon',\n",
       " 'text general strategies',\n",
       " 'summansmg',\n",
       " 'mtermeate techniques',\n",
       " 'temporal expressions labeling',\n",
       " 'ensemble based methods',\n",
       " 'feature based and deep learning methods',\n",
       " 'event detection systems',\n",
       " 'participant systems',\n",
       " 'media sourcing',\n",
       " 'probabilistic models',\n",
       " 'human communication dynamics framework',\n",
       " 'computational technologies',\n",
       " 'statistics',\n",
       " 'japangloss',\n",
       " 'autoscribe',\n",
       " 'kbmt',\n",
       " 'data and model distillation',\n",
       " 'speech to speech translation services',\n",
       " 'whiteboard application',\n",
       " 'nespole',\n",
       " 'video conferencing channel',\n",
       " 'client server architecture',\n",
       " 'lstmcnn model',\n",
       " 'cnn textvgg16',\n",
       " 'scope based resources',\n",
       " 'open domain question answering system',\n",
       " 'quantitative and qualitative methods',\n",
       " 'distributed semantic representation',\n",
       " 'nlp method',\n",
       " 'hopeful nlp@lt - edi - eacl2021',\n",
       " 'timebank',\n",
       " 'spacebank',\n",
       " 'spaceml language',\n",
       " 'spatio temporal model',\n",
       " 'linguistic resource',\n",
       " 'lexically - driven features',\n",
       " 'social network based systems',\n",
       " 'decoding process',\n",
       " 'delta m theorem',\n",
       " 'metal system',\n",
       " 'lt strategy',\n",
       " 'languagerelated parts',\n",
       " 'r2d2 systems',\n",
       " 'voting procedure',\n",
       " 'computational social science methodology',\n",
       " 'interdisciplinary approaches',\n",
       " 'longitudinal analysis',\n",
       " 'wordlevel baseline method',\n",
       " 'wdm method',\n",
       " 'dynamic vector auto regression',\n",
       " 'static cross correlation coefficient',\n",
       " 'low dimensional support vector machine svm classifier',\n",
       " 'message level weighted daily mood',\n",
       " 'semantic similarity features',\n",
       " 'fine tuned word embeddings',\n",
       " 'bayesian segmentation model',\n",
       " 'realistic grammars',\n",
       " 'generalized phrase structure grammars',\n",
       " 'merge method',\n",
       " 'aslnet v1',\n",
       " 'data model',\n",
       " 'att tcn attention based temporal convolutional neural network',\n",
       " 'temporal convolutional neural network',\n",
       " 'sae att tcnself attentive embedding attention based temporal convolutional neural network',\n",
       " 'scoring software',\n",
       " 'generation challenges',\n",
       " 'localized tree model',\n",
       " 'minimal system',\n",
       " 'forced aligner',\n",
       " 'speech technologies',\n",
       " 'automatic speech recognition tools',\n",
       " 'scanning process',\n",
       " 'trigger scoping strategy',\n",
       " 'nitcs',\n",
       " 'amazigh',\n",
       " 'nif4oggd nlp interchange format',\n",
       " 'sparql endpoint',\n",
       " 'keyword based search',\n",
       " 'geodata store',\n",
       " 'scanning technique',\n",
       " 'cls mt',\n",
       " 'pre translation tool',\n",
       " 'sign detection system',\n",
       " 'spot',\n",
       " 's pot',\n",
       " 'pragmatic reasoning',\n",
       " 'decoding methods',\n",
       " 'subword segmentation',\n",
       " 'mirror theory',\n",
       " 'syntactic framework',\n",
       " 'teitok web based platform',\n",
       " 'stenographic protocols',\n",
       " 'conceptual system',\n",
       " 'neural methods',\n",
       " 'enculturation mechanisms',\n",
       " 'selfregulation',\n",
       " 'directed dynamic measure of cultural fit',\n",
       " 'geoname',\n",
       " 'al strategy',\n",
       " 'dynamic learning',\n",
       " 'interpretable models',\n",
       " 'supervised baseline',\n",
       " 'ltc knowhow',\n",
       " 'industrial grade knowledge management platform',\n",
       " 'ltcknowhow',\n",
       " 'content recommender system',\n",
       " 'standalone platform',\n",
       " 'semantic search components',\n",
       " 'content analyzer',\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others[2999:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e8a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
